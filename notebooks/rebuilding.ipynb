{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\35679\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0419e-02, -6.1356e-03, -1.8098e-03,  7.4841e-02,  5.6615e-02,\n",
       "           1.7083e-02, -1.2694e-02],\n",
       "         [ 1.1083e-02,  9.5276e-03, -1.0993e-01, -2.8050e-01, -2.7124e-01,\n",
       "          -1.2907e-01,  3.7424e-03],\n",
       "         [-6.9434e-03,  5.9089e-02,  2.9548e-01,  5.8720e-01,  5.1972e-01,\n",
       "           2.5632e-01,  6.3573e-02],\n",
       "         [ 3.0505e-02, -6.7018e-02, -2.9841e-01, -4.3868e-01, -2.7085e-01,\n",
       "          -6.1282e-04,  5.7602e-02],\n",
       "         [-2.7535e-02,  1.6045e-02,  7.2595e-02, -5.4102e-02, -3.3285e-01,\n",
       "          -4.2058e-01, -2.5781e-01],\n",
       "         [ 3.0613e-02,  4.0960e-02,  6.2850e-02,  2.3897e-01,  4.1384e-01,\n",
       "           3.9359e-01,  1.6606e-01],\n",
       "         [-1.3736e-02, -3.6746e-03, -2.4084e-02, -6.5877e-02, -1.5070e-01,\n",
       "          -8.2230e-02, -5.7828e-03]],\n",
       "\n",
       "        [[-1.1397e-02, -2.6619e-02, -3.4641e-02,  3.6812e-02,  3.2521e-02,\n",
       "           6.6221e-04, -2.5743e-02],\n",
       "         [ 4.5687e-02,  3.3603e-02, -1.0453e-01, -3.0885e-01, -3.1253e-01,\n",
       "          -1.6051e-01, -1.2826e-03],\n",
       "         [-8.3730e-04,  9.8420e-02,  4.0210e-01,  7.7035e-01,  7.0789e-01,\n",
       "           3.6887e-01,  1.2455e-01],\n",
       "         [-5.8427e-03, -1.2862e-01, -4.2071e-01, -5.9270e-01, -3.8285e-01,\n",
       "          -4.2407e-02,  6.1568e-02],\n",
       "         [-5.5926e-02, -5.2239e-03,  2.7081e-02, -1.5159e-01, -4.6178e-01,\n",
       "          -5.7080e-01, -3.6552e-01],\n",
       "         [ 3.2860e-02,  5.5574e-02,  9.9670e-02,  3.1815e-01,  5.4636e-01,\n",
       "           4.8276e-01,  1.9867e-01],\n",
       "         [ 5.3051e-03,  6.6938e-03, -1.7254e-02, -6.9806e-02, -1.4822e-01,\n",
       "          -7.7248e-02,  7.2183e-04]],\n",
       "\n",
       "        [[-2.0315e-03, -9.1617e-03,  2.1209e-02,  8.9755e-02,  8.9177e-02,\n",
       "           3.3655e-02, -2.0102e-02],\n",
       "         [ 1.5398e-02, -1.8648e-02, -1.2591e-01, -2.9553e-01, -2.5342e-01,\n",
       "          -1.2980e-01, -2.7975e-02],\n",
       "         [ 9.8454e-03,  4.9047e-02,  2.1699e-01,  4.3010e-01,  3.4872e-01,\n",
       "           1.0433e-01,  1.8413e-02],\n",
       "         [ 2.6426e-02, -2.5990e-02, -1.9699e-01, -2.6806e-01, -1.0524e-01,\n",
       "           7.8577e-02,  1.2077e-01],\n",
       "         [-2.8356e-02,  1.8404e-02,  9.8647e-02,  6.1242e-02, -1.1740e-01,\n",
       "          -2.5760e-01, -1.5451e-01],\n",
       "         [ 2.0766e-02, -2.6286e-03, -3.7825e-02,  5.7450e-02,  2.4141e-01,\n",
       "           2.4345e-01,  1.1796e-01],\n",
       "         [ 7.4684e-04,  7.7677e-04, -1.0050e-02, -5.5153e-02, -1.4865e-01,\n",
       "          -1.1754e-01, -3.8350e-02]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "model = resnet18(weights=ResNet18_Weights)\n",
    "list(model.children())[0].weight.data[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0419e-02, -6.1356e-03, -1.8098e-03,  7.4841e-02,  5.6615e-02,\n",
       "           1.7083e-02, -1.2694e-02],\n",
       "         [ 1.1083e-02,  9.5276e-03, -1.0993e-01, -2.8050e-01, -2.7124e-01,\n",
       "          -1.2907e-01,  3.7424e-03],\n",
       "         [-6.9434e-03,  5.9089e-02,  2.9548e-01,  5.8720e-01,  5.1972e-01,\n",
       "           2.5632e-01,  6.3573e-02],\n",
       "         [ 3.0505e-02, -6.7018e-02, -2.9841e-01, -4.3868e-01, -2.7085e-01,\n",
       "          -6.1282e-04,  5.7602e-02],\n",
       "         [-2.7535e-02,  1.6045e-02,  7.2595e-02, -5.4102e-02, -3.3285e-01,\n",
       "          -4.2058e-01, -2.5781e-01],\n",
       "         [ 3.0613e-02,  4.0960e-02,  6.2850e-02,  2.3897e-01,  4.1384e-01,\n",
       "           3.9359e-01,  1.6606e-01],\n",
       "         [-1.3736e-02, -3.6746e-03, -2.4084e-02, -6.5877e-02, -1.5070e-01,\n",
       "          -8.2230e-02, -5.7828e-03]],\n",
       "\n",
       "        [[-1.1397e-02, -2.6619e-02, -3.4641e-02,  3.6812e-02,  3.2521e-02,\n",
       "           6.6221e-04, -2.5743e-02],\n",
       "         [ 4.5687e-02,  3.3603e-02, -1.0453e-01, -3.0885e-01, -3.1253e-01,\n",
       "          -1.6051e-01, -1.2826e-03],\n",
       "         [-8.3730e-04,  9.8420e-02,  4.0210e-01,  7.7035e-01,  7.0789e-01,\n",
       "           3.6887e-01,  1.2455e-01],\n",
       "         [-5.8427e-03, -1.2862e-01, -4.2071e-01, -5.9270e-01, -3.8285e-01,\n",
       "          -4.2407e-02,  6.1568e-02],\n",
       "         [-5.5926e-02, -5.2239e-03,  2.7081e-02, -1.5159e-01, -4.6178e-01,\n",
       "          -5.7080e-01, -3.6552e-01],\n",
       "         [ 3.2860e-02,  5.5574e-02,  9.9670e-02,  3.1815e-01,  5.4636e-01,\n",
       "           4.8276e-01,  1.9867e-01],\n",
       "         [ 5.3051e-03,  6.6938e-03, -1.7254e-02, -6.9806e-02, -1.4822e-01,\n",
       "          -7.7248e-02,  7.2183e-04]],\n",
       "\n",
       "        [[-2.0315e-03, -9.1617e-03,  2.1209e-02,  8.9755e-02,  8.9177e-02,\n",
       "           3.3655e-02, -2.0102e-02],\n",
       "         [ 1.5398e-02, -1.8648e-02, -1.2591e-01, -2.9553e-01, -2.5342e-01,\n",
       "          -1.2980e-01, -2.7975e-02],\n",
       "         [ 9.8454e-03,  4.9047e-02,  2.1699e-01,  4.3010e-01,  3.4872e-01,\n",
       "           1.0433e-01,  1.8413e-02],\n",
       "         [ 2.6426e-02, -2.5990e-02, -1.9699e-01, -2.6806e-01, -1.0524e-01,\n",
       "           7.8577e-02,  1.2077e-01],\n",
       "         [-2.8356e-02,  1.8404e-02,  9.8647e-02,  6.1242e-02, -1.1740e-01,\n",
       "          -2.5760e-01, -1.5451e-01],\n",
       "         [ 2.0766e-02, -2.6286e-03, -3.7825e-02,  5.7450e-02,  2.4141e-01,\n",
       "           2.4345e-01,  1.1796e-01],\n",
       "         [ 7.4684e-04,  7.7677e-04, -1.0050e-02, -5.5153e-02, -1.4865e-01,\n",
       "          -1.1754e-01, -3.8350e-02]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_model(path, pruned=False):\n",
    "    model = resnet18()\n",
    "    if pruned:\n",
    "        state = torch.load('../checkpoints/'+path+\".pth\", map_location='cpu')\n",
    "        tp.load_state_dict(model, state_dict=state)\n",
    "\n",
    "    else:\n",
    "        model.load_state_dict(torch.load('../checkpoints/'+path+\".pth\"))\n",
    "    return model\n",
    "\n",
    "tuned = load_model(\"resnet50_tuned_0.2\", pruned=True)\n",
    "list(tuned.children())[0].weight.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer4.0.downsample.0': [896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023]}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# Load the dictionary from the file\n",
    "with open(\"..\\checkpoints\\history\\in_resnet50_pruned_0.125.pkl\", 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)\n",
    "\n",
    "# Print the loaded dictionary\n",
    "print(loaded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def get_layers(model: torch.nn.Module, parent_name=''):\n",
    "    layers = {}\n",
    "    for name, module in model.named_children():\n",
    "        layer_name = f\"{parent_name}.{name}\" if parent_name else name\n",
    "        if len(list(module.children())) == 0:\n",
    "            layers[layer_name] = module\n",
    "        else:\n",
    "            layers.update(get_layers(module, parent_name=layer_name))\n",
    "    return layers\n",
    "\n",
    "def compare_models(model_a, model_b):\n",
    "    layers_a = get_layers(model=model_a)\n",
    "    layers_b = get_layers(model=model_b)\n",
    "    i = 1\n",
    "    layer_count = len(layers_a)\n",
    "    if (len(layers_a) == len(layers_b)):\n",
    "        print(\"Same layer count\")\n",
    "\n",
    "    for i, (name, module) in enumerate(layers_a.items()):\n",
    "        if hasattr(module, 'weight'):\n",
    "            if not torch.equal(module.weight.data, layers_b[name].weight.data):\n",
    "                print(str(i), \"of\", str(layer_count), \"Fail:\", name, module)\n",
    "            else:\n",
    "                print(str(i), \"of\", str(layer_count), \"Pass:\", name, module)\n",
    "        i += 1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch_pruning as tp\n",
    "from functools import reduce\n",
    "\n",
    "test_model = resnet50(weights=ResNet50_Weights).eval()\n",
    "test2_model = resnet50(weights=ResNet50_Weights).eval()\n",
    "\n",
    "def compareModelWeights(model_a, model_b):\n",
    "    module_a = model_a._modules\n",
    "    module_b = model_b._modules\n",
    "    if len(list(module_a.keys())) != len(list(module_b.keys())):\n",
    "        return False\n",
    "    a_modules_names = list(module_a.keys())\n",
    "    b_modules_names = list(module_b.keys())\n",
    "    for i in range(len(a_modules_names)):\n",
    "        layer_name_a = a_modules_names[i]\n",
    "        layer_name_b = b_modules_names[i]\n",
    "        if layer_name_a != layer_name_b:\n",
    "            return False\n",
    "        layer_a = module_a[layer_name_a]\n",
    "        layer_b = module_b[layer_name_b]\n",
    "        if (\n",
    "            (type(layer_a) == nn.Module) or (type(layer_b) == nn.Module) or\n",
    "            (type(layer_a) == nn.Sequential) or (type(layer_b) == nn.Sequential)\n",
    "            ):\n",
    "            if not compareModelWeights(layer_a, layer_b):\n",
    "                return False\n",
    "        if hasattr(layer_a, 'weight') and hasattr(layer_b, 'weight'):\n",
    "            if not torch.equal(layer_a.weight.data, layer_b.weight.data):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "compareModelWeights(test_model, test2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\35679\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch_pruning as tp\n",
    "from functools import reduce\n",
    "\n",
    "def get_module_by_name(model, access_string):\n",
    "    names = access_string.split(sep='.')\n",
    "    return reduce(getattr, names, model)\n",
    "\n",
    "model = resnet50().eval()\n",
    "bigger_model = resnet50(weights=ResNet50_Weights).eval()\n",
    "\n",
    "# state = torch.load('exp_2_model_resnet50_prune_0.125_single_epochs_10_epoch9pruned.pth', map_location='cpu')\n",
    "# tp.load_state_dict(model, state_dict=state)\n",
    "# model.eval()\n",
    "\n",
    "# model = model.module\n",
    "\n",
    "# # Iterate over model parameters\n",
    "# for name, params in model.named_parameters():\n",
    "#     new_tensor = torch.ones_like(params.data)\n",
    "#     params.data = new_tensor\n",
    "\n",
    "# # Iterate over model parameters\n",
    "# for name, params in model.named_parameters():\n",
    "#     if name == \"conv1.weight\":\n",
    "#         new_tensor = torch.ones_like(params.data[1, :, :, :])\n",
    "#         params.data[1, :, :, :] = new_tensor \n",
    "\n",
    "# model.conv1.weight.data[1, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1 Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "1 bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2 relu ReLU(inplace=True)\n",
      "3 maxpool MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "4 layer1.0.conv1 Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "5 layer1.0.bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "6 layer1.0.conv2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "7 layer1.0.bn2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "8 layer1.0.conv3 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "9 layer1.0.bn3 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "10 layer1.0.relu ReLU(inplace=True)\n",
      "11 layer1.0.downsample.0 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "12 layer1.0.downsample.1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "13 layer1.1.conv1 Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "14 layer1.1.bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "15 layer1.1.conv2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "16 layer1.1.bn2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "17 layer1.1.conv3 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "18 layer1.1.bn3 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "19 layer1.1.relu ReLU(inplace=True)\n",
      "20 layer1.2.conv1 Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "21 layer1.2.bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "22 layer1.2.conv2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "23 layer1.2.bn2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "24 layer1.2.conv3 Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "25 layer1.2.bn3 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "26 layer1.2.relu ReLU(inplace=True)\n",
      "27 layer2.0.conv1 Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "28 layer2.0.bn1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "29 layer2.0.conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "30 layer2.0.bn2 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "31 layer2.0.conv3 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "32 layer2.0.bn3 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "33 layer2.0.relu ReLU(inplace=True)\n",
      "34 layer2.0.downsample.0 Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "35 layer2.0.downsample.1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "36 layer2.1.conv1 Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "37 layer2.1.bn1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "38 layer2.1.conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "39 layer2.1.bn2 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "40 layer2.1.conv3 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "41 layer2.1.bn3 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "42 layer2.1.relu ReLU(inplace=True)\n",
      "43 layer2.2.conv1 Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "44 layer2.2.bn1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "45 layer2.2.conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "46 layer2.2.bn2 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "47 layer2.2.conv3 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "48 layer2.2.bn3 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "49 layer2.2.relu ReLU(inplace=True)\n",
      "50 layer2.3.conv1 Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "51 layer2.3.bn1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "52 layer2.3.conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "53 layer2.3.bn2 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "54 layer2.3.conv3 Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "55 layer2.3.bn3 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "56 layer2.3.relu ReLU(inplace=True)\n",
      "57 layer3.0.conv1 Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "58 layer3.0.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "59 layer3.0.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "60 layer3.0.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "61 layer3.0.conv3 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "62 layer3.0.bn3 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "63 layer3.0.relu ReLU(inplace=True)\n",
      "64 layer3.0.downsample.0 Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "65 layer3.0.downsample.1 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "66 layer3.1.conv1 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "67 layer3.1.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "68 layer3.1.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "69 layer3.1.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "70 layer3.1.conv3 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "71 layer3.1.bn3 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "72 layer3.1.relu ReLU(inplace=True)\n",
      "73 layer3.2.conv1 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "74 layer3.2.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "75 layer3.2.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "76 layer3.2.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "77 layer3.2.conv3 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "78 layer3.2.bn3 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "79 layer3.2.relu ReLU(inplace=True)\n",
      "80 layer3.3.conv1 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "81 layer3.3.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "82 layer3.3.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "83 layer3.3.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "84 layer3.3.conv3 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "85 layer3.3.bn3 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "86 layer3.3.relu ReLU(inplace=True)\n",
      "87 layer3.4.conv1 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "88 layer3.4.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "89 layer3.4.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "90 layer3.4.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "91 layer3.4.conv3 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "92 layer3.4.bn3 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "93 layer3.4.relu ReLU(inplace=True)\n",
      "94 layer3.5.conv1 Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "95 layer3.5.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "96 layer3.5.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "97 layer3.5.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "98 layer3.5.conv3 Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "99 layer3.5.bn3 BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "100 layer3.5.relu ReLU(inplace=True)\n",
      "101 layer4.0.conv1 Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "102 layer4.0.bn1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "103 layer4.0.conv2 Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "104 layer4.0.bn2 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "105 layer4.0.conv3 Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "106 layer4.0.bn3 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "107 layer4.0.relu ReLU(inplace=True)\n",
      "108 layer4.0.downsample.0 Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "109 layer4.0.downsample.1 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "110 layer4.1.conv1 Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "111 layer4.1.bn1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "112 layer4.1.conv2 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "113 layer4.1.bn2 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "114 layer4.1.conv3 Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "115 layer4.1.bn3 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "116 layer4.1.relu ReLU(inplace=True)\n",
      "117 layer4.2.conv1 Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "118 layer4.2.bn1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "119 layer4.2.conv2 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "120 layer4.2.bn2 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "121 layer4.2.conv3 Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "122 layer4.2.bn3 BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "123 layer4.2.relu ReLU(inplace=True)\n",
      "124 avgpool AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "125 fc Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "def get_layers(model: torch.nn.Module, parent_name=''):\n",
    "    layers = {}\n",
    "    for name, module in model.named_children():\n",
    "        layer_name = f\"{parent_name}.{name}\" if parent_name else name\n",
    "        if len(list(module.children())) == 0:\n",
    "            layers[layer_name] = module\n",
    "        else:\n",
    "            layers.update(get_layers(module, parent_name=layer_name))\n",
    "    return layers\n",
    "\n",
    "layers = get_layers(bigger_model)\n",
    "for i, (name, module) in enumerate(layers.items()):\n",
    "    print(str(i), name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('0.125_history_exp2', 'rb') as file:\n",
    "    history = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_affected = len(history)\n",
    "layers_affected_per_step = int(layers_affected / 1)\n",
    "step_history = [history[i:i+layers_affected_per_step] for i in range(0, layers_affected, layers_affected_per_step)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over model parameters\n",
    "# for name, params in model.named_parameters():\n",
    "#     if name == \"conv1.weight\":\n",
    "#         new_tensor = torch.ones_like(params.data[1, :, :, :])\n",
    "#         params.data[1, :, :, :] = new_tensor \n",
    "\n",
    "# model.conv1.weight.data[1, :, :, :]\n",
    "\n",
    "def rebuild_model(tuned_model, bigger_model, step_history):\n",
    "    for i, history in enumerate(reversed(step_history[0])):\n",
    "\n",
    "        # loop through each layer changed in pruning\n",
    "        for pruned_layer_name, b, channels_removed in reversed(history):\n",
    "\n",
    "            # loop through the layers of the larger model (same number of layers, different channel width)\n",
    "            for layer_name, bigger_layer_params in bigger_model.named_parameters():\n",
    "\n",
    "                skipped = 0\n",
    "\n",
    "                if\"module.\"+layer_name == pruned_layer_name+\".weight\" and layer_name == \"conv1.weight\":\n",
    "\n",
    "                        # get copy of layers\n",
    "                        tuned_layer = get_module_by_name(tuned_model, layer_name[:-7])\n",
    "                        bigger_layer = get_module_by_name(bigger_model, layer_name[:-7])\n",
    "                        print(channels_removed)\n",
    "\n",
    "                        # loop throught the channels of the bigger model\n",
    "                        for idx in range(bigger_layer.out_channels):\n",
    "\n",
    "                            # check if the channel has been dropped\n",
    "                            if idx in channels_removed:\n",
    "                                # if channel was dropped, do not copy weights from smaller tuned model\n",
    "                                # print(\"Channel was skipped\")\n",
    "                                skipped += 1\n",
    "\n",
    "                            else:\n",
    "                                # copy weights from tuned model to larger model\n",
    "                                if \"layer\" not in layer_name:\n",
    "                                    print(layer_name, idx, idx-skipped)\n",
    "                                    bigger_layer_params.data[idx,:, : ,:] = tuned_layer.weight.data[idx-skipped,:, : ,:]\n",
    "\n",
    "                                else: # for conv layers with reshape of both input and output\n",
    "\n",
    "                                    # bigger_layer_params.requires_grad_(False)\n",
    "                                    skipped_j = 0\n",
    "\n",
    "                                    if (bigger_layer.in_channels - tuned_layer.in_channels) == len(channels_removed):\n",
    "\n",
    "                                        for idx_j in range(bigger_layer.in_channels):\n",
    "\n",
    "                                            if idx_j in channels_removed:\n",
    "                                                # if channel was dropped, do not copy weights from smaller tuned model\n",
    "                                                skipped_j += 1\n",
    "                                            else:\n",
    "                                                bigger_layer_params.data[idx,idx_j, : ,:] = tuned_layer.weight.data[idx-skipped,idx_j-skipped_j, : ,:]\n",
    "    return bigger_model\n",
    "\n",
    "bm = rebuild_model(model, bigger_model, step_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\35679\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch_pruning as tp\n",
    "from functools import reduce\n",
    "import pickle\n",
    "\n",
    "def get_module_by_name(model, access_string):\n",
    "    names = access_string.split(sep='.')\n",
    "    return reduce(getattr, names, model)\n",
    "\n",
    "\n",
    "model = resnet50().eval()\n",
    "bigger_model = resnet50(weights=ResNet50_Weights).eval()\n",
    "verif_model = resnet50(weights=ResNet50_Weights).eval()\n",
    "# model.state_dict()['layer1.0.conv1.weight'].in_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same layer count\n",
      "1 of 126 Pass: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "2 of 126 Pass: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "3 of 126 No weights ReLU(inplace=True)\n",
      "4 of 126 No weights MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "5 of 126 Pass: Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "6 of 126 Pass: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "7 of 126 Pass: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "8 of 126 Pass: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "9 of 126 Pass: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "10 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "11 of 126 No weights ReLU(inplace=True)\n",
      "12 of 126 Pass: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "13 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "14 of 126 Pass: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "15 of 126 Pass: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "16 of 126 Pass: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "17 of 126 Pass: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "18 of 126 Pass: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "19 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "20 of 126 No weights ReLU(inplace=True)\n",
      "21 of 126 Pass: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "22 of 126 Pass: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "23 of 126 Pass: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "24 of 126 Pass: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "25 of 126 Pass: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "26 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "27 of 126 No weights ReLU(inplace=True)\n",
      "28 of 126 Pass: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "29 of 126 Pass: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "30 of 126 Pass: Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "31 of 126 Pass: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "32 of 126 Pass: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "33 of 126 Pass: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "34 of 126 No weights ReLU(inplace=True)\n",
      "35 of 126 Pass: Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "36 of 126 Pass: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "37 of 126 Pass: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "38 of 126 Pass: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "39 of 126 Pass: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "40 of 126 Pass: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "41 of 126 Pass: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "42 of 126 Pass: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "43 of 126 No weights ReLU(inplace=True)\n",
      "44 of 126 Pass: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "45 of 126 Pass: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "46 of 126 Pass: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "47 of 126 Pass: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "48 of 126 Pass: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "49 of 126 Pass: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "50 of 126 No weights ReLU(inplace=True)\n",
      "51 of 126 Pass: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "52 of 126 Pass: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "53 of 126 Pass: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "54 of 126 Pass: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "55 of 126 Pass: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "56 of 126 Pass: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "57 of 126 No weights ReLU(inplace=True)\n",
      "58 of 126 Pass: Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "59 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "60 of 126 Pass: Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "61 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "62 of 126 Pass: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "63 of 126 Pass: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "64 of 126 No weights ReLU(inplace=True)\n",
      "65 of 126 Pass: Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "66 of 126 Pass: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "67 of 126 Pass: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "68 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "69 of 126 Pass: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "70 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "71 of 126 Pass: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "72 of 126 Pass: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "73 of 126 No weights ReLU(inplace=True)\n",
      "74 of 126 Pass: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "75 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "76 of 126 Pass: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "77 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "78 of 126 Pass: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "79 of 126 Pass: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "80 of 126 No weights ReLU(inplace=True)\n",
      "81 of 126 Pass: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "82 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "83 of 126 Pass: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "84 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "85 of 126 Pass: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "86 of 126 Pass: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "87 of 126 No weights ReLU(inplace=True)\n",
      "88 of 126 Pass: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "89 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "90 of 126 Pass: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "91 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "92 of 126 Pass: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "93 of 126 Pass: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "94 of 126 No weights ReLU(inplace=True)\n",
      "95 of 126 Pass: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "96 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "97 of 126 Pass: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "98 of 126 Pass: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "99 of 126 Pass: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "100 of 126 Pass: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "101 of 126 No weights ReLU(inplace=True)\n",
      "102 of 126 Pass: Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "103 of 126 Pass: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "104 of 126 Pass: Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "105 of 126 Pass: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "106 of 126 Pass: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "107 of 126 Pass: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "108 of 126 No weights ReLU(inplace=True)\n",
      "109 of 126 Pass: Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "110 of 126 Pass: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "111 of 126 Pass: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "112 of 126 Pass: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "113 of 126 Pass: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "114 of 126 Pass: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "115 of 126 Pass: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "116 of 126 Pass: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "117 of 126 No weights ReLU(inplace=True)\n",
      "118 of 126 Pass: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "119 of 126 Pass: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "120 of 126 Pass: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "121 of 126 Pass: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "122 of 126 Pass: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "123 of 126 Pass: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "124 of 126 No weights ReLU(inplace=True)\n",
      "125 of 126 No weights AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "126 of 126 Pass: Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "def get_layers(model: torch.nn.Module):\n",
    "    children = list(model.children())\n",
    "    return [model] if len(children) == 0 else [ci for c in children for ci in get_layers(c)]\n",
    "\n",
    "def compare_models(model_a, model_b):\n",
    "    \n",
    "    layers_a = get_layers(model=model_a)\n",
    "    layers_b = get_layers(model=model_b)\n",
    "\n",
    "    layer_count = len(layers_a)\n",
    "    i = 1\n",
    "    \n",
    "    if(len(layers_a) == len(layers_b)):\n",
    "        print(\"Same layer count\")\n",
    "\n",
    "    for idx in range(layer_count):\n",
    "        if hasattr(layers_a[idx], 'weight'):\n",
    "            if torch.equal(layers_a[idx].weight.data, layers_b[idx].weight.data):\n",
    "                print(str(i),\"of\",str(layer_count), \"Pass:\", layers_a[idx])\n",
    "            else:\n",
    "                print(str(i),\"of\",str(layer_count),\"Fail:\", layers_a[idx])\n",
    "        else:\n",
    "            print(str(i),\"of\",str(layer_count),\"No weights\", layers_a[idx])\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "compare_models(bigger_model, verif_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 56, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(56, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(224, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(224, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(224, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(224, 448, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(448, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(448, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(448, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(448, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(224, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(448, 896, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(896, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(224, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(896, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(224, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(896, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(224, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(896, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(224, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(896, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(224, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(896, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(448, 448, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(896, 1792, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1792, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1792, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=1792, out_features=1000, bias=True)\n",
      ")\n",
      "150 37\n",
      "['conv1', 'bn1', 'relu', 'maxpool', 'layer1', 'layer1.0', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.conv3', 'layer1.0.bn3', 'layer1.0.relu', 'layer1.0.downsample', 'layer1.0.downsample.0', 'layer1.0.downsample.1', 'layer1.1', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.conv3', 'layer1.1.bn3', 'layer1.1.relu', 'layer1.2', 'layer1.2.conv1', 'layer1.2.bn1', 'layer1.2.conv2', 'layer1.2.bn2', 'layer1.2.conv3', 'layer1.2.bn3', 'layer1.2.relu', 'layer2', 'layer2.0', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.conv3', 'layer2.0.bn3', 'layer2.0.relu', 'layer2.0.downsample', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.1', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.conv3', 'layer2.1.bn3', 'layer2.1.relu', 'layer2.2', 'layer2.2.conv1', 'layer2.2.bn1', 'layer2.2.conv2', 'layer2.2.bn2', 'layer2.2.conv3', 'layer2.2.bn3', 'layer2.2.relu', 'layer2.3', 'layer2.3.conv1', 'layer2.3.bn1', 'layer2.3.conv2', 'layer2.3.bn2', 'layer2.3.conv3', 'layer2.3.bn3', 'layer2.3.relu', 'layer3', 'layer3.0', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.conv3', 'layer3.0.bn3', 'layer3.0.relu', 'layer3.0.downsample', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.1', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.conv3', 'layer3.1.bn3', 'layer3.1.relu', 'layer3.2', 'layer3.2.conv1', 'layer3.2.bn1', 'layer3.2.conv2', 'layer3.2.bn2', 'layer3.2.conv3', 'layer3.2.bn3', 'layer3.2.relu', 'layer3.3', 'layer3.3.conv1', 'layer3.3.bn1', 'layer3.3.conv2', 'layer3.3.bn2', 'layer3.3.conv3', 'layer3.3.bn3', 'layer3.3.relu', 'layer3.4', 'layer3.4.conv1', 'layer3.4.bn1', 'layer3.4.conv2', 'layer3.4.bn2', 'layer3.4.conv3', 'layer3.4.bn3', 'layer3.4.relu', 'layer3.5', 'layer3.5.conv1', 'layer3.5.bn1', 'layer3.5.conv2', 'layer3.5.bn2', 'layer3.5.conv3', 'layer3.5.bn3', 'layer3.5.relu', 'layer4', 'layer4.0', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.conv3', 'layer4.0.bn3', 'layer4.0.relu', 'layer4.0.downsample', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.1', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.conv3', 'layer4.1.bn3', 'layer4.1.relu', 'layer4.2', 'layer4.2.conv1', 'layer4.2.bn1', 'layer4.2.conv2', 'layer4.2.bn2', 'layer4.2.conv3', 'layer4.2.bn3', 'layer4.2.relu', 'avgpool', 'fc']\n",
      "['layer4.0.downsample.0', 'layer3.0.downsample.0', 'layer2.0.downsample.0', 'layer1.0.downsample.0', 'conv1', 'layer1.0.conv2', 'layer1.0.conv1', 'layer1.1.conv2', 'layer1.1.conv1', 'layer1.2.conv2', 'layer1.2.conv1', 'layer2.0.conv2', 'layer2.0.conv1', 'layer2.1.conv2', 'layer2.1.conv1', 'layer2.2.conv2', 'layer2.2.conv1', 'layer2.3.conv2', 'layer2.3.conv1', 'layer3.0.conv2', 'layer3.0.conv1', 'layer3.1.conv2', 'layer3.1.conv1', 'layer3.2.conv2', 'layer3.2.conv1', 'layer3.3.conv2', 'layer3.3.conv1', 'layer3.4.conv2', 'layer3.4.conv1', 'layer3.5.conv2', 'layer3.5.conv1', 'layer4.0.conv2', 'layer4.0.conv1', 'layer4.1.conv2', 'layer4.1.conv1', 'layer4.2.conv2', 'layer4.2.conv1']\n",
      "Layers not found in both models: {'layer2.3.bn2', 'layer1.0.bn2', 'bn1', 'layer3.4.bn2', 'layer1.0.bn1', 'layer4.2.relu', 'layer1.0.conv3', 'layer4.0.downsample.1', 'layer4.0.conv3', 'layer2.1', 'layer3.1', 'layer4.1.bn2', 'layer2.1.bn3', 'layer2.3.relu', 'layer4.2.bn1', 'layer1.2.conv3', 'layer2.3', 'layer3.0.bn1', 'layer3.5.bn1', 'layer3.0.downsample.1', 'layer3.4', 'layer2.1.bn2', 'layer2.3.bn3', 'layer3.2', 'layer3.0.bn2', 'layer1.2.bn1', 'layer3.0.relu', 'layer1.1.conv3', 'layer2.2', 'layer3.1.bn1', 'layer1.2.bn3', 'layer4.0.relu', 'layer3.4.relu', 'layer3.3.bn1', 'layer4.0', 'layer3.3.bn3', 'layer4.2.bn3', 'relu', 'layer4.0.bn2', 'fc', 'layer4.1.bn3', 'layer4', 'layer1.0', 'layer3', 'layer2.0.bn1', 'layer3.2.relu', 'layer2.0.conv3', 'layer3.4.bn1', 'layer1.0.downsample.1', 'layer2.1.bn1', 'layer1.0.downsample', 'layer2.0.bn2', 'layer3.1.bn2', 'layer2.2.bn2', 'layer1.1.relu', 'layer4.1', 'layer3.0.conv3', 'layer2.2.conv3', 'layer4.0.bn3', 'layer3.3.conv3', 'layer1.2.bn2', 'layer2.0.relu', 'layer1.1', 'layer2.3.bn1', 'layer3.1.conv3', 'layer1.0.bn3', 'layer3.2.bn3', 'maxpool', 'layer3.3', 'layer3.5.bn2', 'layer3.5', 'layer3.1.bn3', 'layer2.1.conv3', 'layer3.3.relu', 'layer4.0.bn1', 'layer1.0.relu', 'layer1.1.bn3', 'layer1', 'layer1.2', 'layer2.3.conv3', 'layer3.1.relu', 'layer4.2.bn2', 'layer1.1.bn2', 'layer2.1.relu', 'layer2.2.relu', 'layer3.5.conv3', 'avgpool', 'layer2.0.bn3', 'layer2.0.downsample', 'layer1.2.relu', 'layer3.0.bn3', 'layer3.2.bn2', 'layer4.1.relu', 'layer2.0', 'layer3.3.bn2', 'layer4.2', 'layer1.1.bn1', 'layer2.2.bn3', 'layer3.4.bn3', 'layer4.1.bn1', 'layer2.0.downsample.1', 'layer2.2.bn1', 'layer4.0.downsample', 'layer3.5.bn3', 'layer3.0.downsample', 'layer4.1.conv3', 'layer3.5.relu', 'layer3.4.conv3', 'layer2', 'layer3.2.conv3', 'layer3.0', 'layer3.2.bn1', 'layer4.2.conv3'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state = torch.load(\n",
    "    '../checkpoints/resnet50_pruned_0.125.pth', map_location='cpu')\n",
    "tp.load_state_dict(model, state_dict=state)\n",
    "model.eval()\n",
    "# model = model.module\n",
    "\n",
    "with open('../checkpoints/history/out_resnet50_pruned_0.125', 'rb') as file:\n",
    "    history_steps = pickle.load(file)\n",
    "\n",
    "    print(model)\n",
    "\n",
    "all_layers = [name for name, _ in model.named_modules() if name != '']\n",
    "layers_pruned = []\n",
    "for step in history_steps:\n",
    "    for layer_name, b, out_channels_pruned in step:\n",
    "        layers_pruned.append(layer_name)\n",
    "\n",
    "print(len(all_layers), len(layers_pruned))\n",
    "print(all_layers)\n",
    "print(layers_pruned)\n",
    "not_found = set(all_layers) - set(layers_pruned)\n",
    "print(\"Layers not found in both models:\", not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same layer count\n",
      "1 of 126 Fail: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "2 of 126 Fail: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "3 of 126 No weights ReLU(inplace=True)\n",
      "4 of 126 No weights MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "5 of 126 Fail: Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "6 of 126 Fail: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "7 of 126 Fail: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "8 of 126 Fail: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "9 of 126 Fail: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "10 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "11 of 126 No weights ReLU(inplace=True)\n",
      "12 of 126 Fail: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "13 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "14 of 126 Fail: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "15 of 126 Fail: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "16 of 126 Fail: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "17 of 126 Fail: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "18 of 126 Fail: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "19 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "20 of 126 No weights ReLU(inplace=True)\n",
      "21 of 126 Fail: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "22 of 126 Fail: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "23 of 126 Fail: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "24 of 126 Fail: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "25 of 126 Fail: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "26 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "27 of 126 No weights ReLU(inplace=True)\n",
      "28 of 126 Fail: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "29 of 126 Fail: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "30 of 126 Fail: Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "31 of 126 Fail: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "32 of 126 Fail: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "33 of 126 Fail: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "34 of 126 No weights ReLU(inplace=True)\n",
      "35 of 126 Fail: Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "36 of 126 Fail: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "37 of 126 Fail: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "38 of 126 Fail: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "39 of 126 Fail: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "40 of 126 Fail: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "41 of 126 Fail: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "42 of 126 Fail: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "43 of 126 No weights ReLU(inplace=True)\n",
      "44 of 126 Fail: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "45 of 126 Fail: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "46 of 126 Fail: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "47 of 126 Fail: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "48 of 126 Fail: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "49 of 126 Fail: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "50 of 126 No weights ReLU(inplace=True)\n",
      "51 of 126 Fail: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "52 of 126 Fail: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "53 of 126 Fail: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "54 of 126 Fail: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "55 of 126 Fail: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "56 of 126 Fail: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "57 of 126 No weights ReLU(inplace=True)\n",
      "58 of 126 Fail: Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "59 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "60 of 126 Fail: Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "61 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "62 of 126 Fail: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "63 of 126 Fail: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "64 of 126 No weights ReLU(inplace=True)\n",
      "65 of 126 Fail: Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "66 of 126 Fail: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "67 of 126 Fail: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "68 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "69 of 126 Fail: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "70 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "71 of 126 Fail: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "72 of 126 Fail: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "73 of 126 No weights ReLU(inplace=True)\n",
      "74 of 126 Fail: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "75 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "76 of 126 Fail: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "77 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "78 of 126 Fail: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "79 of 126 Fail: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "80 of 126 No weights ReLU(inplace=True)\n",
      "81 of 126 Fail: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "82 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "83 of 126 Fail: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "84 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "85 of 126 Fail: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "86 of 126 Fail: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "87 of 126 No weights ReLU(inplace=True)\n",
      "88 of 126 Fail: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "89 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "90 of 126 Fail: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "91 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "92 of 126 Fail: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "93 of 126 Fail: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "94 of 126 No weights ReLU(inplace=True)\n",
      "95 of 126 Fail: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "96 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "97 of 126 Fail: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "98 of 126 Fail: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "99 of 126 Fail: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "100 of 126 Fail: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "101 of 126 No weights ReLU(inplace=True)\n",
      "102 of 126 Fail: Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "103 of 126 Fail: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "104 of 126 Fail: Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "105 of 126 Fail: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "106 of 126 Fail: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "107 of 126 Fail: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "108 of 126 No weights ReLU(inplace=True)\n",
      "109 of 126 Fail: Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "110 of 126 Fail: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "111 of 126 Fail: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "112 of 126 Fail: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "113 of 126 Fail: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "114 of 126 Fail: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "115 of 126 Fail: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "116 of 126 Fail: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "117 of 126 No weights ReLU(inplace=True)\n",
      "118 of 126 Fail: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "119 of 126 Fail: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "120 of 126 Fail: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "121 of 126 Fail: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "122 of 126 Fail: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "123 of 126 Fail: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "124 of 126 No weights ReLU(inplace=True)\n",
      "125 of 126 No weights AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "126 of 126 Fail: Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import onnx\n",
    "# from onnx2torch import convert\n",
    "\n",
    "# # Path to ONNX model\n",
    "# rebuilt_path = '../checkpoints/onnx/resnet50_rebuilt.onnx'\n",
    "# verif_path = '../checkpoints/onnx/resnet50_verif.onnx'\n",
    "# # You can pass the path to the onnx model to convert it or...\n",
    "# # rebuilt_model_onnx = convert(rebuilt_path)\n",
    "# # verif_model_onnx = convert(verif_path)\n",
    "# onnx_model = onnx.load(rebuilt_path)\n",
    "# torch_model_2 = convert(onnx_model)\n",
    "# print(torch_model_2)\n",
    "\n",
    "rebuilt_model = resnet50()\n",
    "rebuilt_model.load_state_dict(torch.load(\"../checkpoints/resnet50_rebuilt.pth\"))\n",
    "bigger_model\n",
    "\n",
    "compare_models(bigger_model, rebuilt_model)\n",
    "\n",
    "# for layer in all_layers:\n",
    "#     original_layer = get_module_by_name(bigger_model, layer)\n",
    "#     rebuilt_layer = get_module_by_name(rebuilt_model, layer)\n",
    "#     if hasattr(original_layer, 'weight'):\n",
    "#         if torch.equal(original_layer.weight.data, rebuilt_layer.weight.data):\n",
    "#             print(\"Pass:\", layer)\n",
    "#         # else:\n",
    "#             # print(\"Fail\", layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigger_model.bn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_layer_history(layer, history_steps):\n",
    "    for step in history_steps:\n",
    "        for name, b, channels in step:\n",
    "            if name == \"module.\"+layer:\n",
    "                return channels\n",
    "\n",
    "\n",
    "def get_module_by_name(model, access_string):\n",
    "    names = access_string.split(sep='.')\n",
    "    return reduce(getattr, names, model)\n",
    "\n",
    "    # print(original_layer.weight.data.shape)\n",
    "    # print(pruned_layer.weight.data.shape)\n",
    "\n",
    "    # todo add loop for all out channels\n",
    "\n",
    "    # out 256 => 224 32 out channels, these removed channels use original weights when rebuilding\n",
    "    # in 256 => 224 32 in channels removed on non pruned channels, for each non pruned channel, find in channels that are pruned also\n",
    "\n",
    "\n",
    "def get_layer_in_channel_history(original, pruned, layer, pruned_out_channels):\n",
    "    original_layer = get_module_by_name(original, layer)\n",
    "    pruned_layer = get_module_by_name(pruned, layer)\n",
    "    skipped = 0  # adjustment to match out_channel between original and pruned model of different shapes\n",
    "    pruned_in_channels_history = []\n",
    "\n",
    "    for out_channel_idx in range(original_layer.out_channels):\n",
    "        not_pruned_in_channels = []  # in channels pruned per out channel\n",
    "        if out_channel_idx in pruned_out_channels:\n",
    "            # the out_channel is completely pruned\n",
    "            skipped += 1\n",
    "        else:\n",
    "            for in_channel_i in range(original_layer.in_channels):\n",
    "                # the out_channel is partially pruned, loop through the in channels \n",
    "                # and find which idx have been pruned for each non-pruned out channel\n",
    "                for in_channel_j in range(pruned_layer.in_channels):\n",
    "                    # the output channel exists in both pruned and original model\n",
    "                    if torch.equal(original_layer.weight.data[out_channel_idx, in_channel_i, :, :], original_layer.weight.data[out_channel_idx-skipped, in_channel_j, :, :]):\n",
    "                        not_pruned_in_channels.append(in_channel_j)\n",
    "                        continue\n",
    "                        # in_channel_j of the pruned layer matches weights in the original layer, i.e not pruned\n",
    "        \n",
    "        all_channels = list(range(original_layer.in_channels))\n",
    "        pruned_in_channels= [x for x in all_channels if x not in not_pruned_in_channels]\n",
    "        pruned_in_channels_history.append([layer, pruned_in_channels])\n",
    "        break # the input channels dropped are the same for each output channel\n",
    "    return pruned_in_channels_history\n",
    "\n",
    "pruned_out_channels = get_layer_history('layer2.2.conv1', history_steps)\n",
    "in_history = get_layer_in_channel_history(bigger_model, model, 'layer2.2.conv1', pruned_out_channels)\n",
    "\n",
    "for step in history_steps:\n",
    "    for layer_name, b, out_channels_pruned in step:\n",
    "        # print(layer_name[7:])\n",
    "        in_history = get_layer_in_channel_history(bigger_model, model, layer_name[7:], pruned_out_channels)\n",
    "        for idx, in_channels in in_history:\n",
    "            print(layer_name, idx, in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# histories overview\n",
    "# out_channel history layer_name, [channels pruned]\n",
    "# in_channel history layer_name, out_channel, [channels_pruned] (do not include out_channels that have been pruned)\n",
    "\n",
    "def find_missing_channel_indices(original, pruned, layer):\n",
    "    conv_layer1 = get_module_by_name(original, layer)\n",
    "    conv_layer2 = get_module_by_name(pruned, layer)\n",
    "\n",
    "    print(conv_layer1.weight.data.shape)\n",
    "    print(conv_layer2.weight.data.shape)\n",
    "\n",
    "    not_found = []\n",
    "    for channel_i in range(conv_layer1.out_channels):\n",
    "        found_match = False\n",
    "        for channel_j in range(conv_layer2.out_channels):\n",
    "            if torch.equal(conv_layer1.weight.data[channel_i], conv_layer2.weight.data[channel_j]):\n",
    "                found_match = True\n",
    "                break\n",
    "\n",
    "        if not found_match:\n",
    "            not_found.append(channel_i)\n",
    "\n",
    "    return not_found\n",
    "\n",
    "# for step in history:\n",
    "#     for name, b, channels in step:\n",
    "#         pruned_channels = find_missing_channel_indices(bigger_model, model, name[7:])\n",
    "#         print(name, len(pruned_channels), len(channels))\n",
    "\n",
    "# pruned_channels = find_missing_channel_indices(bigger_model, model, \"layer1.0.conv2\")\n",
    "# check input channels\n",
    "\n",
    "\n",
    "# layer_name = \"layer3.5.conv1\"\n",
    "out_history = get_layer_history(layer_name, history)\n",
    "print(len(out_history), out_history)\n",
    "\n",
    "# find the history of how the input channels are removed for each layer\n",
    "found = find_missing_channel_indices_input(\n",
    "    bigger_model, model, layer_name, out_history)\n",
    "len(found)\n",
    "\n",
    "# make input channel history per output channel\n",
    "\n",
    "for step in history_steps:\n",
    "    for layer_name, b, channels in step:\n",
    "        pruned_channels = find_missing_channel_indices_input(\n",
    "            bigger_model, model, layer_name, channels)\n",
    "        print(name, len(pruned_channels), len(channels))\n",
    "\n",
    "# rebuilt model with output history and input history (change needed for in channels part)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name1, param1), (name2, param2) in zip(model1.named_parameters(), model2.named_parameters()):\n",
    "        # Check if the parameter names match\n",
    "        if name1 != name2:\n",
    "            print(f\"Warning: Parameter name mismatch - {name1} != {name2}\")\n",
    "            continue\n",
    "\n",
    "        # Compare the weights\n",
    "        if torch.equal(param1.data, param2.data):\n",
    "            print(f\"Weights in layer '{name1}' are the same.\")\n",
    "        else:\n",
    "            print(f\"Weights in layer '{name1}' are different.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = \"module.layer4.0.downsample.0,2,61,93,100,108,112,143,275,311,338,468,471,583,605,619,653,695,831,839,854,892,898,991,1058,1099,1154,1257,1258,1288,1312,1427,1462,1465,1477,1542,1561,1748,1772,1827,1880,1925,1993,2040,2035,351,305,715,1727,1014,1694,327,1201,1532,570,1530,1555,167,751,1193,1736,1888,1344,1077,2046,1492,745,15,1009,449,1578,309,1906,847,1980,1850,1253,616,1929,273,1444,1156,623,1568,1592,558,2020,861,1126,560,456,794,1441,22,66,663,706,526,478,32,1868,675,660,1158,610,1508,1819,1653,929,106,1428,1262,1144,1326,497,195,1817,94,362,218,1974,968,1349,16,1693,1322,833,1051,950,1743,1900,1292,204,1570,563,1371,955,303,743,80,43,1192,734,622,801,1843,1460,1087,1496,296,808,1604,975,1510,1932,1820,158,617,301,1124,1211,1834,850,1625,1613,1971,1718,1829,7,1898,331,144,726,54,1393,427,1595,128,382,2003,307,101,1686,1645,1055,1307,194,771,868,453,688,77,1270,472,415,1440,203,1681,705,1429,909,1676,51,1680,1674,939,2042,353,974,1093,1120,412,1081,474,1692,1769,1608,486,687,1187,672,2022,685,1770,247,1357,1600,279,1003,1347,1249,1028,863,691,521,1598,895,910,1849,293,461,83,107,300,809,1699,737,1944,782,754,1167,1658,1046,207,1414,302,1301,module.layer3.0.downsample.0,962,1023,853,1018,544,657,197,486,170,412,644,303,491,18,778,91,729,501,906,151,500,980,51,60,759,444,297,194,45,741,96,1017,38,609,419,966,1011,803,16,123,390,662,923,927,685,487,514,786,83,149,511,656,590,595,118,728,825,928,482,744,407,132,881,352,732,709,873,747,388,331,541,92,536,772,105,478,365,556,647,37,475,579,610,863,801,202,340,800,329,985,619,99,71,325,205,776,47,836,766,817,665,457,326,819,93,371,601,589,620,114,706,433,199,576,701,330,748,678,716,683,4,14,900,376,543,72,311,533,module.layer2.0.downsample.0,387,246,243,404,176,412,347,34,100,11,163,24,114,98,371,424,66,96,363,53,379,43,495,361,438,326,207,509,166,311,85,33,353,188,382,473,442,309,58,328,192,372,339,60,0,131,462,184,147,279,465,72,142,10,81,285,269,177,102,381,504,447,265,483,module.layer1.0.downsample.0,144,77,108,214,150,58,112,131,103,92,156,29,235,233,31,10,36,225,231,168,63,245,68,0,196,97,218,135,78,60,21,105,module.conv1,13,42,44,52,57,11,31,59,module.layer1.0.conv2,0,1,9,14,19,22,28,59,module.layer1.0.conv1,1,7,18,20,21,23,27,33,module.layer1.1.conv2,6,17,25,41,44,38,40,45,module.layer1.1.conv1,2,4,9,13,15,19,23,30,module.layer1.2.conv2,11,4,7,57,8,24,51,43,module.layer1.2.conv1,39,49,2,11,63,19,45,52,module.layer2.0.conv2,35,119,90,3,12,29,4,69,53,120,99,51,111,110,115,38,module.layer2.0.conv1,112,92,63,89,104,68,8,14,122,61,66,2,110,12,121,86,module.layer2.1.conv2,9,10,26,29,46,54,77,93,94,100,109,120,121,112,38,126,module.layer2.1.conv1,1,3,5,14,28,29,45,56,58,63,69,76,83,102,108,111,module.layer2.2.conv2,56,29,18,39,101,75,34,86,32,2,35,12,53,96,40,97,module.layer2.2.conv1,38,63,75,112,117,120,40,12,102,6,76,88,123,107,67,124,module.layer2.3.conv2,127,124,36,76,77,17,105,67,113,0,95,19,116,107,104,21,module.layer2.3.conv1,9,74,120,6,79,49,114,4,52,23,30,37,33,105,119,127,module.layer3.0.conv2,2,4,13,54,106,141,207,221,248,250,35,157,151,194,133,152,222,247,211,115,254,111,160,116,127,126,219,136,232,192,150,210,module.layer3.0.conv1,4,18,48,89,90,136,139,148,220,245,254,134,236,92,110,178,44,225,39,79,196,135,86,160,244,1,189,235,103,197,194,253,module.layer3.1.conv2,7,8,9,16,23,24,42,56,72,74,82,88,100,108,111,123,127,130,132,133,146,155,164,191,209,213,218,221,228,229,235,238,module.layer3.1.conv1,11,13,32,41,43,50,54,73,75,76,77,79,85,92,95,97,103,122,131,142,144,149,152,162,167,172,173,181,187,188,194,201,module.layer3.2.conv2,35,79,108,117,149,196,43,157,156,166,99,190,34,47,87,241,3,240,228,17,153,14,233,250,130,112,30,182,48,81,169,131,module.layer3.2.conv1,1,20,23,29,30,47,51,56,97,99,100,105,134,153,155,161,164,167,216,242,243,62,8,0,181,148,196,208,210,59,84,52,module.layer3.3.conv2,34,35,127,148,190,247,100,146,37,82,131,197,161,157,199,43,85,124,186,71,218,76,183,169,255,38,221,217,119,149,173,231,module.layer3.3.conv1,9,19,24,31,58,59,100,114,124,180,181,189,195,214,219,240,244,254,144,128,217,213,71,41,79,188,209,252,110,81,167,73,module.layer3.4.conv2,19,41,42,53,126,144,150,169,186,242,244,252,35,116,105,50,213,79,165,212,117,222,164,174,231,84,193,16,198,67,210,86,module.layer3.4.conv1,6,10,14,20,26,48,55,60,71,73,87,100,108,110,190,204,111,168,227,76,1,240,17,21,164,122,65,19,153,49,8,104,module.layer3.5.conv2,8,38,59,91,94,105,135,142,143,183,186,203,215,221,239,219,141,77,206,137,52,224,222,227,127,53,249,163,128,85,114,0,module.layer3.5.conv1,1,3,5,10,16,29,70,84,95,112,114,133,190,200,204,220,246,249,251,250,126,55,199,166,205,81,77,203,153,254,12,105,module.layer4.0.conv2,12,25,38,46,48,61,65,72,78,84,103,111,127,130,142,143,157,160,163,171,178,192,203,231,236,238,244,266,268,269,272,284,286,290,303,306,326,365,371,378,381,383,386,388,409,422,452,461,506,511,453,499,405,342,211,22,91,319,126,267,335,50,80,253,module.layer4.0.conv1,8,10,12,15,16,18,34,53,55,124,132,143,188,191,225,230,234,251,252,254,268,280,291,304,309,312,314,316,318,326,329,338,383,388,406,410,416,420,429,431,432,436,447,454,457,467,471,483,485,487,488,510,203,426,421,433,259,0,128,105,336,114,253,394,module.layer4.1.conv2,12,18,35,36,40,46,48,51,54,57,58,60,61,63,67,73,76,78,86,87,88,91,95,96,104,116,118,119,120,128,131,134,144,148,153,155,162,163,169,170,172,175,177,178,183,185,193,194,198,202,204,205,214,223,224,229,237,248,249,251,256,258,261,263,module.layer4.1.conv1,7,9,10,12,17,19,22,25,27,29,30,31,32,35,41,44,45,46,47,51,52,54,56,58,60,61,63,64,65,68,72,73,74,75,78,80,84,86,88,93,94,96,99,100,104,105,111,114,117,118,120,122,124,126,128,133,135,139,141,142,143,145,147,151,module.layer4.2.conv2,0,7,8,11,15,26,33,37,43,46,47,54,62,70,80,84,87,92,96,99,100,125,150,155,156,158,160,166,169,171,173,176,178,183,187,188,201,213,219,235,243,245,266,270,275,277,281,283,284,294,295,302,307,308,309,315,331,333,336,337,344,348,350,353,module.layer4.2.conv1,3,5,6,7,8,14,15,18,19,24,26,29,33,34,37,38,44,46,48,49,50,54,57,59,64,65,66,69,76,77,78,79,80,87,88,89,90,91,92,93,95,98,100,102,103,105,106,108,109,110,111,112,113,114,115,117,118,120,121,125,126,127,129,135\"\n",
    "# h = h.replace(\"'\", \"\")\n",
    "\n",
    "delimiter = 'module'\n",
    "h_list = [delimiter+x for x in h.split(delimiter) if x]\n",
    "h_list\n",
    "\n",
    "\n",
    "#split names from indexes\n",
    "hl = []\n",
    "for i in h_list:\n",
    "    i = i.split(\",\", 1)\n",
    "    # print(i)\n",
    "    hl.append(i)\n",
    "\n",
    "\n",
    "def remove_values_from_list(the_list, val):\n",
    "   return [value for value in the_list if value != val]\n",
    "\n",
    "fl = []\n",
    "for name, indexes in hl:\n",
    "    s_indexes = indexes.split(\",\")\n",
    "    s_indexes = remove_values_from_list(s_indexes, \"\")\n",
    "    n_indexes = [int(i) for i in s_indexes]\n",
    "    indexes = n_indexes\n",
    "\n",
    "for name, indexes in hl:\n",
    "    print(name, indexes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
