{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\35679\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\35679\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning sparsity: 0\n",
      "Pruning step: 1 multiply–accumulate (macs): 4121925096.0 number of parameters 25557032\n",
      "Pruning step: 2 multiply–accumulate (macs): 4121925096.0 number of parameters 25557032\n",
      "Pruning step: 3 multiply–accumulate (macs): 4121925096.0 number of parameters 25557032\n",
      "Pruning step: 4 multiply–accumulate (macs): 4121925096.0 number of parameters 25557032\n",
      "Pruning step: 5 multiply–accumulate (macs): 4121925096.0 number of parameters 25557032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\35679\\anaconda3\\lib\\site-packages\\torchinfo\\torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "c:\\Users\\35679\\anaconda3\\lib\\site-packages\\torch\\storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n",
      "Pruning sparsity: 0.0625\n",
      "layer4.0.downsample.0 [1094, 351, 2, 1748, 1292, 275, 1154, 695, 1727, 1349, 167, 617, 12, 619, 218, 143, 1561, 80, 899, 1288, 311, 1904, 605, 108, 456, 1993]\n",
      "layer3.0.downsample.0 [962, 1018, 486, 1023, 853, 657, 303, 501, 91, 170, 197, 544, 491]\n",
      "layer2.0.downsample.0 [387, 246, 176, 243, 404, 34, 53]\n",
      "layer1.0.downsample.0 [144, 77, 108, 214]\n",
      "conv1 [13]\n",
      "layer1.0.conv2 [0]\n",
      "layer1.0.conv1 [38]\n",
      "layer1.1.conv2 [17]\n",
      "layer1.1.conv1 [42]\n",
      "layer1.2.conv2 [11]\n",
      "layer1.2.conv1 [2]\n",
      "layer2.0.conv2 [35, 29]\n",
      "layer2.0.conv1 [112, 92]\n",
      "layer2.1.conv2 [10, 93]\n",
      "layer2.1.conv1 [5, 1]\n",
      "layer2.2.conv2 [29, 56]\n",
      "layer2.2.conv1 [120, 117]\n",
      "layer2.3.conv2 [127, 124]\n",
      "layer2.3.conv1 [9, 6]\n",
      "layer3.0.conv2 [106, 141, 151, 13]\n",
      "layer3.0.conv1 [4, 48, 139, 148]\n",
      "layer3.1.conv2 [123, 72, 213, 155]\n",
      "layer3.1.conv1 [229, 88, 85, 172]\n",
      "layer3.2.conv2 [196, 35, 79, 149]\n",
      "layer3.2.conv1 [47, 71, 181, 210]\n",
      "layer3.3.conv2 [190, 35, 148, 127]\n",
      "layer3.3.conv1 [124, 217, 214, 31]\n",
      "layer3.4.conv2 [242, 252, 50, 126]\n",
      "layer3.4.conv1 [26, 204, 6, 8]\n",
      "layer3.5.conv2 [186, 94, 203, 77]\n",
      "layer3.5.conv1 [84, 1, 199, 3]\n",
      "layer4.0.conv2 [461, 78, 286, 454, 244, 371, 326]\n",
      "layer4.0.conv1 [0, 55, 426, 143, 253, 254, 34]\n",
      "layer4.1.conv2 [128, 352, 111, 351, 4, 428, 426]\n",
      "layer4.1.conv1 [348, 390, 200, 369, 202, 203, 204]\n",
      "layer4.2.conv2 [0, 105, 92, 508, 507, 99, 426]\n",
      "layer4.2.conv1 [64, 255, 507, 506, 505, 5, 6]\n",
      "Pruning step: 1 multiply–accumulate (macs): 4003375446.0 number of parameters 24882554\n",
      "layer4.0.downsample.0 [1183, 1306, 457, 329, 90, 649, 1035, 975, 1042, 97, 661, 1109, 108, 1127, 1509, 1570, 1456, 1235, 2020, 1082, 1521, 1735, 301, 318, 952, 552]\n",
      "layer3.0.downsample.0 [18, 750, 408, 494, 45, 95, 636, 720, 700, 150, 60, 863, 969]\n",
      "layer2.0.downsample.0 [342, 161, 405, 11, 98, 24]\n",
      "layer1.0.downsample.0 [147, 58, 221]\n",
      "conv1 [41]\n",
      "layer1.0.conv2 [0]\n",
      "layer1.0.conv1 [7]\n",
      "layer1.1.conv2 [43]\n",
      "layer1.1.conv1 [2]\n",
      "layer1.2.conv2 [7]\n",
      "layer1.2.conv1 [38]\n",
      "layer2.0.conv2 [49, 88]\n",
      "layer2.0.conv1 [63, 89]\n",
      "layer2.1.conv2 [92, 28]\n",
      "layer2.1.conv1 [2, 74]\n",
      "layer2.2.conv2 [38, 18]\n",
      "layer2.2.conv1 [75, 38]\n",
      "layer2.3.conv2 [67, 17]\n",
      "layer2.3.conv1 [35, 72]\n",
      "layer3.0.conv2 [114, 53, 34]\n",
      "layer3.0.conv1 [88, 87, 250]\n",
      "layer3.1.conv2 [185, 125, 128]\n",
      "layer3.1.conv1 [13, 178, 150]\n",
      "layer3.2.conv2 [106, 154, 17]\n",
      "layer3.2.conv1 [30, 103, 208]\n",
      "layer3.3.conv2 [144, 75, 34]\n",
      "layer3.3.conv1 [58, 179, 9]\n",
      "layer3.4.conv2 [52, 142, 241]\n",
      "layer3.4.conv1 [97, 161, 187]\n",
      "layer3.5.conv2 [217, 59, 141]\n",
      "layer3.5.conv1 [200, 196, 3]\n",
      "layer4.0.conv2 [126, 291, 282, 237, 331, 61]\n",
      "layer4.0.conv1 [14, 377, 51, 332, 129, 185]\n",
      "layer4.1.conv2 [221, 116, 435, 117, 432, 417]\n",
      "layer4.1.conv1 [336, 370, 176, 198, 368, 402]\n",
      "layer4.2.conv2 [52, 497, 377, 86, 380, 154]\n",
      "layer4.2.conv1 [63, 205, 447, 449, 208, 5]\n",
      "Pruning step: 2 multiply–accumulate (macs): 3899629676.0 number of parameters 24296793\n",
      "layer4.0.downsample.0 [1304, 1948, 20, 1221, 145, 1549, 1930, 1450, 720, 1573, 1856, 1839, 1599, 1220, 1696, 1875, 1121, 814, 542, 89, 296, 1468, 829, 1026, 836]\n",
      "layer3.0.downsample.0 [993, 884, 722, 434, 575, 943, 668, 37, 49, 80, 594, 905, 316]\n",
      "layer2.0.downsample.0 [62, 109, 425, 361, 31, 411, 177]\n",
      "layer1.0.downsample.0 [128, 226, 29]\n",
      "conv1 [42]\n",
      "layer1.0.conv2 [7]\n",
      "layer1.0.conv1 [19]\n",
      "layer1.1.conv2 [24]\n",
      "layer1.1.conv1 [14]\n",
      "layer1.2.conv2 [4]\n",
      "layer1.2.conv1 [47]\n",
      "layer2.0.conv2 [66]\n",
      "layer2.0.conv1 [101]\n",
      "layer2.1.conv2 [96]\n",
      "layer2.1.conv1 [56]\n",
      "layer2.2.conv2 [97]\n",
      "layer2.2.conv1 [62]\n",
      "layer2.3.conv2 [0]\n",
      "layer2.3.conv1 [75]\n",
      "layer3.0.conv2 [241, 243, 128]\n",
      "layer3.0.conv1 [214, 239, 17]\n",
      "layer3.1.conv2 [24, 211, 84]\n",
      "layer3.1.conv1 [240, 40, 219]\n",
      "layer3.2.conv2 [41, 113, 45]\n",
      "layer3.2.conv1 [23, 54, 163]\n",
      "layer3.3.conv2 [127, 229, 79]\n",
      "layer3.3.conv1 [190, 247, 97]\n",
      "layer3.4.conv2 [41, 19, 42]\n",
      "layer3.4.conv1 [84, 70, 106]\n",
      "layer3.5.conv2 [132, 213, 139]\n",
      "layer3.5.conv1 [242, 244, 108]\n",
      "layer4.0.conv2 [89, 267, 375, 264, 372, 175, 35]\n",
      "layer4.0.conv1 [416, 423, 258, 299, 119, 304, 444]\n",
      "layer4.1.conv2 [62, 323, 325, 204, 327, 189, 188]\n",
      "layer4.1.conv1 [124, 177, 482, 478, 477, 178, 472]\n",
      "layer4.2.conv2 [60, 180, 144, 228, 343, 259, 6]\n",
      "layer4.2.conv1 [124, 426, 430, 432, 200, 435, 202]\n",
      "Pruning step: 3 multiply–accumulate (macs): 3804591863.0 number of parameters 23695182\n",
      "layer4.0.downsample.0 [1856, 435, 1017, 626, 561, 1964, 58, 14, 1389, 894, 977, 1774, 1112, 920, 509, 1372, 698, 1867, 1944, 1146, 195, 1811, 1760, 429, 559, 228]\n",
      "layer3.0.downsample.0 [471, 299, 633, 891, 16, 716, 676, 375, 377, 774, 184, 975, 702]\n",
      "layer2.0.downsample.0 [92, 475, 39, 0, 364, 157]\n",
      "layer1.0.downsample.0 [225, 149, 30]\n",
      "conv1 [49]\n",
      "layer1.0.conv2 [11]\n",
      "layer1.0.conv1 [19]\n",
      "layer1.1.conv2 [36]\n",
      "layer1.1.conv1 [42]\n",
      "layer1.2.conv2 [21]\n",
      "layer1.2.conv1 [43]\n",
      "layer2.0.conv2 [114, 4]\n",
      "layer2.0.conv1 [8, 67]\n",
      "layer2.1.conv2 [25, 116]\n",
      "layer2.1.conv1 [11, 26]\n",
      "layer2.2.conv2 [32, 71]\n",
      "layer2.2.conv1 [109, 85]\n",
      "layer2.3.conv2 [34, 73]\n",
      "layer2.3.conv1 [49, 115]\n",
      "layer3.0.conv2 [199, 152, 2]\n",
      "layer3.0.conv1 [131, 189, 105]\n",
      "layer3.1.conv2 [85, 127, 126]\n",
      "layer3.1.conv1 [140, 41, 146]\n",
      "layer3.2.conv2 [94, 223, 181]\n",
      "layer3.2.conv1 [23, 142, 128]\n",
      "layer3.3.conv2 [161, 149, 26]\n",
      "layer3.3.conv1 [72, 210, 183]\n",
      "layer3.4.conv2 [143, 100, 34]\n",
      "layer3.4.conv1 [102, 52, 94]\n",
      "layer3.5.conv2 [198, 38, 172]\n",
      "layer3.5.conv1 [7, 148, 185]\n",
      "layer4.0.conv2 [365, 63, 186, 370, 81, 245]\n",
      "layer4.0.conv1 [122, 322, 467, 468, 7, 9]\n",
      "layer4.1.conv2 [35, 281, 282, 179, 455, 177]\n",
      "layer4.1.conv1 [122, 487, 486, 172, 479, 478]\n",
      "layer4.2.conv2 [30, 323, 257, 409, 262, 156]\n",
      "layer4.2.conv1 [122, 317, 207, 208, 209, 192]\n",
      "Pruning step: 4 multiply–accumulate (macs): 3703461272.0 number of parameters 23123597\n",
      "layer4.0.downsample.0 [1618, 529, 709, 1642, 1488, 791, 587, 623, 1731, 1238, 1498, 1861, 309, 1368, 1778, 1015, 666, 1844, 1518, 1195, 97, 181, 287, 534, 1634]\n",
      "layer3.0.downsample.0 [114, 568, 739, 140, 883, 489, 925, 181, 728, 696, 96, 631]\n",
      "layer2.0.downsample.0 [192, 136, 322, 483, 88, 309]\n",
      "layer1.0.downsample.0 [99, 10, 220]\n",
      "layer2.0.conv2 [3]\n",
      "layer2.0.conv1 [2]\n",
      "layer2.1.conv2 [74]\n",
      "layer2.1.conv1 [63]\n",
      "layer2.2.conv2 [21]\n",
      "layer2.2.conv1 [12]\n",
      "layer2.3.conv2 [100]\n",
      "layer2.3.conv1 [46]\n",
      "layer3.0.conv2 [210, 3, 148]\n",
      "layer3.0.conv1 [214, 233, 98]\n",
      "layer3.1.conv2 [225, 208, 180]\n",
      "layer3.1.conv1 [76, 62, 70]\n",
      "layer3.2.conv2 [77, 82, 232]\n",
      "layer3.2.conv1 [144, 146, 27]\n",
      "layer3.3.conv2 [234, 205, 187]\n",
      "layer3.3.conv1 [228, 23, 232]\n",
      "layer3.4.conv2 [109, 176, 18]\n",
      "layer3.4.conv1 [154, 56, 112]\n",
      "layer3.5.conv2 [132, 175, 123]\n",
      "layer3.5.conv1 [235, 66, 77]\n",
      "layer4.0.conv2 [398, 274, 397, 207, 47, 12]\n",
      "layer4.0.conv1 [12, 484, 447, 409, 245, 443]\n",
      "layer4.1.conv2 [120, 85, 202, 155, 284, 156]\n",
      "layer4.1.conv1 [60, 145, 251, 483, 482, 149]\n",
      "layer4.2.conv2 [417, 157, 65, 267, 446, 373]\n",
      "layer4.2.conv1 [250, 301, 233, 234, 288, 236]\n",
      "Pruning step: 5 multiply–accumulate (macs): 3631739080.0 number of parameters 22586020\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 60, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(60, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(60, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(60, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(60, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(60, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(240, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(120, 120, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(240, 480, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(480, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(480, 960, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(960, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(480, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(480, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(960, 1920, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1920, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(480, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1920, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(480, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=1920, out_features=1000, bias=True)\n",
      ")\n",
      "Pruning sparsity: 0.125\n",
      "layer4.0.downsample.0 [1051, 275, 950, 93, 1542, 898, 1925, 338, 112, 1561, 1748, 468, 955, 218, 1288, 675, 892, 854, 1530, 167, 286, 1993, 831, 1978, 605, 143, 739, 100, 1326, 881, 1158, 61, 1464, 1058, 1759, 108, 1077, 1144, 1193, 415, 327, 1645, 794, 1055, 1201, 653, 311, 790, 1492, 839, 148, 1154]\n",
      "layer3.0.downsample.0 [412, 853, 486, 962, 1018, 1023, 544, 803, 657, 491, 170, 91, 741, 303, 444, 500, 45, 873, 595, 96, 197, 501, 51, 60, 644, 729]\n",
      "layer2.0.downsample.0 [387, 412, 246, 176, 243, 347, 100, 34, 163, 404, 24, 424, 114]\n",
      "layer1.0.downsample.0 [144, 77, 214, 108, 150, 58, 131]\n",
      "conv1 [13, 44]\n",
      "layer1.0.conv2 [0, 1]\n",
      "layer1.0.conv1 [60, 1]\n",
      "layer1.1.conv2 [6, 17]\n",
      "layer1.1.conv1 [56, 43]\n",
      "layer1.2.conv2 [11, 7]\n",
      "layer1.2.conv1 [39, 2]\n",
      "layer2.0.conv2 [35, 119, 110, 90]\n",
      "layer2.0.conv1 [89, 112, 92, 63]\n",
      "layer2.1.conv2 [10, 93, 29, 9]\n",
      "layer2.1.conv1 [14, 1, 83, 3]\n",
      "layer2.2.conv2 [29, 56, 34, 18]\n",
      "layer2.2.conv1 [63, 38, 40, 120]\n",
      "layer2.3.conv2 [127, 36, 124, 76]\n",
      "layer2.3.conv1 [74, 9, 120, 6]\n",
      "layer3.0.conv2 [127, 2, 4, 250, 248, 141, 54]\n",
      "layer3.0.conv1 [136, 220, 139, 148, 48, 245, 90]\n",
      "layer3.1.conv2 [16, 123, 250, 132, 133, 88, 24]\n",
      "layer3.1.conv1 [32, 181, 41, 244, 88, 173, 172]\n",
      "layer3.2.conv2 [35, 117, 79, 196, 43, 108, 166]\n",
      "layer3.2.conv1 [20, 97, 99, 23, 105, 24, 161]\n",
      "layer3.3.conv2 [190, 148, 35, 131, 247, 34, 37]\n",
      "layer3.3.conv1 [195, 189, 71, 59, 211, 100, 180]\n",
      "layer3.4.conv2 [244, 126, 105, 53, 242, 144, 252]\n",
      "layer3.4.conv1 [20, 73, 48, 6, 10, 227, 204]\n",
      "layer3.5.conv2 [203, 206, 59, 105, 94, 143, 221]\n",
      "layer3.5.conv1 [1, 126, 3, 249, 5, 251, 246]\n",
      "layer4.0.conv2 [12, 203, 371, 340, 238, 91, 326, 143, 111, 178, 130, 163, 35]\n",
      "layer4.0.conv1 [483, 314, 316, 488, 107, 487, 318, 326, 8, 431, 10, 268, 12]\n",
      "layer4.1.conv2 [437, 118, 2, 104, 493, 370, 369, 461, 480, 459, 475, 458, 12]\n",
      "layer4.1.conv1 [31, 315, 217, 264, 263, 314, 222, 7, 309, 9, 10, 11, 255]\n",
      "layer4.2.conv2 [0, 160, 166, 169, 431, 171, 6, 7, 8, 87, 270, 11, 426]\n",
      "layer4.2.conv1 [64, 411, 412, 3, 447, 5, 6, 7, 415, 382, 417, 418, 422]\n",
      "Pruning step: 1 multiply–accumulate (macs): 3899629676.0 number of parameters 24296793\n",
      "layer4.0.downsample.0 [938, 1908, 1929, 1882, 984, 731, 1857, 1546, 709, 1522, 1988, 1819, 1386, 602, 1573, 823, 1308, 696, 455, 786, 187, 547, 1770, 401, 1120, 1252, 296, 676, 1558, 1947, 1696, 1721, 1467, 1303, 1267, 146, 1223, 865, 836, 1403, 79, 1090, 32, 1794, 1839, 337, 606, 1024, 292, 1801, 323]\n",
      "layer3.0.downsample.0 [739, 900, 38, 956, 883, 16, 18, 188, 575, 758, 667, 476, 987, 710, 747, 942, 948, 691, 993, 522, 118, 766, 146, 80, 94, 639]\n",
      "layer2.0.downsample.0 [96, 11, 354, 64, 362, 51, 201, 41, 482, 94, 303, 32, 352]\n",
      "layer1.0.downsample.0 [101, 109, 29, 62, 228, 150]\n",
      "conv1 [41, 50]\n",
      "layer1.0.conv2 [7, 59]\n",
      "layer1.0.conv1 [41, 55]\n",
      "layer1.1.conv2 [36, 43]\n",
      "layer1.1.conv1 [7, 4]\n",
      "layer1.2.conv2 [55, 22]\n",
      "layer1.2.conv1 [47, 43]\n",
      "layer2.0.conv2 [29, 68, 4]\n",
      "layer2.0.conv1 [8, 101, 67]\n",
      "layer2.1.conv2 [96, 51, 43]\n",
      "layer2.1.conv1 [60, 3, 73]\n",
      "layer2.2.conv2 [36, 71, 97]\n",
      "layer2.2.conv1 [109, 114, 72]\n",
      "layer2.3.conv2 [17, 0, 75]\n",
      "layer2.3.conv1 [4, 21, 50]\n",
      "layer3.0.conv2 [103, 152, 129, 113, 147, 202]\n",
      "layer3.0.conv1 [230, 88, 101, 247, 18, 219]\n",
      "layer3.1.conv2 [223, 80, 70, 54, 7, 8]\n",
      "layer3.1.conv1 [216, 225, 71, 223, 181, 141]\n",
      "layer3.2.conv2 [54, 152, 45, 144, 184, 14]\n",
      "layer3.2.conv1 [149, 147, 142, 95, 203, 157]\n",
      "layer3.3.conv2 [124, 152, 142, 212, 97, 193]\n",
      "layer3.3.conv1 [31, 141, 40, 24, 41, 247]\n",
      "layer3.4.conv2 [41, 42, 206, 50, 114, 78]\n",
      "layer3.4.conv1 [185, 95, 23, 105, 37, 94]\n",
      "layer3.5.conv2 [241, 139, 90, 213, 182, 76]\n",
      "layer3.5.conv1 [186, 78, 195, 7, 196, 13]\n",
      "layer4.0.conv2 [222, 258, 76, 59, 368, 154, 259, 151, 370, 149, 375, 353, 234]\n",
      "layer4.0.conv1 [31, 139, 420, 497, 304, 120, 12, 13, 52, 50, 447, 457, 128]\n",
      "layer4.1.conv2 [313, 86, 198, 244, 245, 200, 201, 416, 89, 254, 420, 422, 130]\n",
      "layer4.1.conv1 [88, 349, 494, 477, 472, 345, 344, 471, 465, 464, 462, 461, 459]\n",
      "layer4.2.conv2 [298, 297, 373, 266, 203, 450, 296, 75, 456, 465, 10, 473, 86]\n",
      "layer4.2.conv1 [124, 388, 247, 248, 390, 392, 398, 401, 374, 9, 10, 11, 12]\n",
      "Pruning step: 2 multiply–accumulate (macs): 3703461272.0 number of parameters 23123597\n",
      "layer4.0.downsample.0 [192, 1067, 452, 1013, 136, 16, 1386, 1161, 1035, 1402, 1817, 1849, 1420, 1787, 1641, 1513, 629, 425, 222, 850, 1739, 632, 1918, 286, 1833, 1844, 923, 289, 538, 1029, 312, 1156, 1943, 1876, 1041, 582, 281, 699, 1856, 1340, 322, 423, 1204, 1875, 11, 1518, 340, 500, 360, 1299, 1303]\n",
      "layer3.0.downsample.0 [391, 593, 619, 684, 374, 491, 709, 84, 582, 712, 309, 735, 372, 912, 883, 179, 488, 402, 95, 460, 739, 336, 282, 313, 121]\n",
      "layer2.0.downsample.0 [154, 358, 175, 0, 413, 483, 322, 136, 74, 78, 122, 417, 79]\n",
      "layer1.0.downsample.0 [10, 88, 30, 35, 219, 185, 221]\n",
      "conv1 [53]\n",
      "layer1.0.conv2 [16]\n",
      "layer1.0.conv1 [20]\n",
      "layer1.1.conv2 [23]\n",
      "layer1.1.conv1 [7]\n",
      "layer1.2.conv2 [48]\n",
      "layer1.2.conv1 [10]\n",
      "layer2.0.conv2 [3, 48, 94]\n",
      "layer2.0.conv1 [104, 64, 115]\n",
      "layer2.1.conv2 [24, 114, 113]\n",
      "layer2.1.conv1 [105, 95, 101]\n",
      "layer2.2.conv2 [2, 12, 39]\n",
      "layer2.2.conv1 [12, 84, 98]\n",
      "layer2.3.conv2 [101, 106, 39]\n",
      "layer2.3.conv1 [33, 73, 26]\n",
      "layer3.0.conv2 [143, 111, 11, 211, 33, 221, 142]\n",
      "layer3.0.conv1 [233, 120, 4, 152, 199, 1, 38]\n",
      "layer3.1.conv2 [20, 180, 223, 217, 118, 38, 103]\n",
      "layer3.1.conv1 [74, 118, 93, 138, 144, 72, 63]\n",
      "layer3.2.conv2 [220, 93, 16, 29, 68, 147, 221]\n",
      "layer3.2.conv1 [26, 127, 44, 27, 53, 48, 1]\n",
      "layer3.3.conv2 [224, 206, 40, 25, 115, 26, 68]\n",
      "layer3.3.conv1 [207, 117, 73, 172, 9, 205, 228]\n",
      "layer3.4.conv2 [160, 35, 177, 20, 19, 141, 156]\n",
      "layer3.4.conv1 [99, 49, 43, 7, 65, 112, 18]\n",
      "layer3.5.conv2 [205, 171, 52, 210, 122, 198, 176]\n",
      "layer3.5.conv1 [108, 194, 65, 24, 78, 106, 193]\n",
      "layer4.0.conv2 [435, 361, 62, 46, 253, 355, 265, 485, 179, 480, 315, 221, 383]\n",
      "layer4.0.conv1 [392, 365, 408, 449, 217, 388, 320, 222, 416, 291, 403, 376, 191]\n",
      "layer4.1.conv2 [171, 300, 264, 334, 73, 336, 74, 267, 434, 114, 428, 204, 178]\n",
      "layer4.1.conv1 [60, 163, 337, 347, 348, 167, 168, 352, 170, 353, 357, 173, 358]\n",
      "layer4.2.conv2 [374, 329, 149, 343, 312, 340, 96, 188, 279, 91, 165, 90, 419]\n",
      "layer4.2.conv1 [60, 345, 344, 343, 235, 342, 460, 227, 226, 341, 225, 11, 224]\n",
      "Pruning step: 3 multiply–accumulate (macs): 3520505718.0 number of parameters 21952302\n",
      "layer4.0.downsample.0 [1218, 1101, 1762, 575, 1491, 786, 1403, 1567, 1844, 1733, 1410, 647, 62, 1332, 434, 100, 1688, 653, 51, 635, 95, 633, 1334, 1641, 361, 891, 1486, 1154, 672, 439, 432, 445, 1568, 771, 1076, 1158, 1322, 191, 713, 639, 180, 1478, 1594, 1308, 1569, 273, 826, 1561, 1254, 1552, 952]\n",
      "layer3.0.downsample.0 [438, 237, 290, 460, 135, 679, 576, 404, 614, 738, 860, 317, 559, 762, 773, 567, 445, 84, 186, 516, 549, 389, 816, 289, 341, 652]\n",
      "layer2.0.downsample.0 [342, 53, 123, 303, 285, 301, 261, 132, 351, 448, 171, 428, 116]\n",
      "layer1.0.downsample.0 [208, 63, 0, 62, 89, 201]\n",
      "conv1 [30, 11]\n",
      "layer1.0.conv2 [18, 24]\n",
      "layer1.0.conv1 [19, 43]\n",
      "layer1.1.conv2 [40, 37]\n",
      "layer1.1.conv1 [16, 27]\n",
      "layer1.2.conv2 [4, 5]\n",
      "layer1.2.conv1 [47, 58]\n",
      "layer2.0.conv2 [48, 49, 56]\n",
      "layer2.0.conv1 [60, 11, 13]\n",
      "layer2.1.conv2 [101, 34, 116]\n",
      "layer2.1.conv1 [54, 52, 64]\n",
      "layer2.2.conv2 [30, 77, 46]\n",
      "layer2.2.conv1 [71, 6, 114]\n",
      "layer2.3.conv2 [53, 63, 101]\n",
      "layer2.3.conv1 [105, 96, 110]\n",
      "layer3.0.conv2 [205, 177, 179, 195, 105, 145]\n",
      "layer3.0.conv1 [117, 176, 165, 40, 102, 85]\n",
      "layer3.1.conv2 [131, 227, 90, 205, 193, 149]\n",
      "layer3.1.conv1 [13, 73, 205, 178, 172, 52]\n",
      "layer3.2.conv2 [27, 225, 73, 42, 72, 160]\n",
      "layer3.2.conv1 [222, 177, 196, 74, 7, 223]\n",
      "layer3.3.conv2 [75, 115, 182, 191, 203, 172]\n",
      "layer3.3.conv1 [198, 18, 73, 194, 197, 156]\n",
      "layer3.4.conv2 [137, 151, 196, 191, 205, 200]\n",
      "layer3.4.conv1 [147, 220, 174, 22, 222, 1]\n",
      "layer3.5.conv2 [0, 220, 79, 128, 205, 130]\n",
      "layer3.5.conv1 [42, 231, 176, 152, 120, 162]\n",
      "layer4.0.conv2 [418, 232, 385, 57, 119, 118, 50, 365, 250, 269, 74, 213, 294]\n",
      "layer4.0.conv1 [314, 206, 118, 326, 294, 244, 238, 413, 86, 103, 463, 217, 462]\n",
      "layer4.1.conv2 [46, 167, 145, 143, 58, 162, 138, 74, 16, 249, 248, 160, 134]\n",
      "layer4.1.conv1 [78, 469, 346, 170, 461, 460, 459, 458, 457, 456, 154, 441, 440]\n",
      "layer4.2.conv2 [338, 64, 302, 310, 336, 470, 113, 259, 56, 48, 351, 354, 468]\n",
      "layer4.2.conv1 [336, 379, 378, 377, 247, 205, 206, 209, 244, 212, 213, 215, 217]\n",
      "Pruning step: 4 multiply–accumulate (macs): 3334201847.0 number of parameters 20837770\n",
      "layer4.0.downsample.0 [1257, 635, 1628, 1626, 1642, 1067, 106, 1819, 76, 1686, 314, 1297, 1173, 447, 7, 1494, 935, 945, 407, 1772, 825, 1160, 1669, 154, 1092, 1704, 1215, 1605, 1627, 816, 618, 1401, 115, 1515, 780, 1050, 775, 223, 759, 904, 108, 1091, 650, 522, 611, 779, 621, 197, 286, 1785, 370]\n",
      "layer3.0.downsample.0 [616, 775, 27, 113, 671, 66, 740, 611, 72, 19, 489, 414, 528, 483, 831, 832, 522, 525, 717, 301, 338, 839, 105, 292, 14]\n",
      "layer2.0.downsample.0 [9, 317, 277, 51, 153, 225, 399, 424, 342, 160, 444, 453]\n",
      "layer1.0.downsample.0 [219, 54, 119, 12, 105, 19]\n",
      "conv1 [51]\n",
      "layer1.0.conv2 [54]\n",
      "layer1.0.conv1 [41]\n",
      "layer1.1.conv2 [27]\n",
      "layer1.1.conv1 [33]\n",
      "layer1.2.conv2 [34]\n",
      "layer1.2.conv1 [17]\n",
      "layer2.0.conv2 [107, 36, 103]\n",
      "layer2.0.conv1 [2, 58, 108]\n",
      "layer2.1.conv2 [86, 26, 70]\n",
      "layer2.1.conv1 [24, 25, 99]\n",
      "layer2.2.conv2 [84, 16, 78]\n",
      "layer2.2.conv1 [42, 101, 62]\n",
      "layer2.3.conv2 [97, 87, 17]\n",
      "layer2.3.conv1 [43, 94, 61]\n",
      "layer3.0.conv2 [228, 180, 198, 77, 117, 223]\n",
      "layer3.0.conv1 [155, 107, 16, 175, 122, 215]\n",
      "layer3.1.conv2 [97, 66, 116, 138, 7, 214]\n",
      "layer3.1.conv1 [69, 82, 195, 190, 150, 202]\n",
      "layer3.2.conv2 [123, 136, 224, 179, 115, 97]\n",
      "layer3.2.conv1 [189, 7, 160, 146, 84, 49]\n",
      "layer3.3.conv2 [184, 167, 33, 77, 145, 190]\n",
      "layer3.3.conv1 [67, 103, 189, 116, 29, 89]\n",
      "layer3.4.conv2 [18, 175, 184, 208, 113, 218]\n",
      "layer3.4.conv1 [15, 174, 5, 6, 36, 48]\n",
      "layer3.5.conv2 [7, 200, 223, 130, 37, 139]\n",
      "layer3.5.conv1 [151, 17, 183, 139, 95, 66]\n",
      "layer4.0.conv2 [269, 442, 253, 316, 338, 93, 158, 404, 372, 75, 272, 14]\n",
      "layer4.0.conv1 [232, 212, 298, 0, 457, 208, 199, 42, 218, 19, 277, 438]\n",
      "layer4.1.conv2 [381, 295, 43, 105, 144, 398, 62, 395, 363, 197, 54, 196]\n",
      "layer4.1.conv1 [114, 380, 219, 378, 224, 375, 372, 229, 382, 216, 366, 214]\n",
      "layer4.2.conv2 [300, 155, 219, 41, 267, 256, 257, 84, 195, 318, 395, 152]\n",
      "layer4.2.conv1 [270, 267, 193, 194, 195, 196, 266, 264, 199, 262, 201, 202]\n",
      "Pruning step: 5 multiply–accumulate (macs): 3172561832.0 number of parameters 19798176\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 56, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(56, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(224, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(224, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(224, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(224, 448, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(448, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(448, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(448, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(448, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(224, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(448, 896, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(896, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(224, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(896, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(224, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(896, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(224, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(896, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(224, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(896, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(224, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(896, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(448, 448, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(896, 1792, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1792, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1792, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=1792, out_features=1000, bias=True)\n",
      ")\n",
      "Pruning sparsity: 0.1875\n",
      "layer4.0.downsample.0 [955, 854, 2, 605, 1542, 218, 93, 351, 695, 167, 1827, 1748, 12, 675, 80, 1694, 1993, 1592, 100, 653, 275, 1880, 1561, 1968, 1058, 1051, 143, 991, 311, 898, 327, 892, 1154, 112, 338, 1326, 108, 1530, 831, 1477, 455, 1492, 1126, 309, 997, 1257, 456, 1144, 1464, 1906, 1253, 1736, 1460, 1946, 745, 1999, 416, 1427, 583, 751, 968, 2040, 1201, 2046, 1898, 1743, 1532, 16, 794, 153, 1077, 663, 1925, 563, 570, 1555, 1726]\n",
      "layer3.0.downsample.0 [962, 197, 1018, 853, 1023, 486, 170, 501, 544, 778, 803, 906, 759, 500, 657, 644, 96, 491, 595, 303, 412, 91, 151, 709, 194, 729, 45, 18, 60, 419, 980, 38, 83, 105, 741, 685, 123, 701, 51]\n",
      "layer2.0.downsample.0 [387, 404, 412, 176, 243, 246, 347, 163, 100, 34, 11, 24, 114, 424, 98, 207, 66, 372, 43, 53]\n",
      "layer1.0.downsample.0 [144, 77, 108, 214, 150, 112, 58, 103, 131, 29]\n",
      "conv1 [13, 44, 42]\n",
      "layer1.0.conv2 [0, 1, 19]\n",
      "layer1.0.conv1 [60, 1, 58]\n",
      "layer1.1.conv2 [41, 25, 6]\n",
      "layer1.1.conv1 [42, 23, 2]\n",
      "layer1.2.conv2 [11, 7, 57]\n",
      "layer1.2.conv1 [2, 49, 39]\n",
      "layer2.0.conv2 [35, 29, 90, 119, 110]\n",
      "layer2.0.conv1 [112, 92, 89, 104, 63]\n",
      "layer2.1.conv2 [93, 54, 29, 100, 26]\n",
      "layer2.1.conv1 [5, 1, 58, 3, 28]\n",
      "layer2.2.conv2 [29, 56, 18, 34, 75]\n",
      "layer2.2.conv1 [38, 117, 63, 112, 120]\n",
      "layer2.3.conv2 [127, 17, 124, 0, 36]\n",
      "layer2.3.conv1 [9, 6, 120, 74, 49]\n",
      "layer3.0.conv2 [2, 4, 207, 116, 250, 141, 13, 248, 106, 133]\n",
      "layer3.0.conv1 [90, 89, 220, 245, 139, 18, 148, 48, 136, 254]\n",
      "layer3.1.conv2 [127, 155, 132, 133, 88, 123, 228, 7, 8, 9]\n",
      "layer3.1.conv1 [142, 129, 194, 199, 75, 65, 211, 95, 122, 249]\n",
      "layer3.2.conv2 [196, 117, 79, 35, 149, 108, 43, 157, 17, 190]\n",
      "layer3.2.conv1 [56, 167, 164, 100, 51, 155, 99, 161, 148, 210]\n",
      "layer3.3.conv2 [146, 148, 190, 35, 127, 131, 247, 34, 100, 197]\n",
      "layer3.3.conv1 [189, 144, 31, 158, 100, 58, 59, 79, 99, 9]\n",
      "layer3.4.conv2 [19, 244, 242, 169, 144, 126, 105, 53, 116, 252]\n",
      "layer3.4.conv1 [26, 1, 190, 55, 48, 164, 10, 242, 204, 110]\n",
      "layer3.5.conv2 [0, 94, 143, 239, 77, 142, 203, 206, 8, 186]\n",
      "layer3.5.conv1 [29, 203, 112, 199, 197, 5, 153, 246, 174, 70]\n",
      "layer4.0.conv2 [290, 87, 461, 84, 111, 286, 35, 452, 421, 284, 203, 78, 12, 91, 272, 238, 269, 236, 126, 268]\n",
      "layer4.0.conv1 [416, 338, 316, 312, 457, 485, 406, 487, 8, 488, 10, 143, 12, 53, 500, 15, 16, 510, 336, 410]\n",
      "layer4.1.conv2 [128, 454, 2, 448, 205, 505, 202, 442, 294, 439, 469, 195, 12, 331, 437, 194, 193, 428, 18, 426]\n",
      "layer4.1.conv1 [128, 365, 200, 364, 202, 203, 204, 7, 362, 9, 10, 206, 207, 360, 358, 210, 211, 17, 357, 19]\n",
      "layer4.2.conv2 [0, 99, 381, 469, 384, 385, 307, 80, 8, 308, 417, 11, 463, 419, 328, 15, 331, 333, 277, 188]\n",
      "layer4.2.conv1 [64, 254, 255, 248, 510, 5, 6, 7, 507, 506, 505, 504, 502, 249, 14, 15, 499, 498, 18, 19]\n",
      "Pruning step: 1 multiply–accumulate (macs): 3804591863.0 number of parameters 23695182\n",
      "layer4.0.downsample.0 [806, 1508, 1294, 294, 1558, 1393, 1147, 476, 428, 1243, 863, 974, 1753, 1762, 447, 1564, 292, 1708, 1110, 800, 100, 598, 1858, 1534, 594, 1901, 1776, 457, 193, 1056, 344, 827, 1299, 1907, 677, 1213, 1028, 29, 288, 397, 1886, 184, 1632, 512, 1044, 1861, 1174, 1597, 132, 1390, 1441, 634, 1537, 893, 657, 63, 283, 1751, 377, 714, 1928, 769, 430, 148, 74, 1510, 1050, 37, 1900, 660, 937, 1620, 1704, 1273, 1455, 1095, 196]\n",
      "layer3.0.downsample.0 [974, 375, 700, 427, 892, 980, 893, 839, 632, 930, 717, 469, 718, 888, 637, 85, 461, 337, 714, 296, 703, 490, 586, 754, 936, 493, 283, 568, 350, 91, 557, 515, 735, 392, 458, 688, 784, 109]\n",
      "layer2.0.downsample.0 [356, 312, 348, 489, 363, 138, 156, 94, 90, 297, 75, 467, 475, 418, 177, 79, 338, 124, 181]\n",
      "layer1.0.downsample.0 [225, 61, 30, 147, 215, 66, 223, 89, 235, 187]\n",
      "conv1 [54, 49]\n",
      "layer1.0.conv2 [7, 58]\n",
      "layer1.0.conv1 [48, 47]\n",
      "layer1.1.conv2 [16, 41]\n",
      "layer1.1.conv1 [14, 52]\n",
      "layer1.2.conv2 [49, 7]\n",
      "layer1.2.conv1 [43, 60]\n",
      "layer2.0.conv2 [67, 49, 4, 12, 111]\n",
      "layer2.0.conv1 [2, 67, 8, 61, 117]\n",
      "layer2.1.conv2 [9, 44, 116, 10, 115]\n",
      "layer2.1.conv1 [103, 71, 97, 107, 78]\n",
      "layer2.2.conv2 [36, 2, 96, 12, 32]\n",
      "layer2.2.conv1 [73, 100, 12, 6, 39]\n",
      "layer2.3.conv2 [64, 19, 7, 103, 74]\n",
      "layer2.3.conv1 [110, 28, 49, 75, 35]\n",
      "layer3.0.conv2 [122, 150, 51, 145, 239, 32, 213, 153, 111, 79]\n",
      "layer3.0.conv1 [99, 43, 106, 4, 131, 189, 88, 53, 84, 236]\n",
      "layer3.1.conv2 [79, 225, 71, 182, 212, 53, 219, 82, 179, 96]\n",
      "layer3.1.conv1 [11, 212, 94, 213, 43, 235, 222, 220, 126, 208]\n",
      "layer3.2.conv2 [29, 158, 78, 125, 53, 178, 223, 33, 149, 28]\n",
      "layer3.2.conv1 [30, 20, 232, 29, 47, 130, 101, 23, 93, 233]\n",
      "layer3.3.conv2 [80, 35, 69, 26, 227, 202, 150, 154, 116, 83]\n",
      "layer3.3.conv1 [204, 171, 38, 185, 79, 107, 209, 172, 207, 244]\n",
      "layer3.4.conv2 [179, 40, 49, 144, 77, 41, 34, 206, 159, 158]\n",
      "layer3.4.conv1 [68, 17, 147, 95, 19, 66, 94, 55, 103, 5]\n",
      "layer3.5.conv2 [57, 212, 210, 177, 36, 88, 206, 123, 131, 51]\n",
      "layer3.5.conv1 [192, 195, 122, 78, 15, 71, 241, 239, 110, 9]\n",
      "layer4.0.conv2 [122, 472, 170, 392, 63, 36, 169, 325, 371, 97, 207, 369, 242, 366, 134, 364, 152, 361, 302]\n",
      "layer4.0.conv1 [261, 417, 222, 415, 412, 118, 297, 452, 246, 302, 306, 29, 383, 338, 196, 407, 227, 126, 317]\n",
      "layer4.1.conv2 [56, 117, 259, 116, 258, 113, 366, 130, 101, 220, 254, 271, 215, 214, 208, 239, 240, 378, 205]\n",
      "layer4.1.conv1 [372, 370, 192, 430, 362, 361, 359, 386, 183, 356, 199, 349, 201, 348, 203, 338, 337, 17, 380]\n",
      "layer4.2.conv2 [236, 422, 212, 378, 276, 273, 50, 263, 259, 87, 206, 340, 119, 91, 58, 354, 408, 349, 346]\n",
      "layer4.2.conv1 [61, 471, 467, 232, 466, 234, 249, 237, 461, 459, 238, 247, 456, 454, 452, 241, 448, 17, 447]\n",
      "Pruning step: 2 multiply–accumulate (macs): 3520505718.0 number of parameters 21952302\n",
      "layer4.0.downsample.0 [301, 1484, 1256, 538, 1326, 84, 676, 573, 431, 891, 49, 85, 1488, 1174, 1868, 213, 391, 679, 1798, 950, 1327, 349, 1102, 154, 270, 129, 1670, 1270, 411, 838, 1639, 433, 1156, 106, 926, 1844, 635, 1413, 900, 1592, 437, 115, 632, 1662, 184, 710, 1686, 1568, 1553, 795, 694, 1119, 1335, 999, 1557, 225, 483, 183, 958, 1204, 457, 421, 1671, 1751, 1696, 800, 826, 75, 663, 987, 1292, 1809, 64, 256, 1561, 1344, 839]\n",
      "layer3.0.downsample.0 [366, 311, 578, 835, 518, 708, 119, 658, 538, 16, 739, 604, 577, 392, 136, 185, 912, 740, 441, 305, 320, 860, 544, 816, 506, 632, 349, 568, 430, 543, 637, 644, 44, 563, 86, 504, 177, 773, 670]\n",
      "layer2.0.downsample.0 [31, 134, 303, 314, 53, 166, 0, 10, 449, 118, 429, 55, 411, 104, 256, 310, 286, 262, 284]\n",
      "layer1.0.downsample.0 [34, 214, 10, 154, 90, 202, 124, 57, 0]\n",
      "conv1 [30, 11, 53]\n",
      "layer1.0.conv2 [11, 24, 18]\n",
      "layer1.0.conv1 [26, 32, 4]\n",
      "layer1.1.conv2 [35, 40, 9]\n",
      "layer1.1.conv1 [43, 3, 41]\n",
      "layer1.2.conv2 [21, 4, 5]\n",
      "layer1.2.conv1 [10, 18, 48]\n",
      "layer2.0.conv2 [110, 49, 3, 94, 16]\n",
      "layer2.0.conv1 [62, 102, 112, 12, 72]\n",
      "layer2.1.conv2 [101, 34, 71, 116, 87]\n",
      "layer2.1.conv1 [58, 73, 11, 102, 64]\n",
      "layer2.2.conv2 [77, 19, 36, 39, 33]\n",
      "layer2.2.conv1 [82, 70, 114, 100, 42]\n",
      "layer2.3.conv2 [52, 88, 103, 98, 108]\n",
      "layer2.3.conv1 [30, 21, 4, 97, 110]\n",
      "layer3.0.conv2 [215, 179, 139, 205, 195, 184, 177, 104, 106]\n",
      "layer3.0.conv1 [145, 179, 163, 65, 74, 46, 137, 123, 68]\n",
      "layer3.1.conv2 [234, 119, 133, 102, 226, 13, 193, 68, 39]\n",
      "layer3.1.conv1 [12, 155, 26, 33, 72, 70, 84, 162, 163]\n",
      "layer3.2.conv2 [41, 66, 78, 225, 230, 209, 214, 127, 14]\n",
      "layer3.2.conv1 [175, 194, 89, 1, 8, 131, 52, 22, 198]\n",
      "layer3.3.conv2 [39, 34, 168, 104, 199, 134, 235, 154, 200]\n",
      "layer3.3.conv1 [23, 41, 195, 221, 38, 75, 114, 225, 208]\n",
      "layer3.4.conv2 [194, 200, 224, 164, 36, 186, 205, 16, 138]\n",
      "layer3.4.conv1 [65, 107, 96, 42, 106, 221, 108, 181, 174]\n",
      "layer3.5.conv2 [76, 166, 127, 203, 75, 107, 42, 86, 27]\n",
      "layer3.5.conv1 [178, 203, 44, 88, 34, 71, 3, 19, 1]\n",
      "layer4.0.conv2 [58, 130, 144, 213, 298, 24, 43, 45, 47, 342, 336, 276, 307, 57, 224, 384, 472, 250, 279]\n",
      "layer4.0.conv1 [219, 298, 364, 245, 228, 106, 115, 218, 404, 239, 208, 400, 214, 449, 107, 181, 220, 179, 13]\n",
      "layer4.1.conv2 [59, 72, 322, 160, 320, 319, 74, 162, 342, 341, 165, 167, 168, 305, 169, 82, 340, 84, 229]\n",
      "layer4.1.conv1 [59, 433, 432, 157, 431, 428, 426, 161, 162, 425, 423, 421, 410, 167, 404, 169, 398, 171, 172]\n",
      "layer4.2.conv2 [43, 147, 323, 29, 172, 64, 149, 33, 39, 287, 275, 455, 463, 139, 468, 469, 176, 312, 155]\n",
      "layer4.2.conv1 [198, 406, 407, 201, 410, 203, 204, 414, 415, 417, 208, 419, 423, 211, 424, 426, 214, 215, 18]\n",
      "Pruning step: 3 multiply–accumulate (macs): 3239550232.0 number of parameters 20301833\n",
      "layer4.0.downsample.0 [622, 595, 305, 519, 275, 1184, 1496, 1166, 1508, 743, 911, 262, 609, 975, 764, 1715, 1082, 625, 1520, 1454, 372, 806, 253, 928, 1670, 1475, 1561, 887, 1463, 640, 940, 1639, 1655, 1584, 62, 1489, 263, 619, 55, 248, 839, 932, 507, 1332, 1058, 421, 249, 1760, 1659, 688, 65, 1247, 1064, 924, 296, 1149, 628, 1514, 974, 1159, 1599, 1546, 1286, 712, 1741, 46, 1170, 1220, 1142, 843, 1138, 1511, 1503, 367, 187, 491, 207]\n",
      "layer3.0.downsample.0 [56, 438, 406, 529, 816, 681, 826, 83, 870, 111, 302, 147, 254, 100, 685, 722, 690, 754, 87, 820, 35, 232, 728, 447, 498, 830, 764, 78, 427, 301, 371, 184, 907, 526, 852, 536, 539, 65]\n",
      "layer2.0.downsample.0 [390, 335, 118, 222, 275, 419, 318, 61, 237, 55, 199, 121, 200, 154, 259, 73, 439, 228, 201]\n",
      "layer1.0.downsample.0 [24, 60, 19, 174, 68, 98, 130, 125, 12, 92]\n",
      "conv1 [51, 43]\n",
      "layer1.0.conv2 [52, 53]\n",
      "layer1.0.conv1 [50, 18]\n",
      "layer1.1.conv2 [26, 35]\n",
      "layer1.1.conv1 [7, 36]\n",
      "layer1.2.conv2 [29, 33]\n",
      "layer1.2.conv1 [30, 49]\n",
      "layer2.0.conv2 [0, 89, 98, 84, 66]\n",
      "layer2.0.conv1 [10, 4, 98, 58, 92]\n",
      "layer2.1.conv2 [86, 26, 100, 76, 73]\n",
      "layer2.1.conv1 [103, 53, 51, 24, 40]\n",
      "layer2.2.conv2 [31, 76, 36, 43, 82]\n",
      "layer2.2.conv1 [61, 109, 48, 21, 44]\n",
      "layer2.3.conv2 [101, 69, 16, 37, 38]\n",
      "layer2.3.conv1 [37, 112, 2, 92, 102]\n",
      "layer3.0.conv2 [136, 188, 225, 40, 201, 115, 196, 123, 135, 214]\n",
      "layer3.0.conv1 [1, 37, 166, 27, 199, 111, 182, 212, 76, 82]\n",
      "layer3.1.conv2 [96, 19, 20, 195, 147, 222, 144, 211, 51, 22]\n",
      "layer3.1.conv1 [136, 91, 76, 68, 162, 45, 82, 146, 169, 49]\n",
      "layer3.2.conv2 [86, 135, 66, 89, 3, 98, 8, 70, 31, 40]\n",
      "layer3.2.conv1 [168, 172, 126, 141, 6, 134, 0, 210, 72, 51]\n",
      "layer3.3.conv2 [176, 40, 69, 112, 132, 151, 36, 178, 20, 118]\n",
      "layer3.3.conv1 [18, 188, 52, 134, 169, 139, 224, 30, 113, 95]\n",
      "layer3.4.conv2 [19, 17, 190, 166, 178, 156, 31, 87, 126, 18]\n",
      "layer3.4.conv1 [11, 168, 6, 46, 39, 160, 37, 7, 174, 145]\n",
      "layer3.5.conv2 [220, 196, 124, 199, 113, 27, 164, 43, 101, 133]\n",
      "layer3.5.conv1 [78, 210, 180, 169, 196, 26, 58, 116, 148, 71]\n",
      "layer4.0.conv2 [21, 442, 398, 304, 168, 69, 110, 263, 56, 399, 204, 329, 186, 368, 100, 424, 235, 170, 185]\n",
      "layer4.0.conv1 [420, 440, 271, 226, 344, 202, 104, 384, 116, 419, 282, 99, 227, 312, 293, 47, 255, 18, 380]\n",
      "layer4.1.conv2 [56, 222, 269, 403, 55, 260, 57, 224, 253, 342, 373, 372, 62, 107, 109, 354, 117, 129, 133]\n",
      "layer4.1.conv1 [227, 148, 149, 441, 440, 439, 438, 437, 150, 302, 436, 433, 297, 432, 153, 427, 426, 296, 420]\n",
      "layer4.2.conv2 [158, 375, 149, 151, 22, 153, 263, 401, 432, 72, 270, 298, 138, 6, 262, 253, 178, 389, 75]\n",
      "layer4.2.conv1 [56, 311, 308, 176, 307, 305, 304, 303, 302, 182, 299, 184, 298, 296, 187, 293, 292, 290, 191]\n",
      "Pruning step: 4 multiply–accumulate (macs): 2977856940.0 number of parameters 18690753\n",
      "layer4.0.downsample.0 [1136, 1009, 1377, 993, 988, 101, 634, 1144, 1514, 970, 1326, 1585, 581, 1346, 827, 1337, 1164, 1581, 380, 1039, 1405, 980, 1729, 1431, 592, 1538, 1604, 1285, 1094, 328, 1601, 1134, 99, 43, 1649, 1658, 1599, 522, 1376, 1043, 523, 360, 573, 886, 1480, 945, 1580, 678, 1197, 642, 100, 683, 1007, 1703, 1250, 924, 660, 1021, 1664, 65, 994, 671, 1109, 612, 1536, 217, 472, 298, 1570, 437, 1495, 532, 1583, 209, 599, 1263]\n",
      "layer3.0.downsample.0 [249, 172, 379, 429, 416, 670, 569, 795, 699, 215, 68, 126, 83, 568, 411, 787, 62, 40, 745, 526, 58, 602, 142, 825, 799, 19, 261, 463, 24, 194, 27, 86, 23, 721, 522, 862, 189, 413]\n",
      "layer2.0.downsample.0 [119, 22, 58, 199, 379, 169, 189, 428, 146, 68, 112, 35, 166, 205, 337, 316, 262, 424, 346]\n",
      "layer1.0.downsample.0 [182, 116, 208, 98, 172, 160, 143, 25, 85]\n",
      "conv1 [2, 26]\n",
      "layer1.0.conv2 [37, 27]\n",
      "layer1.0.conv1 [18, 48]\n",
      "layer1.1.conv2 [23, 48]\n",
      "layer1.1.conv1 [5, 35]\n",
      "layer1.2.conv2 [13, 42]\n",
      "layer1.2.conv1 [48, 53]\n",
      "layer2.0.conv2 [20, 45, 9, 8]\n",
      "layer2.0.conv1 [104, 75, 88, 93]\n",
      "layer2.1.conv2 [54, 103, 85, 80]\n",
      "layer2.1.conv1 [52, 24, 20, 28]\n",
      "layer2.2.conv2 [103, 91, 83, 40]\n",
      "layer2.2.conv1 [100, 95, 22, 2]\n",
      "layer2.3.conv2 [107, 95, 91, 97]\n",
      "layer2.3.conv1 [0, 47, 36, 54]\n",
      "layer3.0.conv2 [19, 39, 63, 52, 88, 191, 163, 91, 110]\n",
      "layer3.0.conv1 [144, 37, 179, 16, 200, 165, 105, 24, 70]\n",
      "layer3.1.conv2 [159, 31, 197, 40, 85, 109, 183, 160, 129]\n",
      "layer3.1.conv1 [37, 127, 128, 184, 122, 159, 190, 192, 140]\n",
      "layer3.2.conv2 [168, 8, 203, 85, 139, 86, 14, 210, 73]\n",
      "layer3.2.conv1 [200, 151, 208, 94, 33, 99, 195, 22, 69]\n",
      "layer3.3.conv2 [177, 195, 164, 17, 14, 158, 48, 142, 92]\n",
      "layer3.3.conv1 [93, 201, 118, 192, 146, 182, 170, 60, 9]\n",
      "layer3.4.conv2 [165, 204, 43, 45, 167, 87, 73, 58, 100]\n",
      "layer3.4.conv1 [19, 136, 76, 5, 187, 13, 11, 117, 114]\n",
      "layer3.5.conv2 [124, 206, 213, 66, 90, 127, 138, 73, 54]\n",
      "layer3.5.conv1 [87, 21, 212, 48, 141, 82, 8, 45, 191]\n",
      "layer4.0.conv2 [27, 378, 315, 245, 130, 410, 171, 16, 225, 409, 136, 121, 192, 76, 238, 45, 14, 91, 199]\n",
      "layer4.0.conv1 [197, 425, 95, 432, 288, 189, 379, 7, 253, 243, 255, 218, 101, 154, 90, 24, 104, 110, 155]\n",
      "layer4.1.conv2 [129, 390, 37, 78, 131, 389, 274, 386, 268, 314, 43, 138, 45, 139, 66, 260, 48, 145, 293]\n",
      "layer4.1.conv1 [54, 211, 212, 309, 214, 125, 127, 128, 305, 304, 431, 430, 429, 132, 133, 134, 411, 135, 136]\n",
      "layer4.2.conv2 [309, 293, 3, 26, 148, 243, 189, 365, 244, 426, 86, 237, 295, 37, 340, 90, 76, 332, 329]\n",
      "layer4.2.conv1 [108, 296, 294, 318, 293, 321, 306, 326, 304, 301, 327, 329, 330, 331, 333, 345, 346, 347, 212]\n",
      "Pruning step: 5 multiply–accumulate (macs): 2744393352.0 number of parameters 17193500\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 52, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(52, 52, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(208, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(104, 104, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(104, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(208, 416, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(416, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(104, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(416, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(104, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(416, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(104, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(416, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(208, 208, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(208, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(416, 832, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(832, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(208, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(832, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(208, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(832, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(208, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(832, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(208, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(832, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(208, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(832, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(416, 416, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(416, 1664, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(832, 1664, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1664, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(416, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(416, 1664, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1664, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(416, 416, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(416, 1664, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=1664, out_features=1000, bias=True)\n",
      ")\n",
      "Pruning sparsity: 0.25\n",
      "layer4.0.downsample.0 [478, 100, 2, 311, 1999, 1578, 456, 1051, 80, 1093, 583, 275, 1925, 93, 1561, 1288, 1326, 605, 468, 892, 2046, 663, 1056, 1344, 2020, 112, 2040, 1427, 338, 1993, 1058, 1748, 1154, 1349, 1772, 92, 1253, 1868, 1126, 1736, 1530, 854, 968, 309, 1604, 143, 1880, 898, 1477, 695, 1144, 327, 351, 16, 1542, 1464, 61, 745, 1727, 955, 746, 728, 751, 1906, 449, 653, 1257, 167, 301, 108, 1743, 1055, 207, 1929, 1292, 616, 839, 1402, 558, 929, 1570, 1014, 1492, 1510, 1749, 1980, 48, 1888, 1850, 660, 415, 1595, 833, 1077, 1619, 991, 153, 1932, 623, 1158, 148, 1819, 1444]\n",
      "layer3.0.downsample.0 [1023, 853, 501, 486, 962, 1018, 657, 91, 412, 500, 759, 544, 60, 644, 303, 1011, 170, 1017, 741, 803, 906, 444, 491, 96, 151, 595, 590, 18, 419, 685, 51, 45, 980, 923, 873, 38, 609, 197, 728, 928, 123, 388, 767, 536, 487, 729, 83, 494, 927, 194, 744, 966]\n",
      "layer2.0.downsample.0 [387, 243, 246, 404, 176, 347, 412, 100, 34, 163, 53, 11, 24, 114, 96, 66, 98, 363, 43, 207, 371, 424, 495, 379, 311, 166]\n",
      "layer1.0.downsample.0 [144, 108, 214, 150, 233, 131, 58, 103, 29, 235, 77, 92, 31]\n",
      "conv1 [13, 44, 42, 52]\n",
      "layer1.0.conv2 [0, 1, 19, 61]\n",
      "layer1.0.conv1 [1, 60, 38, 5]\n",
      "layer1.1.conv2 [17, 41, 25, 6]\n",
      "layer1.1.conv1 [56, 42, 2, 41]\n",
      "layer1.2.conv2 [11, 4, 7, 24]\n",
      "layer1.2.conv1 [39, 2, 49, 45]\n",
      "layer2.0.conv2 [35, 29, 51, 110, 69, 90, 3]\n",
      "layer2.0.conv1 [112, 89, 92, 63, 104, 68, 8]\n",
      "layer2.1.conv2 [46, 93, 100, 121, 120, 9, 10]\n",
      "layer2.1.conv1 [1, 3, 118, 5, 111, 76, 112]\n",
      "layer2.2.conv2 [29, 56, 18, 39, 101, 34, 12]\n",
      "layer2.2.conv1 [117, 120, 112, 38, 63, 75, 6]\n",
      "layer2.3.conv2 [127, 124, 105, 36, 76, 21, 0]\n",
      "layer2.3.conv1 [120, 74, 6, 79, 23, 9, 4]\n",
      "layer3.0.conv2 [13, 141, 2, 106, 35, 157, 250, 248, 222, 54, 221, 133, 194]\n",
      "layer3.0.conv1 [136, 139, 48, 4, 148, 103, 89, 90, 220, 254, 18, 245, 44]\n",
      "layer3.1.conv2 [7, 100, 130, 132, 209, 221, 133, 123, 8, 228, 229, 111, 108]\n",
      "layer3.1.conv1 [32, 229, 142, 225, 181, 41, 231, 43, 235, 222, 244, 11, 173]\n",
      "layer3.2.conv2 [117, 35, 196, 108, 79, 43, 149, 166, 112, 17, 157, 156, 47]\n",
      "layer3.2.conv1 [210, 56, 164, 212, 30, 242, 134, 47, 167, 29, 153, 24, 148]\n",
      "layer3.3.conv2 [190, 35, 148, 247, 131, 34, 127, 100, 82, 37, 218, 146, 43]\n",
      "layer3.3.conv1 [19, 99, 100, 59, 58, 244, 181, 114, 9, 31, 195, 240, 189]\n",
      "layer3.4.conv2 [169, 53, 50, 116, 252, 150, 105, 242, 244, 186, 41, 126, 19]\n",
      "layer3.4.conv1 [6, 108, 73, 71, 8, 10, 87, 100, 19, 190, 204, 26, 55]\n",
      "layer3.5.conv2 [206, 77, 127, 219, 142, 221, 143, 203, 91, 59, 186, 94, 38]\n",
      "layer3.5.conv1 [16, 1, 190, 204, 70, 251, 203, 249, 10, 200, 29, 112, 126]\n",
      "layer4.0.conv2 [378, 46, 78, 284, 48, 326, 244, 319, 409, 157, 388, 126, 12, 286, 160, 290, 274, 272, 130, 269, 84, 216, 178, 386, 268, 492]\n",
      "layer4.0.conv1 [466, 304, 124, 457, 388, 406, 143, 410, 225, 34, 10, 383, 12, 421, 467, 15, 314, 429, 436, 268, 231, 230, 229, 253, 510, 316]\n",
      "layer4.1.conv2 [454, 333, 2, 475, 4, 122, 469, 465, 144, 347, 348, 129, 355, 351, 134, 294, 256, 459, 18, 193, 299, 194, 426, 448, 185, 291]\n",
      "layer4.1.conv1 [64, 382, 381, 379, 198, 376, 200, 7, 369, 9, 10, 320, 193, 203, 365, 364, 206, 17, 207, 19, 362, 360, 22, 210, 211, 25]\n",
      "layer4.2.conv2 [0, 308, 307, 353, 92, 93, 469, 96, 8, 494, 99, 11, 12, 302, 178, 479, 176, 359, 173, 350, 362, 219, 295, 294, 169, 166]\n",
      "layer4.2.conv1 [64, 382, 415, 182, 380, 5, 6, 7, 418, 379, 423, 378, 376, 424, 14, 15, 16, 375, 18, 19, 428, 431, 370, 287, 24, 367]\n",
      "Pruning step: 1 multiply–accumulate (macs): 3703461272.0 number of parameters 23123597\n",
      "layer4.0.downsample.0 [535, 1141, 1644, 1390, 768, 588, 1359, 1754, 340, 290, 280, 11, 1877, 203, 1200, 1620, 904, 1491, 360, 1043, 114, 754, 679, 94, 1097, 927, 506, 14, 1740, 818, 1132, 761, 288, 424, 706, 181, 283, 470, 1563, 1258, 650, 1189, 1372, 10, 1161, 817, 690, 553, 591, 1527, 1683, 1423, 986, 1805, 1844, 87, 1304, 1290, 499, 1224, 180, 109, 404, 38, 51, 1082, 494, 241, 1308, 133, 1716, 1254, 1518, 697, 1248, 1604, 373, 62, 1588, 284, 1360, 580, 586, 1520, 1729, 1481, 205, 656, 1940, 1610, 1714, 1611, 1368, 1903, 1151, 78, 338, 652, 1346, 30, 670, 73]\n",
      "layer3.0.downsample.0 [375, 631, 392, 487, 140, 591, 677, 284, 626, 85, 490, 740, 786, 297, 16, 763, 338, 66, 192, 669, 925, 698, 428, 840, 351, 712, 684, 738, 460, 762, 311, 530, 326, 516, 711, 189, 617, 315, 36, 797, 563, 181, 590, 674, 748, 401, 97, 106, 91, 823, 581]\n",
      "layer2.0.downsample.0 [413, 175, 343, 139, 483, 179, 352, 79, 440, 0, 55, 462, 31, 309, 53, 322, 137, 253, 60, 311, 132, 10, 448, 75, 123, 269]\n",
      "layer1.0.downsample.0 [146, 105, 65, 214, 10, 220, 232, 34, 60, 92, 186, 158, 0]\n",
      "conv1 [53, 30, 11]\n",
      "layer1.0.conv2 [7, 12, 19]\n",
      "layer1.0.conv1 [43, 42, 5]\n",
      "layer1.1.conv2 [9, 40, 35]\n",
      "layer1.1.conv1 [14, 52, 3]\n",
      "layer1.2.conv2 [53, 6, 15]\n",
      "layer1.2.conv1 [10, 59, 53]\n",
      "layer2.0.conv2 [112, 50, 108, 95, 3, 11]\n",
      "layer2.0.conv1 [64, 13, 60, 11, 114, 2]\n",
      "layer2.1.conv2 [104, 27, 51, 119, 36, 90]\n",
      "layer2.1.conv1 [104, 98, 60, 26, 25, 55]\n",
      "layer2.2.conv2 [69, 80, 31, 38, 48, 91]\n",
      "layer2.2.conv1 [38, 11, 98, 84, 117, 116]\n",
      "layer2.3.conv2 [108, 16, 64, 101, 111, 5]\n",
      "layer2.3.conv1 [26, 45, 108, 33, 48, 99]\n",
      "layer3.0.conv2 [236, 152, 3, 144, 111, 110, 198, 221, 143, 106, 210, 145, 202]\n",
      "layer3.0.conv1 [233, 128, 37, 103, 225, 214, 186, 111, 82, 184, 40, 187, 118]\n",
      "layer3.1.conv2 [14, 182, 70, 233, 146, 137, 80, 225, 222, 83, 155, 54, 121]\n",
      "layer3.1.conv1 [75, 71, 204, 187, 72, 61, 73, 214, 50, 209, 32, 210, 12]\n",
      "layer3.2.conv2 [174, 220, 227, 94, 35, 29, 178, 52, 232, 28, 122, 97, 170]\n",
      "layer3.2.conv1 [20, 147, 95, 94, 47, 100, 186, 1, 90, 92, 171, 154, 204]\n",
      "layer3.3.conv2 [26, 147, 151, 224, 242, 206, 17, 35, 173, 80, 118, 200, 209]\n",
      "layer3.3.conv1 [38, 241, 22, 208, 203, 200, 198, 136, 202, 225, 74, 196, 159]\n",
      "layer3.4.conv2 [156, 200, 137, 75, 34, 170, 157, 40, 142, 231, 202, 110, 80]\n",
      "layer3.4.conv1 [100, 43, 7, 99, 91, 90, 11, 153, 54, 181, 14, 229, 23]\n",
      "layer3.5.conv2 [204, 131, 129, 0, 44, 100, 175, 52, 211, 226, 155, 30, 135]\n",
      "layer3.5.conv1 [126, 4, 2, 108, 79, 189, 191, 72, 63, 194, 146, 90, 238]\n",
      "layer4.0.conv2 [34, 98, 359, 344, 106, 314, 354, 485, 58, 350, 135, 136, 321, 69, 319, 436, 104, 361, 429, 394, 24, 47, 376, 220, 225, 137]\n",
      "layer4.0.conv1 [323, 463, 462, 334, 51, 127, 410, 460, 397, 110, 213, 197, 241, 248, 15, 325, 311, 301, 303, 458, 222, 139, 377, 205, 299, 105]\n",
      "layer4.1.conv2 [60, 219, 256, 250, 83, 247, 85, 238, 239, 375, 384, 390, 141, 372, 403, 408, 93, 370, 419, 454, 146, 456, 148, 479, 422, 101]\n",
      "layer4.1.conv1 [60, 308, 160, 161, 313, 315, 316, 324, 166, 328, 168, 169, 170, 171, 331, 333, 174, 334, 176, 340, 341, 179, 22, 364, 24, 181]\n",
      "layer4.2.conv2 [221, 329, 188, 58, 290, 396, 394, 66, 152, 263, 380, 387, 175, 261, 314, 267, 312, 150, 174, 361, 269, 210, 22, 270, 430, 317]\n",
      "layer4.2.conv1 [92, 317, 316, 345, 343, 376, 342, 341, 378, 384, 385, 315, 314, 387, 333, 390, 311, 17, 310, 330, 20, 329, 308, 307, 391, 25]\n",
      "Pruning step: 2 multiply–accumulate (macs): 3334201847.0 number of parameters 20837770\n",
      "layer4.0.downsample.0 [1048, 422, 1171, 399, 772, 416, 840, 307, 406, 193, 1065, 683, 258, 767, 1508, 970, 6, 287, 1728, 940, 79, 798, 1166, 418, 1212, 1301, 666, 1491, 899, 640, 1601, 902, 1047, 718, 812, 1200, 1399, 1517, 993, 608, 263, 99, 1820, 1515, 244, 1449, 1622, 59, 601, 632, 771, 750, 1492, 1539, 927, 250, 1053, 1471, 369, 1100, 1647, 577, 944, 527, 374, 954, 1736, 1528, 255, 1106, 1806, 1439, 1546, 1479, 1083, 1694, 713, 1771, 174, 621, 1383, 1076, 1533, 423, 214, 1052, 395, 1102, 801, 105, 224, 100, 600, 1691, 1400, 1505, 629, 1291, 1757, 1626, 507, 694, 1709]\n",
      "layer3.0.downsample.0 [56, 428, 838, 184, 111, 533, 618, 874, 261, 701, 886, 103, 693, 492, 82, 42, 613, 920, 809, 292, 523, 526, 338, 441, 435, 732, 372, 14, 339, 879, 830, 688, 600, 70, 23, 740, 625, 417, 432, 225, 301, 650, 78, 530, 138, 831, 4, 636, 797, 708, 548]\n",
      "layer2.0.downsample.0 [85, 120, 113, 60, 444, 300, 277, 358, 400, 453, 58, 395, 230, 436, 275, 159, 152, 248, 202, 224, 407, 340, 402, 342, 445]\n",
      "layer1.0.downsample.0 [197, 69, 19, 132, 61, 120, 99, 54, 106, 176, 174, 194, 93]\n",
      "conv1 [51, 52, 43]\n",
      "layer1.0.conv2 [22, 53, 54]\n",
      "layer1.0.conv1 [18, 30, 43]\n",
      "layer1.1.conv2 [26, 38, 35]\n",
      "layer1.1.conv1 [7, 42, 40]\n",
      "layer1.2.conv2 [33, 29, 51]\n",
      "layer1.2.conv1 [47, 48, 17]\n",
      "layer2.0.conv2 [19, 47, 0, 107, 22, 54, 33]\n",
      "layer2.0.conv1 [109, 57, 69, 99, 98, 4, 88]\n",
      "layer2.1.conv2 [27, 71, 102, 88, 24, 78, 110]\n",
      "layer2.1.conv1 [62, 71, 75, 53, 11, 40, 51]\n",
      "layer2.2.conv2 [20, 40, 59, 72, 98, 29, 2]\n",
      "layer2.2.conv1 [70, 99, 49, 97, 42, 23, 102]\n",
      "layer2.3.conv2 [6, 16, 38, 35, 37, 52, 62]\n",
      "layer2.3.conv1 [107, 10, 50, 28, 93, 39, 114]\n",
      "layer3.0.conv2 [106, 228, 117, 182, 118, 192, 64, 113, 217, 204, 126, 176, 11]\n",
      "layer3.0.conv1 [73, 135, 143, 172, 27, 49, 67, 83, 215, 222, 187, 25, 161]\n",
      "layer3.1.conv2 [20, 39, 21, 81, 53, 193, 198, 170, 228, 7, 224, 89, 69]\n",
      "layer3.1.conv1 [159, 152, 73, 76, 173, 149, 172, 85, 83, 80, 136, 131, 65]\n",
      "layer3.2.conv2 [179, 78, 65, 137, 205, 72, 141, 216, 73, 3, 210, 10, 31]\n",
      "layer3.2.conv1 [139, 7, 26, 37, 54, 114, 129, 217, 51, 144, 170, 21, 75]\n",
      "layer3.3.conv2 [178, 150, 135, 185, 152, 119, 154, 24, 208, 168, 64, 198, 69]\n",
      "layer3.3.conv1 [196, 9, 76, 39, 113, 138, 29, 146, 68, 100, 31, 73, 98]\n",
      "layer3.4.conv2 [191, 173, 18, 178, 20, 88, 27, 32, 51, 78, 106, 177, 175]\n",
      "layer3.4.conv1 [1, 175, 215, 101, 102, 13, 202, 161, 146, 126, 172, 36, 44]\n",
      "layer3.5.conv2 [223, 75, 28, 44, 48, 161, 218, 85, 104, 199, 74, 78, 198]\n",
      "layer3.5.conv1 [197, 49, 111, 199, 81, 223, 66, 72, 42, 46, 213, 12, 186]\n",
      "layer4.0.conv2 [405, 262, 271, 404, 208, 434, 359, 54, 220, 21, 443, 171, 214, 455, 81, 58, 16, 157, 275, 71, 103, 143, 335, 311, 242]\n",
      "layer4.0.conv1 [48, 305, 256, 170, 8, 101, 206, 119, 201, 211, 179, 384, 297, 162, 389, 161, 370, 99, 106, 176, 449, 214, 88, 20, 401]\n",
      "layer4.1.conv2 [57, 299, 253, 54, 55, 108, 160, 58, 335, 255, 157, 155, 110, 111, 112, 154, 187, 186, 63, 184, 148, 71, 72, 289, 74]\n",
      "layer4.1.conv1 [26, 372, 371, 370, 199, 145, 284, 140, 201, 245, 366, 364, 203, 204, 362, 206, 360, 250, 244, 357, 254, 192, 213, 216, 354]\n",
      "layer4.2.conv2 [114, 28, 139, 42, 41, 32, 38, 392, 242, 246, 323, 324, 338, 77, 350, 145, 144, 80, 309, 456, 455, 450, 299, 49, 377]\n",
      "layer4.2.conv1 [459, 395, 270, 265, 393, 264, 392, 391, 388, 262, 168, 171, 172, 261, 259, 258, 178, 183, 190, 191, 192, 193, 246, 196, 243]\n",
      "Pruning step: 3 multiply–accumulate (macs): 2977856940.0 number of parameters 18690753\n",
      "layer4.0.downsample.0 [476, 433, 823, 584, 790, 1676, 203, 229, 261, 1183, 1214, 1297, 249, 1543, 1685, 1019, 905, 1108, 1010, 1580, 326, 1583, 954, 814, 459, 1437, 1535, 186, 282, 1223, 472, 593, 393, 1518, 200, 403, 1037, 1161, 926, 1603, 111, 1705, 240, 1489, 1614, 1241, 973, 1501, 1475, 490, 1569, 1656, 57, 16, 93, 1011, 346, 974, 245, 965, 854, 312, 764, 1371, 1649, 1291, 1568, 85, 1336, 1646, 138, 488, 1134, 605, 60, 1523, 1504, 1356, 468, 1529, 955, 1694, 572, 411, 399, 1724, 1560, 1651, 1260, 638, 636, 364, 348, 848, 42, 8, 920, 869, 998, 805, 278, 644]\n",
      "layer3.0.downsample.0 [461, 81, 795, 79, 37, 454, 376, 166, 286, 794, 693, 192, 783, 59, 137, 375, 523, 270, 21, 513, 141, 71, 773, 826, 569, 395, 241, 476, 120, 237, 516, 799, 817, 24, 281, 106, 803, 809, 411, 413, 752, 459, 80, 47, 460, 273, 366, 719, 269, 698, 283]\n",
      "layer2.0.downsample.0 [190, 187, 225, 305, 295, 35, 350, 267, 353, 67, 302, 165, 425, 194, 325, 413, 381, 208, 322, 134, 124, 266, 339, 39, 307, 170]\n",
      "layer1.0.downsample.0 [12, 23, 49, 119, 162, 27, 117, 173, 145, 193, 154, 144, 204]\n",
      "conv1 [2, 26, 31]\n",
      "layer1.0.conv2 [27, 37, 42]\n",
      "layer1.0.conv1 [47, 40, 36]\n",
      "layer1.1.conv2 [18, 16, 23]\n",
      "layer1.1.conv1 [19, 29, 10]\n",
      "layer1.2.conv2 [4, 24, 42]\n",
      "layer1.2.conv1 [48, 30, 50]\n",
      "layer2.0.conv2 [94, 84, 8, 96, 81, 31]\n",
      "layer2.0.conv1 [88, 87, 48, 104, 49, 75]\n",
      "layer2.1.conv2 [25, 86, 72, 38, 88, 54]\n",
      "layer2.1.conv1 [20, 52, 24, 47, 74, 28]\n",
      "layer2.2.conv2 [105, 31, 103, 17, 47, 84]\n",
      "layer2.2.conv1 [21, 99, 15, 59, 73, 2]\n",
      "layer2.3.conv2 [95, 47, 7, 90, 81, 107]\n",
      "layer2.3.conv1 [14, 0, 36, 2, 56, 31]\n",
      "layer3.0.conv2 [38, 39, 210, 18, 191, 75, 54, 99, 163, 88, 144, 131, 7]\n",
      "layer3.0.conv1 [107, 115, 5, 1, 61, 181, 147, 215, 190, 72, 74, 17, 28]\n",
      "layer3.1.conv2 [197, 76, 141, 175, 138, 41, 160, 149, 177, 20, 32, 14, 109]\n",
      "layer3.1.conv1 [13, 113, 192, 170, 129, 210, 85, 25, 200, 111, 144, 44, 104]\n",
      "layer3.2.conv2 [12, 109, 7, 211, 75, 74, 47, 38, 90, 9, 110, 141, 209]\n",
      "layer3.2.conv1 [121, 214, 200, 174, 172, 194, 41, 208, 169, 159, 69, 7, 122]\n",
      "layer3.3.conv2 [34, 128, 148, 38, 166, 172, 49, 106, 160, 19, 78, 9, 99]\n",
      "layer3.3.conv1 [107, 62, 192, 13, 102, 18, 171, 60, 175, 3, 214, 80, 117]\n",
      "layer3.4.conv2 [32, 170, 31, 148, 175, 204, 75, 196, 209, 59, 37, 158, 151]\n",
      "layer3.4.conv1 [49, 12, 188, 162, 32, 160, 125, 117, 36, 96, 29, 114, 172]\n",
      "layer3.5.conv2 [132, 124, 76, 97, 141, 128, 23, 45, 109, 210, 129, 127, 131]\n",
      "layer3.5.conv1 [175, 90, 87, 215, 91, 31, 110, 112, 16, 184, 150, 6, 151]\n",
      "layer4.0.conv2 [258, 72, 412, 163, 215, 180, 354, 121, 54, 424, 171, 152, 137, 29, 15, 45, 172, 241, 254, 183, 353, 55, 362, 408, 358, 202]\n",
      "layer4.0.conv1 [401, 7, 432, 139, 256, 156, 242, 201, 304, 286, 266, 143, 198, 386, 103, 340, 25, 211, 190, 191, 298, 33, 224, 392, 194, 12]\n",
      "layer4.1.conv2 [190, 263, 279, 179, 48, 145, 32, 33, 43, 312, 277, 45, 311, 185, 317, 186, 147, 37, 223, 232, 146, 319, 176, 135, 151, 27]\n",
      "layer4.1.conv1 [108, 367, 366, 365, 364, 417, 359, 358, 118, 414, 357, 413, 166, 121, 168, 350, 349, 408, 123, 241, 407, 337, 332, 401, 326, 127]\n",
      "layer4.2.conv2 [357, 371, 337, 67, 43, 86, 11, 207, 6, 392, 307, 242, 194, 362, 331, 363, 279, 144, 291, 322, 432, 7, 90, 5, 297, 409]\n",
      "layer4.2.conv1 [310, 430, 137, 429, 428, 426, 423, 422, 337, 336, 421, 417, 413, 412, 380, 410, 409, 407, 403, 402, 397, 129, 263, 390, 383, 25]\n",
      "Pruning step: 4 multiply–accumulate (macs): 2647792566.0 number of parameters 16641302\n",
      "layer4.0.downsample.0 [289, 1565, 1050, 365, 1013, 885, 1628, 438, 330, 1160, 1177, 1134, 591, 388, 822, 993, 226, 1027, 1568, 548, 1569, 730, 1577, 1226, 727, 1490, 1002, 1019, 964, 704, 728, 100, 1469, 256, 1492, 1412, 318, 1231, 1305, 915, 1312, 1398, 184, 1023, 79, 707, 969, 275, 1067, 958, 1072, 787, 356, 698, 550, 1473, 1385, 1232, 69, 161, 1515, 77, 1360, 1175, 1052, 59, 412, 323, 399, 1463, 301, 1593, 1154, 1135, 167, 148, 673, 1509, 1127, 494, 625, 1445, 1619, 657, 670, 1212, 196, 33, 1159, 944, 1225, 1581, 1352, 988, 1073, 1128, 563, 1496, 856, 1431, 1353, 971]\n",
      "layer3.0.downsample.0 [204, 114, 75, 83, 483, 798, 51, 291, 173, 468, 389, 343, 673, 324, 490, 306, 345, 577, 563, 279, 259, 333, 782, 641, 17, 730, 242, 477, 203, 426, 72, 149, 96, 121, 771, 649, 261, 169, 450, 87, 711, 497, 682, 668, 229, 487, 303, 403, 341, 796, 703]\n",
      "layer2.0.downsample.0 [67, 34, 22, 144, 225, 221, 284, 192, 93, 312, 345, 149, 232, 354, 143, 185, 332, 237, 58, 110, 375, 162, 7, 370, 340]\n",
      "layer1.0.downsample.0 [91, 7, 4, 195, 197, 3, 120, 85, 180, 48, 162, 25]\n",
      "conv1 [25, 2, 26]\n",
      "layer1.0.conv2 [13, 35, 6]\n",
      "layer1.0.conv1 [44, 30, 17]\n",
      "layer1.1.conv2 [44, 1, 35]\n",
      "layer1.1.conv1 [30, 14, 31]\n",
      "layer1.2.conv2 [35, 40, 1]\n",
      "layer1.2.conv1 [35, 50, 11]\n",
      "layer2.0.conv2 [19, 30, 49, 12, 101, 20]\n",
      "layer2.0.conv1 [97, 88, 82, 69, 70, 17]\n",
      "layer2.1.conv2 [5, 63, 85, 95, 77, 7]\n",
      "layer2.1.conv1 [91, 60, 23, 92, 55, 81]\n",
      "layer2.2.conv2 [70, 29, 40, 53, 36, 98]\n",
      "layer2.2.conv1 [50, 94, 62, 40, 48, 37]\n",
      "layer2.3.conv2 [92, 44, 54, 39, 75, 50]\n",
      "layer2.3.conv1 [92, 77, 9, 48, 29, 54]\n",
      "layer3.0.conv2 [26, 171, 48, 43, 78, 74, 202, 94, 32, 84, 87, 113]\n",
      "layer3.0.conv1 [73, 190, 123, 203, 130, 119, 94, 104, 198, 191, 87, 1]\n",
      "layer3.1.conv2 [158, 123, 36, 198, 103, 29, 151, 58, 43, 42, 129, 56]\n",
      "layer3.1.conv1 [78, 123, 183, 4, 46, 108, 113, 139, 192, 24, 134, 154]\n",
      "layer3.2.conv2 [64, 107, 113, 142, 30, 127, 55, 82, 29, 54, 69, 81]\n",
      "layer3.2.conv1 [145, 0, 143, 189, 78, 163, 20, 91, 151, 109, 21, 117]\n",
      "layer3.3.conv2 [164, 13, 126, 167, 100, 158, 40, 92, 123, 14, 172, 121]\n",
      "layer3.3.conv1 [161, 157, 136, 58, 91, 123, 158, 159, 74, 17, 151, 49]\n",
      "layer3.4.conv2 [177, 146, 81, 38, 118, 152, 46, 196, 99, 49, 195, 174]\n",
      "layer3.4.conv1 [56, 197, 61, 160, 162, 77, 163, 5, 174, 53, 183, 33]\n",
      "layer3.5.conv2 [149, 104, 166, 156, 7, 135, 190, 147, 53, 179, 200, 47]\n",
      "layer3.5.conv1 [179, 134, 45, 71, 19, 132, 123, 12, 8, 171, 154, 83]\n",
      "layer4.0.conv2 [300, 212, 381, 350, 205, 100, 123, 382, 12, 317, 387, 167, 71, 82, 31, 14, 135, 37, 390, 376, 282, 251, 39, 190, 126]\n",
      "layer4.0.conv1 [86, 239, 0, 148, 37, 165, 131, 404, 220, 96, 241, 323, 157, 9, 326, 331, 201, 364, 105, 20, 225, 345, 376, 93, 95]\n",
      "layer4.1.conv2 [44, 293, 28, 11, 6, 274, 25, 345, 131, 108, 365, 91, 27, 70, 47, 391, 8, 307, 296, 181, 285, 367, 379, 10, 376]\n",
      "layer4.1.conv1 [102, 353, 351, 215, 84, 87, 89, 93, 207, 99, 255, 406, 405, 404, 403, 105, 106, 109, 36, 111, 396, 395, 394, 115, 380]\n",
      "layer4.2.conv2 [255, 311, 3, 319, 388, 171, 176, 75, 93, 263, 234, 378, 144, 232, 277, 143, 213, 265, 136, 231, 113, 198, 233, 123, 406]\n",
      "layer4.2.conv1 [102, 285, 373, 279, 278, 370, 367, 265, 111, 112, 114, 256, 254, 252, 136, 121, 124, 126, 129, 78, 130, 132, 135, 227, 226]\n",
      "Pruning step: 5 multiply–accumulate (macs): 2347233640.0 number of parameters 14771992\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(192, 384, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(768, 1536, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=1536, out_features=1000, bias=True)\n",
      ")\n",
      "Pruning sparsity: 0.3125\n",
      "layer4.0.downsample.0 [1925, 675, 892, 1449, 678, 1154, 1058, 311, 61, 605, 100, 1542, 1344, 93, 1349, 1561, 1158, 653, 275, 1748, 1993, 1257, 854, 112, 218, 108, 286, 1326, 143, 1427, 327, 1288, 560, 2, 1906, 1492, 1056, 1530, 1201, 1262, 351, 580, 1850, 1193, 565, 1464, 991, 1727, 1144, 1568, 1292, 204, 1743, 570, 1077, 623, 102, 16, 619, 968, 1070, 728, 1532, 296, 955, 80, 382, 1653, 1619, 1880, 898, 583, 167, 1592, 1980, 706, 1555, 1236, 195, 158, 1055, 1099, 1014, 153, 1843, 563, 1510, 1726, 2020, 1371, 1929, 695, 1827, 899, 660, 301, 833, 416, 362, 533, 1253, 48, 743, 1477, 449, 1322, 2040, 447, 839, 929, 144, 497, 307, 2046, 415, 1126, 1639, 1496, 478, 794, 663, 1441, 66, 861, 1718, 1595, 526, 685]\n",
      "layer3.0.downsample.0 [853, 1023, 486, 197, 657, 170, 544, 1018, 962, 501, 595, 491, 91, 644, 803, 1011, 412, 729, 303, 1017, 151, 444, 980, 759, 18, 778, 388, 906, 38, 923, 419, 741, 123, 927, 83, 685, 825, 194, 96, 192, 966, 748, 16, 51, 60, 662, 728, 928, 500, 873, 487, 709, 732, 747, 105, 800, 590, 45, 331, 511, 579, 390, 972, 494]\n",
      "layer2.0.downsample.0 [387, 176, 243, 246, 404, 347, 412, 100, 163, 34, 11, 424, 149, 495, 114, 43, 53, 24, 371, 66, 326, 311, 363, 184, 207, 33, 166, 411, 188, 487, 96, 372]\n",
      "layer1.0.downsample.0 [144, 214, 108, 77, 150, 233, 58, 112, 225, 103, 131, 29, 235, 31, 10, 196]\n",
      "conv1 [13, 44, 42, 52]\n",
      "layer1.0.conv2 [0, 1, 61, 60]\n",
      "layer1.0.conv1 [38, 1, 49, 48]\n",
      "layer1.1.conv2 [38, 41, 6, 25]\n",
      "layer1.1.conv1 [56, 19, 2, 42]\n",
      "layer1.2.conv2 [11, 7, 57, 24]\n",
      "layer1.2.conv1 [2, 39, 49, 45]\n",
      "layer2.0.conv2 [35, 119, 29, 4, 51, 3, 54, 101]\n",
      "layer2.0.conv1 [112, 92, 89, 63, 104, 68, 8, 66]\n",
      "layer2.1.conv2 [109, 46, 9, 10, 121, 93, 120, 100]\n",
      "layer2.1.conv1 [118, 1, 111, 3, 5, 69, 102, 29]\n",
      "layer2.2.conv2 [29, 56, 34, 39, 75, 32, 18, 43]\n",
      "layer2.2.conv1 [117, 112, 38, 120, 75, 63, 102, 40]\n",
      "layer2.3.conv2 [127, 36, 0, 124, 17, 76, 111, 19]\n",
      "layer2.3.conv1 [74, 79, 6, 120, 9, 37, 4, 52]\n",
      "layer3.0.conv2 [106, 13, 2, 141, 133, 248, 250, 222, 207, 54, 152, 160, 35, 157, 151, 4]\n",
      "layer3.0.conv1 [4, 245, 196, 18, 220, 148, 89, 90, 48, 139, 136, 254, 110, 103, 212, 244]\n",
      "layer3.1.conv2 [16, 123, 132, 85, 133, 238, 56, 7, 8, 111, 82, 235, 146, 108, 100, 229]\n",
      "layer3.1.conv1 [32, 173, 244, 211, 201, 75, 73, 187, 188, 50, 194, 11, 65, 13, 249, 181]\n",
      "layer3.2.conv2 [35, 196, 149, 117, 79, 166, 108, 156, 157, 43, 30, 56, 233, 99, 190, 47]\n",
      "layer3.2.conv1 [20, 1, 155, 192, 23, 47, 119, 182, 56, 29, 30, 134, 210, 216, 51, 97]\n",
      "layer3.3.conv2 [148, 35, 127, 190, 247, 34, 146, 157, 161, 37, 43, 236, 112, 218, 131, 76]\n",
      "layer3.3.conv1 [24, 84, 100, 195, 219, 19, 217, 181, 79, 9, 75, 214, 58, 189, 211, 31]\n",
      "layer3.4.conv2 [244, 242, 42, 126, 144, 150, 50, 105, 53, 210, 169, 19, 116, 252, 41, 18]\n",
      "layer3.4.conv1 [204, 40, 164, 100, 108, 110, 26, 10, 55, 73, 111, 48, 190, 242, 76, 99]\n",
      "layer3.5.conv2 [91, 219, 221, 77, 59, 94, 186, 52, 127, 183, 137, 142, 143, 38, 135, 203]\n",
      "layer3.5.conv1 [133, 3, 5, 112, 249, 10, 246, 126, 16, 190, 203, 70, 204, 29, 166, 205]\n",
      "layer4.0.conv2 [80, 378, 386, 388, 178, 244, 48, 294, 236, 203, 142, 290, 12, 286, 284, 371, 272, 65, 269, 409, 419, 268, 130, 160, 238, 192, 326, 78, 103, 266, 342, 35]\n",
      "layer4.0.conv1 [10, 34, 510, 471, 55, 457, 383, 241, 406, 500, 487, 314, 467, 268, 488, 15, 16, 309, 143, 436, 53, 112, 8, 394, 132, 252, 338, 12, 189, 114, 326, 238]\n",
      "layer4.1.conv2 [291, 194, 2, 193, 505, 422, 421, 256, 223, 224, 144, 153, 12, 277, 228, 229, 308, 409, 18, 327, 155, 237, 403, 185, 134, 267, 249, 54, 251, 394, 258, 31]\n",
      "layer4.1.conv1 [64, 412, 186, 187, 414, 189, 416, 7, 191, 9, 10, 11, 192, 193, 418, 419, 421, 17, 422, 19, 198, 424, 22, 200, 426, 25, 202, 203, 427, 29, 428, 31]\n",
      "layer4.2.conv2 [0, 333, 245, 337, 344, 188, 187, 348, 8, 353, 331, 359, 178, 141, 362, 15, 176, 173, 309, 169, 367, 308, 166, 307, 368, 381, 160, 219, 302, 417, 201, 295]\n",
      "layer4.2.conv1 [64, 207, 453, 456, 457, 5, 6, 211, 459, 213, 214, 460, 464, 466, 14, 15, 16, 218, 18, 19, 468, 220, 221, 23, 24, 471, 26, 473, 224, 29, 225, 475]\n",
      "Pruning step: 1 multiply–accumulate (macs): 3631739080.0 number of parameters 22586020\n",
      "layer4.0.downsample.0 [1013, 1365, 51, 1113, 14, 908, 1701, 178, 1809, 396, 1500, 577, 446, 699, 995, 1314, 1516, 1878, 1464, 254, 1320, 573, 87, 1167, 186, 845, 566, 1851, 959, 441, 744, 647, 635, 636, 117, 1145, 1492, 420, 1335, 1778, 1214, 428, 672, 1336, 77, 1845, 1252, 416, 305, 639, 72, 1654, 898, 807, 333, 833, 239, 1769, 846, 228, 6, 89, 1844, 967, 726, 705, 802, 1266, 667, 682, 1547, 1704, 445, 1678, 1644, 752, 326, 1257, 1582, 1562, 1344, 977, 65, 1197, 1799, 715, 1768, 156, 852, 872, 189, 935, 1760, 1653, 1715, 272, 1574, 1422, 655, 658, 1031, 1354, 1565, 889, 1245, 279, 258, 1093, 1830, 1572, 784, 1227, 1451, 632, 1641, 963, 1807, 981, 1142, 549, 1148, 1490, 389, 1548, 394, 265, 1600, 992]\n",
      "layer3.0.downsample.0 [701, 90, 720, 575, 455, 621, 452, 347, 484, 294, 753, 506, 786, 721, 557, 154, 387, 628, 612, 445, 281, 334, 646, 586, 545, 84, 302, 411, 138, 877, 86, 726, 585, 459, 293, 322, 212, 663, 511, 35, 513, 525, 829, 396, 282, 108, 959, 653, 848, 312, 900, 768, 870, 104, 576, 353, 641, 504, 85, 189, 812, 65, 681, 735]\n",
      "layer2.0.downsample.0 [354, 477, 90, 408, 54, 74, 176, 331, 324, 0, 123, 59, 78, 307, 121, 266, 412, 260, 250, 65, 455, 339, 318, 129, 290, 288, 417, 432, 137, 212, 107, 52]\n",
      "layer1.0.downsample.0 [145, 0, 229, 33, 217, 59, 157, 25, 184, 92, 205, 87, 64, 65, 126, 56]\n",
      "conv1 [53, 30, 11, 54]\n",
      "layer1.0.conv2 [7, 20, 42, 26]\n",
      "layer1.0.conv1 [6, 20, 40, 22]\n",
      "layer1.1.conv2 [16, 41, 40, 9]\n",
      "layer1.1.conv1 [14, 52, 3, 44]\n",
      "layer1.2.conv2 [4, 36, 40, 7]\n",
      "layer1.2.conv1 [59, 53, 32, 18]\n",
      "layer2.0.conv2 [63, 108, 10, 48, 112, 84, 103, 0]\n",
      "layer2.0.conv1 [103, 114, 13, 113, 2, 11, 60, 82]\n",
      "layer2.1.conv2 [27, 24, 74, 51, 28, 36, 90, 118]\n",
      "layer2.1.conv1 [102, 71, 59, 25, 78, 74, 54, 11]\n",
      "layer2.2.conv2 [12, 93, 61, 21, 78, 53, 41, 34]\n",
      "layer2.2.conv1 [12, 116, 115, 6, 72, 84, 23, 44]\n",
      "layer2.3.conv2 [18, 63, 33, 5, 100, 90, 6, 101]\n",
      "layer2.3.conv1 [45, 27, 30, 98, 2, 40, 112, 96]\n",
      "layer3.0.conv2 [233, 142, 110, 182, 109, 40, 208, 120, 105, 218, 206, 187, 198, 212, 121, 77]\n",
      "layer3.0.conv1 [168, 42, 184, 87, 40, 223, 212, 76, 150, 52, 90, 119, 142, 162, 82, 83]\n",
      "layer3.1.conv2 [238, 82, 117, 39, 208, 215, 70, 68, 196, 20, 21, 178, 120, 142, 234, 190]\n",
      "layer3.1.conv1 [96, 137, 142, 143, 69, 90, 81, 50, 145, 217, 165, 88, 85, 38, 155, 215]\n",
      "layer3.2.conv2 [68, 81, 33, 14, 143, 104, 122, 213, 75, 16, 17, 3, 229, 35, 234, 225]\n",
      "layer3.2.conv1 [227, 226, 149, 152, 96, 91, 90, 87, 197, 21, 7, 51, 169, 54, 76, 75]\n",
      "layer3.3.conv2 [77, 184, 26, 140, 95, 207, 113, 239, 159, 204, 156, 198, 25, 67, 53, 42]\n",
      "layer3.3.conv1 [135, 37, 236, 171, 149, 187, 115, 197, 66, 210, 224, 105, 36, 182, 91, 200]\n",
      "layer3.4.conv2 [73, 174, 190, 33, 167, 154, 139, 162, 200, 90, 36, 228, 209, 31, 181, 186]\n",
      "layer3.4.conv1 [8, 50, 212, 18, 225, 1, 13, 141, 16, 19, 110, 20, 66, 155, 80, 178]\n",
      "layer3.5.conv2 [201, 167, 223, 0, 192, 109, 78, 208, 211, 44, 145, 8, 152, 85, 120, 206]\n",
      "layer3.5.conv1 [206, 107, 50, 28, 189, 144, 186, 43, 235, 98, 222, 68, 78, 62, 75, 1]\n",
      "layer4.0.conv2 [353, 355, 104, 429, 420, 50, 134, 467, 460, 375, 119, 57, 203, 237, 21, 217, 47, 153, 250, 390, 44, 120, 421, 14, 282, 148, 182, 339, 296, 36, 197, 16]\n",
      "layer4.0.conv1 [287, 281, 283, 219, 253, 238, 366, 407, 401, 405, 221, 99, 206, 217, 13, 316, 212, 448, 392, 116, 297, 386, 207, 190, 161, 214, 243, 396, 397, 294, 276, 218]\n",
      "layer4.1.conv2 [58, 71, 174, 397, 73, 395, 325, 326, 170, 169, 466, 141, 329, 81, 168, 83, 86, 449, 163, 321, 91, 161, 363, 341, 444, 99, 439, 342, 343, 126, 438, 31]\n",
      "layer4.1.conv1 [254, 330, 329, 157, 158, 194, 327, 192, 265, 190, 163, 189, 165, 201, 320, 167, 168, 319, 186, 300, 171, 264, 173, 263, 477, 25, 476, 312, 311, 474, 309, 31]\n",
      "layer4.2.conv2 [34, 262, 229, 51, 44, 40, 251, 470, 89, 255, 437, 462, 454, 93, 84, 446, 266, 353, 393, 77, 154, 432, 279, 67, 146, 363, 421, 102, 409, 269, 30, 408]\n",
      "layer4.2.conv1 [37, 415, 373, 213, 212, 422, 208, 207, 206, 361, 423, 424, 419, 358, 251, 355, 354, 252, 350, 253, 349, 346, 255, 23, 256, 25, 26, 257, 345, 343, 426, 340]\n",
      "Pruning step: 2 multiply–accumulate (macs): 3172561832.0 number of parameters 19798176\n",
      "layer4.0.downsample.0 [649, 567, 1428, 1629, 1048, 590, 209, 1589, 1625, 410, 265, 274, 420, 1712, 1341, 1481, 1106, 1514, 1197, 1714, 1615, 251, 1581, 416, 28, 326, 652, 489, 1129, 1694, 1698, 1633, 1487, 1571, 602, 618, 80, 454, 1755, 747, 1215, 195, 1614, 1579, 1469, 1476, 90, 1089, 695, 356, 1626, 913, 343, 1742, 1316, 1398, 123, 1149, 36, 874, 1475, 996, 1015, 1038, 394, 354, 1293, 1259, 1055, 1711, 248, 409, 18, 687, 1105, 825, 1329, 1005, 1192, 1047, 1733, 406, 1525, 78, 1660, 428, 1638, 1646, 450, 1705, 634, 61, 291, 258, 89, 1534, 1597, 254, 1065, 752, 188, 892, 1376, 1056, 1407, 1519, 1019, 1227, 510, 1771, 990, 1224, 1031, 260, 839, 360, 665, 238, 1531, 866, 1466, 976, 1747, 1775, 1722, 296, 395, 262]\n",
      "layer3.0.downsample.0 [620, 840, 533, 173, 850, 291, 250, 720, 629, 677, 812, 4, 426, 862, 488, 70, 221, 518, 19, 809, 514, 90, 719, 818, 409, 196, 796, 108, 132, 419, 40, 42, 806, 176, 714, 423, 295, 51, 472, 27, 331, 113, 823, 515, 888, 23, 617, 84, 708, 56, 77, 378, 289, 766, 542, 775, 279, 292, 745, 835, 597, 86, 34, 135]\n",
      "layer2.0.downsample.0 [405, 293, 432, 120, 330, 9, 331, 441, 273, 272, 423, 226, 174, 153, 333, 199, 171, 35, 212, 388, 310, 123, 349, 437, 231, 23, 198, 127, 69, 72, 312, 194]\n",
      "layer1.0.downsample.0 [66, 19, 128, 90, 103, 170, 12, 98, 96, 7, 121, 179, 167, 150, 189, 215]\n",
      "conv1 [51, 43, 2, 26]\n",
      "layer1.0.conv2 [11, 16, 53, 29]\n",
      "layer1.0.conv1 [48, 40, 29, 23]\n",
      "layer1.1.conv2 [35, 26, 16, 18]\n",
      "layer1.1.conv1 [7, 40, 37, 38]\n",
      "layer1.2.conv2 [43, 50, 1, 4]\n",
      "layer1.2.conv1 [52, 10, 46, 36]\n",
      "layer2.0.conv2 [88, 100, 9, 21, 18, 52, 98, 8]\n",
      "layer2.0.conv1 [4, 96, 97, 90, 50, 91, 49, 57]\n",
      "layer2.1.conv2 [85, 99, 75, 107, 54, 72, 88, 25]\n",
      "layer2.1.conv1 [97, 52, 55, 39, 50, 20, 28, 48]\n",
      "layer2.2.conv2 [107, 109, 87, 32, 43, 75, 29, 37]\n",
      "layer2.2.conv1 [96, 60, 94, 54, 15, 67, 104, 22]\n",
      "layer2.3.conv2 [97, 34, 99, 95, 100, 47, 102, 32]\n",
      "layer2.3.conv1 [100, 48, 19, 9, 101, 14, 37, 58]\n",
      "layer3.0.conv2 [63, 134, 172, 111, 187, 222, 196, 54, 211, 122, 104, 166, 39, 147, 11, 19]\n",
      "layer3.0.conv1 [37, 217, 182, 110, 27, 136, 30, 64, 67, 172, 129, 209, 76, 119, 223, 50]\n",
      "layer3.1.conv2 [216, 142, 50, 188, 193, 145, 203, 164, 7, 181, 141, 165, 42, 153, 78, 84]\n",
      "layer3.1.conv1 [188, 39, 189, 193, 194, 197, 69, 67, 75, 145, 127, 166, 114, 26, 99, 147]\n",
      "layer3.2.conv2 [211, 86, 36, 124, 55, 161, 9, 111, 38, 68, 7, 205, 15, 151, 70, 144]\n",
      "layer3.2.conv1 [201, 169, 123, 165, 134, 59, 143, 24, 107, 139, 82, 132, 43, 162, 188, 177]\n",
      "layer3.3.conv2 [74, 202, 146, 163, 174, 160, 192, 131, 170, 129, 116, 17, 158, 110, 9, 133]\n",
      "layer3.3.conv1 [38, 150, 3, 180, 52, 71, 213, 103, 206, 197, 95, 169, 173, 113, 134, 65]\n",
      "layer3.4.conv2 [186, 172, 48, 129, 76, 164, 19, 90, 12, 203, 104, 182, 216, 124, 51, 16]\n",
      "layer3.4.conv1 [157, 47, 171, 118, 85, 140, 6, 195, 5, 11, 30, 178, 19, 33, 165, 63]\n",
      "layer3.5.conv2 [27, 48, 74, 133, 194, 69, 114, 44, 125, 103, 94, 17, 217, 14, 146, 47]\n",
      "layer3.5.conv1 [81, 8, 173, 194, 153, 17, 114, 144, 49, 176, 222, 140, 107, 189, 90, 93]\n",
      "layer4.0.conv2 [259, 286, 70, 200, 21, 29, 325, 134, 382, 175, 144, 306, 257, 50, 288, 299, 147, 182, 346, 73, 244, 393, 234, 447, 211, 123, 421, 418, 293, 141, 274, 431]\n",
      "layer4.0.conv1 [41, 18, 277, 377, 102, 438, 110, 174, 112, 423, 286, 201, 358, 91, 243, 207, 308, 389, 391, 413, 141, 364, 251, 445, 289, 442, 336, 346, 209, 158, 144, 305]\n",
      "layer4.1.conv2 [66, 173, 41, 185, 43, 401, 52, 143, 286, 108, 396, 258, 147, 390, 320, 106, 384, 381, 188, 240, 60, 142, 271, 406, 54, 53, 407, 51, 325, 304, 31, 327]\n",
      "layer4.1.conv1 [62, 194, 196, 403, 402, 401, 399, 226, 197, 237, 202, 389, 387, 383, 204, 381, 260, 380, 375, 181, 374, 42, 261, 373, 206, 262, 209, 210, 264, 265, 267, 230]\n",
      "layer4.2.conv2 [111, 54, 95, 288, 40, 405, 160, 244, 365, 443, 151, 294, 371, 444, 252, 74, 251, 414, 418, 6, 208, 197, 225, 23, 333, 363, 3, 86, 139, 305, 250, 5]\n",
      "layer4.2.conv1 [50, 148, 236, 205, 206, 147, 207, 146, 144, 317, 141, 138, 137, 136, 135, 319, 216, 227, 218, 219, 226, 221, 321, 222, 132, 281, 446, 322, 442, 441, 440, 438]\n",
      "Pruning step: 3 multiply–accumulate (macs): 2744393352.0 number of parameters 17193500\n",
      "layer4.0.downsample.0 [1443, 1015, 1064, 598, 985, 1072, 1345, 165, 1180, 821, 92, 265, 713, 1653, 90, 562, 1472, 94, 36, 498, 1518, 95, 1421, 1540, 1045, 685, 18, 744, 259, 1047, 468, 97, 547, 1547, 350, 1605, 448, 1380, 797, 1522, 112, 504, 1152, 1090, 205, 991, 339, 762, 421, 1001, 952, 1455, 446, 1240, 1534, 1085, 955, 200, 672, 1346, 1198, 918, 802, 117, 101, 600, 96, 969, 9, 285, 1617, 268, 316, 1452, 1495, 607, 1607, 612, 1588, 1658, 1602, 1192, 1272, 507, 644, 1583, 650, 1370, 64, 174, 906, 1328, 1093, 791, 1153, 568, 470, 1194, 1600, 270, 560, 43, 546, 1389, 8, 410, 1473, 1010, 1134, 10, 333, 1566, 192, 466, 374, 981, 580, 266, 397, 878, 1445, 1166, 815, 229, 59, 639, 1519, 320]\n",
      "layer3.0.downsample.0 [234, 55, 639, 368, 788, 21, 74, 491, 761, 405, 812, 391, 365, 397, 307, 543, 224, 348, 232, 768, 206, 488, 643, 295, 494, 356, 498, 205, 486, 460, 310, 67, 141, 680, 617, 88, 19, 350, 161, 218, 328, 438, 585, 257, 388, 37, 394, 588, 33, 250, 420, 376, 109, 796, 724, 111, 518, 136, 625, 335, 94, 654, 80, 263]\n",
      "layer2.0.downsample.0 [226, 222, 80, 385, 58, 33, 56, 305, 7, 96, 136, 363, 336, 180, 368, 59, 205, 238, 112, 160, 99, 214, 358, 144, 129, 233, 88, 192, 239, 314, 142, 334]\n",
      "layer1.0.downsample.0 [24, 139, 121, 15, 3, 167, 114, 196, 49, 65, 46, 20, 45, 148, 25, 146]\n",
      "conv1 [29, 25, 2, 26]\n",
      "layer1.0.conv2 [13, 40, 35, 6]\n",
      "layer1.0.conv1 [29, 18, 46, 48]\n",
      "layer1.1.conv2 [21, 45, 46, 36]\n",
      "layer1.1.conv1 [33, 25, 28, 32]\n",
      "layer1.2.conv2 [41, 28, 42, 5]\n",
      "layer1.2.conv1 [47, 44, 51, 33]\n",
      "layer2.0.conv2 [19, 91, 37, 103, 59, 50, 30, 16]\n",
      "layer2.0.conv1 [81, 98, 65, 80, 83, 70, 92, 100]\n",
      "layer2.1.conv2 [78, 37, 84, 66, 87, 82, 7, 97]\n",
      "layer2.1.conv1 [23, 93, 83, 100, 24, 80, 14, 61]\n",
      "layer2.2.conv2 [2, 36, 89, 64, 68, 5, 70, 76]\n",
      "layer2.2.conv1 [41, 90, 80, 92, 45, 96, 69, 9]\n",
      "layer2.3.conv2 [46, 33, 56, 103, 64, 1, 90, 86]\n",
      "layer2.3.conv1 [56, 103, 0, 50, 10, 47, 16, 84]\n",
      "layer3.0.conv2 [83, 49, 94, 86, 174, 204, 75, 7, 201, 27, 77, 33, 108, 44, 206, 81]\n",
      "layer3.0.conv1 [202, 182, 207, 17, 157, 84, 155, 42, 104, 195, 132, 110, 122, 1, 107, 194]\n",
      "layer3.1.conv2 [155, 20, 127, 88, 124, 39, 45, 61, 14, 32, 46, 106, 176, 107, 202, 182]\n",
      "layer3.1.conv1 [183, 101, 109, 136, 199, 33, 36, 13, 19, 162, 186, 115, 189, 30, 111, 48]\n",
      "layer3.2.conv2 [83, 161, 54, 119, 143, 121, 196, 124, 91, 144, 82, 156, 129, 22, 6, 8]\n",
      "layer3.2.conv1 [167, 117, 165, 199, 191, 121, 190, 6, 140, 141, 21, 43, 0, 91, 163, 172]\n",
      "layer3.3.conv2 [43, 31, 162, 168, 165, 76, 88, 171, 13, 138, 104, 173, 18, 182, 96, 128]\n",
      "layer3.3.conv1 [53, 115, 171, 206, 28, 130, 50, 8, 114, 30, 18, 144, 78, 165, 60, 203]\n",
      "layer3.4.conv2 [56, 147, 39, 96, 23, 149, 102, 43, 137, 161, 70, 162, 4, 75, 151, 196]\n",
      "layer3.4.conv1 [154, 29, 70, 90, 74, 5, 185, 45, 155, 51, 85, 32, 205, 6, 158, 111]\n",
      "layer3.5.conv2 [75, 118, 20, 63, 197, 201, 122, 124, 121, 152, 204, 46, 39, 111, 35, 169]\n",
      "layer3.5.conv1 [8, 82, 74, 71, 29, 204, 11, 156, 42, 31, 46, 182, 184, 20, 62, 88]\n",
      "layer4.0.conv2 [143, 185, 85, 153, 210, 72, 58, 244, 386, 51, 1, 119, 392, 93, 192, 300, 284, 303, 89, 95, 320, 172, 165, 311, 337, 74, 38, 369, 57, 223, 391, 393]\n",
      "layer4.0.conv1 [216, 109, 328, 157, 24, 248, 153, 102, 391, 208, 337, 211, 396, 187, 210, 333, 285, 7, 103, 276, 171, 349, 183, 177, 163, 93, 371, 261, 1, 383, 260, 382]\n",
      "layer4.1.conv2 [95, 93, 92, 269, 34, 43, 354, 139, 59, 235, 27, 76, 399, 65, 135, 160, 91, 96, 288, 315, 243, 161, 267, 40, 284, 298, 374, 221, 208, 141, 88, 25]\n",
      "layer4.1.conv1 [320, 79, 84, 149, 86, 237, 90, 215, 96, 339, 336, 207, 102, 103, 107, 109, 324, 322, 36, 312, 406, 405, 311, 306, 404, 113, 403, 115, 402, 401, 118, 398]\n",
      "layer4.2.conv2 [255, 6, 326, 129, 413, 325, 74, 311, 61, 206, 324, 285, 174, 266, 56, 281, 126, 333, 318, 187, 256, 4, 121, 67, 41, 2, 267, 26, 31, 97, 147, 25]\n",
      "layer4.2.conv1 [52, 349, 350, 347, 101, 171, 103, 344, 341, 336, 175, 333, 109, 110, 322, 112, 178, 415, 297, 286, 117, 284, 119, 283, 282, 122, 123, 124, 279, 126, 276, 128]\n",
      "Pruning step: 4 multiply–accumulate (macs): 2347233640.0 number of parameters 14771992\n",
      "layer4.0.downsample.0 [189, 1026, 165, 1408, 657, 573, 73, 1420, 337, 675, 696, 1276, 1364, 862, 85, 1074, 511, 1531, 1304, 1130, 601, 961, 919, 864, 856, 819, 409, 401, 1148, 27, 1015, 1183, 1473, 1362, 893, 97, 1079, 689, 1082, 484, 1499, 418, 832, 1267, 1418, 661, 1025, 1428, 9, 1319, 388, 887, 1211, 1235, 1438, 1435, 1406, 1351, 710, 1234, 979, 990, 1031, 423, 1269, 1360, 1073, 929, 1345, 1516, 1083, 843, 314, 53, 1421, 530, 245, 1201, 1390, 942, 273, 1318, 680, 232, 1165, 477, 1464, 1279, 1460, 719, 270, 718, 150, 93, 1388, 660, 1416, 33, 541, 350, 1121, 1302, 259, 820, 128, 1294, 593, 743, 534, 874, 1246, 622, 538, 1402, 1482, 492, 1363, 580, 1346, 758, 390, 1316, 1185, 11, 732, 237, 1448, 379]\n",
      "layer3.0.downsample.0 [76, 394, 766, 67, 284, 87, 662, 41, 306, 157, 691, 259, 110, 413, 172, 490, 460, 713, 167, 392, 262, 137, 371, 193, 8, 747, 684, 195, 566, 379, 118, 257, 488, 498, 524, 273, 198, 317, 151, 514, 515, 233, 731, 348, 408, 111, 543, 669, 121, 376, 253, 589, 155, 226, 533, 355, 649, 331, 439, 633, 201, 508, 722, 741]\n",
      "layer2.0.downsample.0 [371, 349, 261, 101, 238, 135, 328, 361, 48, 253, 370, 11, 20, 373, 233, 376, 82, 214, 34, 19, 311, 321, 131, 296, 27, 346, 300, 285, 237, 2, 355, 383]\n",
      "layer1.0.downsample.0 [156, 168, 15, 33, 151, 48, 31, 185, 175, 184, 114, 3, 178, 77, 75, 46]\n",
      "conv1 [15, 44, 39, 36]\n",
      "layer1.0.conv2 [10, 30, 40, 23]\n",
      "layer1.0.conv1 [35, 4, 8, 16]\n",
      "layer1.1.conv2 [1, 10, 2, 33]\n",
      "layer1.1.conv1 [10, 31, 18, 5]\n",
      "layer1.2.conv2 [44, 11, 45, 39]\n",
      "layer1.2.conv1 [9, 2, 36, 11]\n",
      "layer2.0.conv2 [17, 54, 71, 26, 60, 88, 83, 52]\n",
      "layer2.0.conv1 [40, 69, 79, 17, 78, 19, 1, 45]\n",
      "layer2.1.conv2 [10, 38, 72, 69, 7, 4, 93, 8]\n",
      "layer2.1.conv1 [87, 57, 13, 30, 9, 10, 11, 42]\n",
      "layer2.2.conv2 [37, 90, 16, 69, 50, 92, 63, 15]\n",
      "layer2.2.conv1 [2, 37, 47, 62, 36, 19, 53, 75]\n",
      "layer2.3.conv2 [38, 44, 77, 41, 53, 73, 1, 0]\n",
      "layer2.3.conv1 [28, 26, 72, 73, 71, 10, 87, 48]\n",
      "layer3.0.conv2 [104, 72, 135, 82, 147, 93, 47, 136, 125, 86, 84, 79, 19, 45, 67, 54]\n",
      "layer3.0.conv1 [85, 27, 75, 62, 8, 96, 4, 190, 92, 163, 30, 58, 128, 93, 191, 106]\n",
      "layer3.1.conv2 [85, 29, 82, 36, 163, 175, 66, 6, 108, 130, 121, 170, 142, 25, 32, 76]\n",
      "layer3.1.conv1 [29, 180, 181, 184, 187, 177, 23, 81, 77, 151, 162, 190, 118, 16, 147, 130]\n",
      "layer3.2.conv2 [26, 122, 131, 83, 185, 92, 77, 64, 10, 132, 28, 189, 75, 107, 126, 70]\n",
      "layer3.2.conv1 [112, 126, 5, 73, 143, 103, 23, 74, 51, 31, 100, 131, 136, 124, 92, 170]\n",
      "layer3.3.conv2 [131, 163, 31, 133, 187, 54, 99, 83, 142, 151, 85, 127, 13, 12, 56, 156]\n",
      "layer3.3.conv1 [132, 83, 94, 18, 55, 93, 145, 66, 39, 1, 150, 158, 61, 136, 62, 161]\n",
      "layer3.4.conv2 [184, 159, 142, 183, 180, 49, 165, 104, 45, 12, 136, 15, 177, 99, 20, 85]\n",
      "layer3.4.conv1 [29, 186, 81, 147, 54, 146, 150, 164, 190, 173, 18, 125, 6, 83, 115, 141]\n",
      "layer3.5.conv2 [24, 146, 91, 23, 127, 179, 2, 141, 3, 64, 118, 40, 145, 139, 82, 144]\n",
      "layer3.5.conv1 [153, 96, 131, 163, 30, 65, 156, 26, 64, 25, 38, 31, 2, 10, 186, 144]\n",
      "layer4.0.conv2 [11, 244, 222, 220, 314, 286, 190, 119, 57, 13, 260, 161, 256, 24, 306, 258, 138, 35, 82, 116, 231, 134, 379, 363, 48, 80, 122, 281, 150, 158, 125, 157]\n",
      "layer4.0.conv1 [265, 92, 117, 9, 344, 29, 302, 268, 326, 135, 95, 223, 152, 193, 176, 80, 5, 97, 356, 121, 93, 179, 215, 184, 225, 217, 199, 138, 24, 286, 270, 256]\n",
      "layer4.1.conv2 [7, 357, 192, 27, 232, 355, 187, 283, 352, 73, 138, 274, 293, 26, 67, 11, 100, 23, 43, 288, 3, 31, 146, 343, 268, 154, 277, 261, 225, 158, 121, 90]\n",
      "layer4.1.conv1 [46, 175, 129, 128, 236, 246, 242, 245, 115, 77, 367, 366, 360, 359, 357, 356, 57, 354, 353, 58, 59, 133, 111, 64, 130, 270, 68, 271, 107, 273, 275, 277]\n",
      "layer4.2.conv2 [343, 215, 289, 6, 178, 381, 270, 170, 319, 328, 272, 68, 193, 70, 196, 143, 339, 47, 112, 243, 192, 171, 255, 162, 312, 220, 217, 214, 4, 121, 227, 360]\n",
      "layer4.2.conv1 [96, 326, 363, 80, 323, 82, 361, 84, 85, 94, 87, 356, 88, 67, 339, 322, 92, 153, 69, 70, 248, 71, 72, 73, 247, 74, 189, 245, 254, 77, 60, 244]\n",
      "Pruning step: 5 multiply–accumulate (macs): 1981082696.0 number of parameters 12533652\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 44, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(44, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(44, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(44, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(176, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(44, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(176, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(44, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(176, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(88, 88, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(88, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(176, 352, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(352, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(88, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(352, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(88, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(352, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(88, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(352, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(176, 176, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(176, 704, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(352, 704, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(704, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(176, 704, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(704, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(176, 704, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(704, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(176, 704, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(704, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(176, 704, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(704, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(176, 704, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(704, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(352, 352, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(704, 1408, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1408, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1408, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=1408, out_features=1000, bias=True)\n",
      ")\n",
      "Pruning sparsity: 0.375\n",
      "layer4.0.downsample.0 [112, 167, 1326, 892, 93, 653, 1978, 1993, 605, 143, 338, 100, 1288, 616, 1542, 2035, 663, 854, 619, 1530, 1094, 1058, 327, 1051, 881, 311, 1748, 898, 831, 471, 275, 675, 468, 1772, 1694, 1001, 1201, 1578, 1925, 351, 1077, 1193, 887, 1570, 1639, 583, 1144, 1592, 1427, 1980, 61, 1344, 309, 416, 745, 1843, 839, 1292, 1154, 1156, 1850, 950, 1203, 1727, 1257, 1009, 760, 2, 2040, 1126, 1477, 1888, 102, 2020, 1093, 1749, 968, 1743, 623, 751, 1158, 1349, 40, 1532, 2046, 80, 929, 1810, 563, 794, 305, 1056, 16, 1906, 1555, 1139, 1221, 1736, 1510, 1014, 629, 108, 415, 456, 1262, 1702, 1055, 861, 1819, 955, 1444, 1726, 195, 1595, 899, 1371, 1929, 478, 382, 533, 1645, 158, 1253, 427, 695, 144, 66, 833, 660, 743, 558, 1974, 362, 1625, 153, 449, 1439, 447, 1958, 975, 194, 526, 617, 715, 1492, 204, 1834, 307, 32, 1608, 685, 622, 1673, 706]\n",
      "layer3.0.downsample.0 [853, 962, 486, 1018, 197, 303, 412, 170, 1023, 729, 500, 491, 91, 759, 544, 96, 657, 980, 906, 388, 803, 60, 1011, 1017, 501, 595, 644, 444, 38, 151, 194, 741, 966, 51, 685, 18, 923, 927, 873, 709, 123, 683, 72, 825, 778, 589, 390, 656, 928, 149, 83, 728, 331, 609, 487, 836, 732, 45, 311, 511, 800, 579, 325, 744, 716, 92, 419, 352, 619, 767, 16, 647, 371, 536, 662, 590, 457]\n",
      "layer2.0.downsample.0 [243, 387, 412, 176, 347, 246, 404, 34, 24, 163, 100, 53, 11, 114, 207, 371, 33, 96, 98, 43, 311, 363, 66, 424, 184, 495, 166, 85, 438, 188, 326, 147, 149, 328, 81, 361, 65, 509, 411]\n",
      "layer1.0.downsample.0 [144, 77, 108, 214, 150, 112, 58, 103, 131, 29, 235, 0, 63, 225, 156, 31, 196, 233, 10, 231]\n",
      "conv1 [13, 42, 44, 57, 52]\n",
      "layer1.0.conv2 [0, 1, 44, 19, 22]\n",
      "layer1.0.conv1 [1, 27, 38, 7, 60]\n",
      "layer1.1.conv2 [44, 6, 45, 17, 25]\n",
      "layer1.1.conv1 [2, 56, 4, 55, 9]\n",
      "layer1.2.conv2 [11, 7, 4, 57, 51]\n",
      "layer1.2.conv1 [2, 49, 39, 45, 11]\n",
      "layer2.0.conv2 [35, 90, 29, 51, 3, 119, 4, 69, 120, 99]\n",
      "layer2.0.conv1 [112, 92, 89, 104, 8, 63, 68, 66, 2, 61]\n",
      "layer2.1.conv2 [9, 93, 10, 121, 120, 109, 54, 46, 100, 29]\n",
      "layer2.1.conv1 [1, 111, 3, 5, 102, 58, 76, 83, 112, 14]\n",
      "layer2.2.conv2 [29, 56, 18, 39, 75, 34, 101, 12, 35, 125]\n",
      "layer2.2.conv1 [38, 75, 120, 117, 112, 63, 40, 102, 124, 12]\n",
      "layer2.3.conv2 [127, 17, 124, 36, 67, 113, 21, 76, 95, 8]\n",
      "layer2.3.conv1 [6, 74, 120, 9, 37, 79, 114, 52, 23, 119]\n",
      "layer3.0.conv2 [13, 141, 2, 106, 54, 248, 35, 250, 157, 133, 4, 232, 115, 207, 151, 152, 199, 116, 194, 219]\n",
      "layer3.0.conv1 [48, 4, 89, 148, 245, 254, 139, 136, 220, 110, 103, 90, 196, 18, 236, 44, 225, 238, 135, 178]\n",
      "layer3.1.conv2 [24, 209, 88, 191, 42, 108, 72, 7, 8, 85, 146, 100, 164, 155, 127, 221, 16, 56, 74, 123]\n",
      "layer3.1.conv1 [32, 165, 181, 231, 54, 85, 56, 92, 162, 171, 172, 11, 79, 13, 77, 76, 229, 88, 225, 188]\n",
      "layer3.2.conv2 [35, 196, 117, 79, 108, 149, 156, 43, 17, 157, 30, 47, 234, 87, 228, 233, 245, 99, 131, 153]\n",
      "layer3.2.conv1 [97, 164, 99, 167, 56, 242, 155, 105, 29, 47, 30, 216, 100, 210, 148, 134, 51, 153, 196, 161]\n",
      "layer3.3.conv2 [247, 35, 190, 148, 127, 131, 34, 100, 161, 146, 157, 26, 37, 255, 218, 82, 25, 169, 197, 76]\n",
      "layer3.3.conv1 [24, 189, 214, 31, 124, 211, 9, 219, 100, 195, 79, 19, 59, 41, 99, 180, 181, 209, 75, 254]\n",
      "layer3.4.conv2 [19, 144, 53, 244, 169, 242, 50, 41, 126, 105, 252, 165, 116, 150, 79, 207, 42, 35, 20, 164]\n",
      "layer3.4.conv1 [10, 204, 60, 110, 26, 6, 99, 100, 40, 73, 19, 87, 168, 108, 48, 192, 153, 14, 55, 43]\n",
      "layer3.5.conv2 [239, 219, 215, 203, 91, 183, 142, 59, 38, 143, 221, 186, 94, 127, 137, 135, 206, 8, 45, 224]\n",
      "layer3.5.conv1 [10, 1, 190, 3, 204, 200, 126, 203, 84, 70, 205, 251, 250, 29, 249, 112, 16, 114, 236, 153]\n",
      "layer4.0.conv2 [12, 143, 238, 326, 178, 103, 461, 46, 203, 452, 48, 244, 269, 342, 231, 111, 286, 91, 365, 284, 84, 371, 192, 272, 160, 378, 78, 381, 383, 386, 388, 35, 127, 61, 492, 130, 216, 511, 409]\n",
      "layer4.0.conv1 [8, 394, 53, 34, 467, 314, 231, 312, 16, 309, 10, 338, 304, 410, 219, 15, 457, 132, 107, 425, 268, 252, 203, 230, 124, 431, 510, 326, 143, 487, 488, 253, 31, 500, 234, 429, 426, 220, 406]\n",
      "layer4.1.conv2 [32, 352, 116, 118, 120, 370, 122, 480, 8, 369, 355, 368, 12, 134, 357, 475, 178, 180, 18, 469, 465, 177, 375, 183, 313, 185, 299, 256, 193, 459, 194, 294, 202, 204, 458, 205, 36, 291, 454]\n",
      "layer4.1.conv1 [418, 452, 450, 448, 444, 443, 442, 7, 441, 9, 10, 285, 436, 435, 434, 284, 280, 17, 228, 19, 428, 427, 22, 426, 424, 25, 422, 229, 421, 29, 231, 31, 275, 233, 419, 35, 72, 416, 234]\n",
      "layer4.2.conv2 [0, 219, 284, 201, 80, 283, 6, 7, 8, 9, 353, 11, 469, 463, 87, 403, 125, 281, 92, 362, 453, 96, 99, 441, 166, 105, 440, 243, 507, 245, 426, 359, 32, 33, 417, 160, 270, 37, 425]\n",
      "layer4.2.conv1 [0, 407, 405, 423, 424, 5, 6, 427, 428, 398, 396, 431, 434, 13, 14, 15, 16, 394, 18, 19, 436, 438, 440, 23, 24, 447, 26, 382, 381, 29, 443, 510, 379, 445, 34, 450, 453, 37, 456]\n",
      "Pruning step: 1 multiply–accumulate (macs): 3520505718.0 number of parameters 21952302\n",
      "layer4.0.downsample.0 [1635, 1010, 1097, 984, 1827, 1589, 737, 1306, 1844, 1349, 198, 1250, 643, 348, 1691, 1853, 1319, 253, 280, 1476, 1233, 71, 187, 1728, 434, 1478, 76, 1383, 1285, 1680, 436, 1553, 946, 86, 1756, 1777, 505, 1168, 1113, 994, 482, 6, 1107, 692, 1328, 418, 836, 1549, 635, 708, 799, 1747, 305, 275, 1682, 1096, 1565, 835, 964, 200, 823, 1437, 677, 954, 1532, 1197, 325, 425, 1821, 1566, 461, 662, 50, 1558, 535, 1799, 109, 258, 440, 1337, 272, 631, 1017, 923, 1036, 227, 1411, 515, 663, 1147, 1645, 1513, 776, 1571, 1356, 110, 926, 1556, 1667, 281, 621, 388, 1582, 798, 1229, 1634, 628, 1210, 443, 654, 1386, 64, 294, 950, 548, 1694, 1106, 269, 1480, 978, 1720, 968, 1130, 1533, 1723, 1054, 1576, 1742, 221, 1072, 864, 842, 1609, 1520, 1871, 1208, 1071, 1338, 1046, 638, 329, 1815, 739, 744, 1331, 1035, 1719, 912, 1842, 1127, 128, 1666, 1241, 1330]\n",
      "layer3.0.downsample.0 [88, 708, 691, 94, 577, 382, 280, 107, 740, 479, 900, 713, 462, 309, 439, 449, 507, 292, 852, 568, 539, 115, 519, 397, 763, 505, 651, 544, 656, 946, 381, 863, 690, 185, 391, 343, 319, 188, 545, 668, 78, 630, 525, 191, 859, 867, 261, 356, 139, 406, 120, 152, 855, 177, 856, 103, 726, 65, 348, 822, 499, 757, 453, 142, 35, 83, 469, 84, 19, 71, 239, 912, 478, 41, 446, 881, 95]\n",
      "layer2.0.downsample.0 [348, 171, 405, 318, 312, 341, 0, 119, 255, 428, 325, 245, 54, 261, 448, 350, 283, 24, 450, 466, 207, 285, 128, 89, 76, 10, 417, 436, 222, 425, 351, 230, 308, 288, 125, 287, 412, 446]\n",
      "layer1.0.downsample.0 [85, 32, 62, 124, 225, 154, 90, 202, 71, 136, 19, 55, 12, 63, 110, 103, 232, 105, 158]\n",
      "conv1 [30, 11, 53, 54, 45]\n",
      "layer1.0.conv2 [7, 56, 55, 54, 12]\n",
      "layer1.0.conv1 [21, 54, 52, 44, 42]\n",
      "layer1.1.conv2 [38, 35, 9, 24, 37]\n",
      "layer1.1.conv1 [44, 42, 40, 10, 12]\n",
      "layer1.2.conv2 [21, 15, 32, 40, 0]\n",
      "layer1.2.conv1 [58, 31, 17, 47, 52]\n",
      "layer2.0.conv2 [93, 48, 49, 0, 89, 105, 107, 56, 11, 102]\n",
      "layer2.0.conv1 [112, 101, 111, 59, 10, 12, 99, 100, 114, 1]\n",
      "layer2.1.conv2 [27, 35, 72, 116, 88, 112, 24, 104, 93, 79]\n",
      "layer2.1.conv1 [58, 64, 24, 57, 25, 100, 73, 108, 54, 52]\n",
      "layer2.2.conv2 [20, 41, 47, 2, 78, 37, 40, 74, 33, 94]\n",
      "layer2.2.conv1 [83, 114, 71, 6, 43, 24, 78, 101, 63, 16]\n",
      "layer2.3.conv2 [104, 53, 103, 99, 0, 38, 108, 98, 101, 54]\n",
      "layer2.3.conv1 [45, 4, 27, 53, 96, 30, 0, 67, 40, 2]\n",
      "layer3.0.conv2 [119, 204, 205, 147, 179, 234, 195, 229, 140, 90, 105, 40, 118, 107, 194, 209, 127, 55, 173]\n",
      "layer3.0.conv1 [181, 176, 148, 193, 140, 82, 198, 66, 75, 1, 40, 118, 226, 51, 37, 27, 86, 126, 144]\n",
      "layer3.1.conv2 [118, 234, 119, 116, 199, 74, 20, 218, 208, 230, 209, 226, 215, 99, 7, 150, 51, 86, 171]\n",
      "layer3.1.conv1 [141, 92, 224, 158, 40, 229, 68, 139, 47, 118, 138, 171, 205, 133, 84, 184, 194, 131, 60]\n",
      "layer3.2.conv2 [151, 75, 14, 103, 186, 32, 222, 175, 171, 230, 139, 128, 51, 167, 155, 68, 3, 94, 120]\n",
      "layer3.2.conv1 [23, 20, 8, 176, 57, 223, 54, 118, 194, 90, 217, 212, 24, 1, 78, 79, 133, 165, 110]\n",
      "layer3.3.conv2 [194, 116, 156, 200, 66, 17, 78, 140, 111, 218, 203, 104, 184, 213, 154, 135, 202, 33, 168]\n",
      "layer3.3.conv1 [73, 104, 53, 147, 39, 196, 233, 139, 54, 65, 19, 117, 184, 100, 192, 156, 199, 133, 221]\n",
      "layer3.4.conv2 [170, 196, 182, 193, 107, 88, 4, 163, 76, 195, 158, 177, 78, 137, 205, 60, 26, 18, 224]\n",
      "layer3.4.conv1 [14, 38, 222, 220, 16, 148, 172, 8, 180, 105, 55, 90, 188, 147, 17, 174, 106, 107, 95]\n",
      "layer3.5.conv2 [0, 81, 204, 73, 28, 132, 229, 39, 232, 99, 15, 108, 152, 109, 49, 121, 228, 77, 3]\n",
      "layer3.5.conv1 [3, 123, 177, 187, 155, 68, 18, 185, 229, 50, 204, 125, 43, 28, 62, 163, 115, 7, 71]\n",
      "layer4.0.conv2 [24, 245, 21, 212, 321, 276, 314, 45, 130, 417, 217, 56, 384, 60, 418, 278, 232, 366, 247, 387, 178, 327, 16, 144, 309, 116, 371, 307, 251, 386, 265, 269, 443, 74, 149, 224, 80, 1]\n",
      "layer4.0.conv1 [392, 106, 98, 216, 240, 436, 387, 357, 10, 14, 414, 264, 215, 235, 20, 119, 366, 412, 292, 399, 294, 403, 117, 378, 332, 450, 211, 437, 323, 278, 218, 269, 114, 470, 48, 234, 203, 304]\n",
      "layer4.1.conv2 [326, 62, 138, 203, 246, 308, 247, 143, 70, 71, 73, 194, 410, 405, 396, 394, 145, 390, 304, 256, 377, 371, 259, 81, 361, 359, 83, 152, 86, 153, 357, 162, 160, 159, 407, 35, 209, 91]\n",
      "layer4.1.conv1 [59, 253, 392, 211, 389, 436, 386, 385, 438, 439, 258, 380, 206, 374, 445, 372, 204, 446, 370, 202, 266, 200, 199, 196, 362, 361, 359, 192, 356, 191, 451, 31, 189, 455, 456, 35, 36, 37]\n",
      "layer4.2.conv2 [448, 45, 269, 276, 456, 322, 281, 282, 142, 53, 134, 307, 283, 194, 165, 305, 170, 311, 469, 139, 440, 160, 244, 61, 169, 362, 356, 365, 158, 355, 352, 339, 338, 34, 470, 38, 268, 464]\n",
      "layer4.2.conv1 [42, 319, 210, 318, 240, 212, 317, 213, 214, 215, 239, 315, 218, 314, 313, 312, 219, 220, 311, 221, 222, 224, 227, 230, 24, 308, 231, 307, 305, 232, 234, 31, 304, 33, 34, 35, 237, 320]\n",
      "Pruning step: 2 multiply–accumulate (macs): 2977856940.0 number of parameters 18690753\n",
      "layer4.0.downsample.0 [603, 1339, 1377, 1061, 366, 643, 1368, 1332, 1008, 845, 1668, 606, 1434, 976, 1094, 590, 1582, 481, 194, 1480, 500, 1038, 621, 422, 583, 1187, 1571, 1102, 357, 1170, 627, 1737, 1033, 248, 597, 1226, 425, 1382, 377, 8, 499, 490, 146, 1615, 1596, 1199, 737, 1169, 1538, 445, 9, 1311, 1165, 259, 1597, 1735, 784, 1088, 392, 801, 78, 1220, 1112, 1508, 278, 1437, 1570, 579, 478, 1479, 607, 927, 203, 409, 619, 1493, 1705, 1247, 242, 174, 739, 617, 656, 1680, 1017, 725, 1601, 414, 1534, 19, 43, 80, 1411, 82, 106, 12, 1442, 1306, 175, 1376, 529, 1532, 61, 1666, 1062, 387, 825, 629, 495, 1084, 1624, 934, 1328, 447, 559, 104, 64, 1196, 1521, 108, 834, 292, 1163, 1248, 1206, 216, 1673, 1659, 1641, 1078, 1068, 1467, 1448, 1661, 555, 249, 878, 13, 88, 1451, 1649, 293, 307, 1685, 1639, 800, 637, 648, 48, 680, 777, 284, 356]\n",
      "layer3.0.downsample.0 [749, 283, 767, 516, 833, 82, 274, 54, 323, 794, 189, 4, 798, 563, 40, 508, 568, 163, 234, 138, 496, 511, 775, 660, 454, 453, 825, 655, 244, 667, 22, 73, 469, 216, 210, 652, 184, 586, 58, 269, 23, 406, 364, 414, 81, 736, 42, 520, 732, 815, 159, 278, 505, 576, 370, 686, 722, 862, 774, 280, 597, 141, 596, 642, 648, 517, 362, 402, 753, 267, 119, 640, 809, 744, 436, 830, 26]\n",
      "layer2.0.downsample.0 [253, 381, 223, 425, 49, 197, 152, 168, 7, 33, 380, 205, 58, 193, 60, 420, 198, 115, 69, 304, 62, 136, 352, 97, 240, 341, 173, 376, 92, 111, 34, 170, 157, 151, 306, 325, 117, 338, 28]\n",
      "layer1.0.downsample.0 [22, 16, 199, 88, 183, 173, 48, 7, 116, 143, 160, 163, 118, 172, 26, 125, 51, 165, 21]\n",
      "conv1 [2, 26, 31, 27, 28]\n",
      "layer1.0.conv2 [22, 37, 28, 13, 42]\n",
      "layer1.0.conv1 [37, 40, 29, 31, 18]\n",
      "layer1.1.conv2 [16, 25, 48, 47, 18]\n",
      "layer1.1.conv1 [35, 25, 32, 28, 14]\n",
      "layer1.2.conv2 [32, 48, 7, 24, 40]\n",
      "layer1.2.conv1 [48, 45, 53, 35, 2]\n",
      "layer2.0.conv2 [9, 107, 61, 34, 99, 35, 95, 18, 70]\n",
      "layer2.0.conv1 [67, 103, 97, 90, 45, 76, 86, 49, 89]\n",
      "layer2.1.conv2 [88, 84, 38, 41, 72, 7, 81, 54, 25]\n",
      "layer2.1.conv1 [39, 97, 11, 28, 60, 24, 65, 20, 48]\n",
      "layer2.2.conv2 [4, 27, 79, 46, 37, 70, 73, 92, 54]\n",
      "layer2.2.conv1 [20, 100, 2, 46, 99, 9, 95, 82, 38]\n",
      "layer2.3.conv2 [59, 93, 55, 16, 37, 67, 32, 94, 0]\n",
      "layer2.3.conv1 [98, 55, 97, 13, 10, 88, 107, 35, 32]\n",
      "layer3.0.conv2 [109, 39, 98, 131, 75, 62, 190, 205, 19, 144, 210, 213, 47, 181, 90, 11, 52, 215, 6]\n",
      "layer3.0.conv1 [101, 42, 201, 74, 108, 28, 72, 63, 209, 215, 112, 29, 178, 163, 16, 8, 94, 4, 162]\n",
      "layer3.1.conv2 [41, 183, 197, 159, 160, 174, 135, 176, 32, 129, 39, 109, 138, 95, 20, 14, 211, 76, 47]\n",
      "layer3.1.conv1 [184, 38, 183, 66, 188, 81, 163, 198, 113, 26, 180, 31, 192, 105, 34, 142, 17, 19, 119]\n",
      "layer3.2.conv2 [78, 7, 138, 70, 35, 10, 204, 38, 93, 40, 26, 72, 31, 57, 3, 77, 34, 84, 9]\n",
      "layer3.2.conv1 [152, 208, 135, 43, 174, 121, 161, 130, 35, 21, 171, 183, 172, 214, 7, 59, 122, 200, 109]\n",
      "layer3.3.conv2 [36, 159, 14, 144, 174, 50, 19, 166, 170, 130, 45, 39, 155, 185, 79, 147, 115, 129, 91]\n",
      "layer3.3.conv1 [207, 35, 80, 70, 53, 9, 99, 200, 60, 162, 28, 191, 75, 167, 92, 174, 170, 118, 168]\n",
      "layer3.4.conv2 [32, 119, 166, 17, 11, 59, 86, 183, 204, 153, 15, 124, 28, 172, 41, 158, 151, 99, 37]\n",
      "layer3.4.conv1 [1, 190, 19, 36, 55, 7, 162, 165, 187, 59, 56, 41, 215, 161, 6, 30, 114, 214, 152]\n",
      "layer3.5.conv2 [79, 70, 108, 152, 40, 208, 25, 38, 161, 44, 128, 43, 123, 140, 65, 76, 131, 189, 45]\n",
      "layer3.5.conv1 [66, 75, 93, 29, 47, 20, 112, 89, 215, 210, 92, 84, 5, 79, 118, 191, 183, 11, 74]\n",
      "layer4.0.conv2 [227, 150, 11, 423, 316, 60, 195, 41, 131, 25, 403, 240, 319, 397, 180, 179, 97, 385, 87, 371, 377, 20, 76, 270, 65, 144, 315, 158, 418, 54, 407, 356, 269, 409, 297, 247, 171, 160, 38]\n",
      "layer4.0.conv1 [197, 412, 402, 99, 171, 48, 281, 387, 224, 243, 225, 239, 233, 352, 154, 272, 169, 301, 399, 153, 336, 249, 100, 101, 184, 291, 245, 166, 288, 190, 271, 82, 260, 381, 343, 7, 143, 340, 97]\n",
      "layer4.1.conv2 [54, 48, 42, 57, 185, 45, 428, 217, 296, 143, 297, 299, 52, 53, 222, 84, 55, 40, 400, 90, 337, 179, 100, 197, 391, 125, 395, 103, 405, 268, 111, 51, 321, 389, 281, 150, 317, 29, 236]\n",
      "layer4.1.conv1 [54, 119, 129, 229, 131, 225, 215, 224, 120, 136, 431, 430, 429, 140, 141, 142, 422, 421, 145, 420, 419, 148, 405, 403, 402, 152, 153, 401, 396, 395, 393, 158, 391, 232, 210, 123, 160, 37, 161]\n",
      "layer4.2.conv2 [147, 143, 145, 245, 81, 302, 354, 244, 9, 36, 248, 281, 69, 299, 239, 367, 391, 201, 20, 246, 408, 76, 82, 190, 356, 42, 26, 340, 2, 334, 89, 185, 195, 3, 140, 57, 100, 366, 287]\n",
      "layer4.2.conv1 [108, 388, 252, 387, 250, 247, 384, 172, 383, 381, 245, 174, 373, 177, 240, 361, 238, 237, 357, 236, 184, 186, 187, 188, 234, 190, 351, 350, 349, 233, 348, 192, 193, 232, 196, 197, 198, 200, 226]\n",
      "Pruning step: 3 multiply–accumulate (macs): 2486448119.0 number of parameters 15672450\n",
      "layer4.0.downsample.0 [1171, 1025, 200, 330, 1527, 308, 225, 251, 403, 126, 1421, 1511, 477, 310, 1309, 709, 967, 78, 1491, 88, 202, 1023, 175, 1507, 190, 235, 1324, 1076, 1386, 583, 1573, 751, 1452, 409, 1402, 440, 100, 1387, 747, 40, 1429, 622, 1523, 230, 1405, 1451, 913, 659, 253, 567, 86, 912, 338, 1193, 911, 1139, 1038, 1115, 624, 305, 1444, 1469, 874, 511, 1455, 1463, 540, 288, 1155, 109, 1277, 245, 718, 436, 1186, 861, 953, 1559, 1040, 830, 1365, 612, 148, 1514, 454, 957, 1045, 261, 216, 725, 93, 291, 1103, 1226, 1369, 1368, 1125, 1085, 1547, 15, 1192, 1430, 611, 949, 553, 106, 430, 1397, 321, 1156, 104, 1308, 155, 548, 364, 287, 762, 480, 124, 989, 1465, 1342, 658, 1577, 33, 1138, 414, 1466, 1127, 1094, 632, 252, 361, 324, 653, 860, 892, 1278, 1339, 1583, 125, 279, 1356, 917, 463, 1357, 952, 740, 257, 962, 1288, 954, 887, 1010]\n",
      "layer3.0.downsample.0 [297, 791, 71, 469, 773, 751, 81, 283, 408, 118, 350, 414, 255, 13, 631, 481, 731, 373, 179, 347, 647, 412, 200, 274, 686, 681, 375, 512, 554, 59, 619, 637, 251, 578, 365, 70, 164, 45, 711, 85, 463, 466, 314, 77, 710, 740, 371, 29, 491, 254, 688, 94, 320, 644, 130, 19, 714, 208, 442, 323, 106, 716, 771, 271, 358, 239, 269, 244, 458, 510, 41, 377, 424, 516, 397, 610, 149]\n",
      "layer2.0.downsample.0 [23, 210, 202, 271, 136, 323, 383, 361, 54, 128, 225, 201, 220, 151, 134, 169, 333, 263, 33, 373, 300, 291, 82, 112, 320, 328, 243, 277, 311, 89, 223, 295, 293, 248, 353, 382, 369, 34]\n",
      "layer1.0.downsample.0 [42, 22, 190, 3, 192, 186, 60, 16, 162, 4, 191, 138, 158, 17, 81, 51, 172, 35, 140]\n",
      "conv1 [2, 45, 40, 16, 10]\n",
      "layer1.0.conv2 [24, 11, 31, 6, 41]\n",
      "layer1.0.conv1 [18, 37, 43, 4, 16]\n",
      "layer1.1.conv2 [35, 10, 36, 1, 2]\n",
      "layer1.1.conv1 [31, 32, 29, 17, 5]\n",
      "layer1.2.conv2 [34, 23, 17, 42, 16]\n",
      "layer1.2.conv1 [46, 8, 36, 10, 1]\n",
      "layer2.0.conv2 [59, 9, 30, 50, 18, 58, 13, 71, 76, 37]\n",
      "layer2.0.conv1 [40, 82, 47, 69, 3, 80, 94, 70, 79, 81]\n",
      "layer2.1.conv2 [85, 82, 1, 78, 4, 69, 39, 5, 8, 95]\n",
      "layer2.1.conv1 [22, 57, 12, 79, 32, 76, 95, 89, 74, 13]\n",
      "layer2.2.conv2 [29, 92, 94, 91, 13, 46, 38, 16, 64, 18]\n",
      "layer2.2.conv1 [85, 60, 46, 48, 38, 35, 87, 18, 47, 53]\n",
      "layer2.3.conv2 [88, 1, 30, 0, 98, 27, 34, 4, 40, 41]\n",
      "layer2.3.conv1 [15, 8, 74, 45, 28, 76, 48, 75, 17, 18]\n",
      "layer3.0.conv2 [91, 102, 26, 76, 72, 6, 141, 98, 74, 110, 131, 194, 49, 32, 146, 142, 165, 78, 87]\n",
      "layer3.0.conv1 [175, 63, 152, 91, 71, 133, 27, 1, 94, 100, 64, 41, 98, 112, 127, 115, 130, 173, 161]\n",
      "layer3.1.conv2 [15, 29, 56, 136, 100, 41, 6, 117, 173, 189, 68, 36, 176, 153, 32, 78, 167, 25, 85]\n",
      "layer3.1.conv1 [176, 82, 189, 23, 60, 13, 156, 155, 129, 182, 148, 185, 109, 177, 29, 190, 168, 139, 89]\n",
      "layer3.2.conv2 [76, 130, 63, 136, 186, 155, 75, 84, 145, 53, 124, 50, 192, 195, 39, 21, 95, 23, 82]\n",
      "layer3.2.conv1 [6, 140, 90, 161, 22, 25, 14, 26, 106, 77, 114, 20, 148, 75, 136, 53, 135, 0, 13]\n",
      "layer3.3.conv2 [159, 32, 48, 136, 55, 131, 164, 9, 91, 86, 41, 168, 154, 147, 31, 99, 14, 139, 193]\n",
      "layer3.3.conv1 [57, 107, 135, 157, 28, 3, 95, 174, 14, 156, 139, 58, 11, 105, 46, 94, 54, 154, 144]\n",
      "layer3.4.conv2 [178, 189, 43, 152, 106, 141, 182, 46, 69, 40, 95, 145, 86, 151, 194, 12, 64, 138, 27]\n",
      "layer3.4.conv1 [177, 8, 152, 109, 158, 106, 180, 67, 88, 72, 147, 23, 57, 131, 159, 82, 193, 31, 71]\n",
      "layer3.5.conv2 [115, 149, 105, 82, 42, 160, 117, 174, 131, 143, 148, 2, 161, 47, 15, 150, 145, 151, 98]\n",
      "layer3.5.conv1 [122, 158, 3, 7, 126, 135, 175, 117, 153, 32, 40, 172, 176, 78, 161, 31, 26, 166, 2]\n",
      "layer4.0.conv2 [29, 372, 255, 391, 140, 155, 25, 83, 164, 234, 233, 156, 126, 54, 81, 148, 319, 297, 332, 292, 329, 252, 27, 271, 198, 157, 111, 159, 12, 85, 109, 120, 373, 376, 368, 165, 273, 69]\n",
      "layer4.0.conv1 [129, 186, 1, 261, 147, 269, 370, 118, 328, 137, 35, 371, 93, 152, 165, 148, 9, 194, 301, 157, 299, 367, 322, 202, 315, 149, 97, 387, 105, 286, 30, 120, 357, 182, 275, 335, 132, 216]\n",
      "layer4.1.conv2 [287, 378, 300, 161, 11, 221, 366, 9, 355, 130, 345, 382, 295, 168, 97, 87, 187, 288, 142, 283, 27, 25, 235, 324, 28, 165, 364, 2, 48, 139, 189, 252, 153, 271, 55, 4, 372, 197]\n",
      "layer4.1.conv1 [62, 102, 298, 150, 296, 104, 295, 252, 73, 106, 75, 76, 148, 164, 246, 112, 78, 145, 263, 81, 115, 244, 243, 144, 286, 262, 160, 87, 121, 122, 279, 259, 159, 158, 157, 93, 278, 230]\n",
      "layer4.2.conv2 [242, 4, 250, 366, 136, 308, 6, 175, 315, 71, 148, 174, 5, 119, 311, 106, 115, 144, 252, 58, 54, 116, 96, 192, 281, 372, 91, 164, 182, 253, 297, 264, 196, 10, 225, 60, 363, 259]\n",
      "layer4.2.conv1 [46, 295, 130, 163, 121, 244, 123, 129, 161, 164, 165, 291, 157, 166, 287, 286, 206, 227, 284, 281, 204, 203, 188, 93, 280, 202, 279, 394, 199, 296, 353, 126, 275, 358, 363, 364, 368, 273]\n",
      "Pruning step: 4 multiply–accumulate (macs): 2033869720.0 number of parameters 12935549\n",
      "layer4.0.downsample.0 [1114, 785, 938, 640, 1339, 1080, 577, 688, 958, 370, 143, 282, 1204, 1103, 1379, 803, 182, 1331, 518, 332, 1193, 29, 841, 1239, 801, 583, 1273, 247, 471, 9, 266, 1095, 539, 304, 1036, 1192, 588, 1376, 624, 1032, 123, 271, 922, 865, 1201, 907, 404, 521, 514, 713, 1428, 867, 759, 1347, 1135, 1253, 503, 421, 508, 1086, 52, 842, 823, 159, 623, 934, 857, 895, 439, 653, 942, 356, 1012, 1297, 766, 1286, 1214, 1280, 676, 1366, 968, 923, 5, 1295, 891, 1026, 650, 435, 354, 702, 415, 1048, 506, 1130, 932, 386, 1194, 301, 33, 27, 965, 41, 789, 323, 875, 1187, 1035, 1001, 1226, 187, 668, 81, 716, 457, 756, 153, 844, 689, 835, 1275, 2, 473, 607, 534, 1369, 428, 1415, 1408, 105, 362, 470, 317, 1199, 565, 1410, 555, 1175, 1332, 870, 986, 155, 149, 138, 1418, 1131, 1296, 1064, 888, 927, 723, 1293, 465, 1264]\n",
      "layer3.0.downsample.0 [39, 617, 205, 346, 435, 382, 626, 214, 502, 380, 99, 480, 640, 146, 158, 230, 509, 55, 126, 588, 240, 310, 45, 462, 471, 362, 594, 216, 112, 492, 30, 59, 312, 411, 387, 611, 81, 690, 586, 313, 695, 696, 36, 538, 120, 499, 566, 8, 657, 383, 27, 358, 397, 183, 161, 242, 474, 481, 673, 326, 402, 262, 610, 162, 605, 687, 422, 691, 504, 410, 524, 217, 674, 298, 655, 487]\n",
      "layer2.0.downsample.0 [350, 20, 262, 254, 136, 11, 333, 347, 8, 19, 318, 44, 315, 202, 93, 121, 325, 269, 73, 218, 65, 308, 151, 70, 86, 66, 138, 280, 102, 112, 270, 320, 215, 226, 53, 85, 139, 111]\n",
      "layer1.0.downsample.0 [163, 42, 158, 51, 35, 30, 62, 173, 0, 157, 174, 44, 58, 22, 28, 168, 20, 156, 8]\n",
      "conv1 [3, 34, 18, 39]\n",
      "layer1.0.conv2 [23, 10, 18, 38]\n",
      "layer1.0.conv1 [26, 7, 38, 23]\n",
      "layer1.1.conv2 [30, 35, 0, 27]\n",
      "layer1.1.conv1 [40, 25, 7, 8]\n",
      "layer1.2.conv2 [0, 41, 3, 11]\n",
      "layer1.2.conv1 [16, 34, 29, 13]\n",
      "layer2.0.conv2 [75, 78, 17, 66, 5, 8, 15, 11, 18]\n",
      "layer2.0.conv1 [82, 6, 18, 48, 43, 42, 84, 12, 62]\n",
      "layer2.1.conv2 [83, 47, 59, 78, 49, 4, 58, 6, 7]\n",
      "layer2.1.conv1 [28, 39, 13, 38, 61, 44, 9, 66, 10]\n",
      "layer2.2.conv2 [64, 16, 59, 14, 78, 77, 85, 65, 45]\n",
      "layer2.2.conv1 [68, 55, 29, 85, 64, 46, 28, 63, 82]\n",
      "layer2.3.conv2 [12, 27, 4, 20, 70, 46, 29, 31, 55]\n",
      "layer2.3.conv1 [10, 44, 71, 84, 2, 28, 38, 15, 5]\n",
      "layer3.0.conv2 [76, 119, 27, 175, 110, 44, 138, 147, 106, 42, 21, 171, 173, 74, 31, 136, 105, 77, 65]\n",
      "layer3.0.conv1 [114, 173, 176, 178, 68, 97, 103, 125, 106, 113, 25, 57, 148, 20, 5, 99, 53, 52, 108]\n",
      "layer3.1.conv2 [92, 163, 132, 73, 93, 64, 37, 99, 94, 104, 71, 9, 121, 125, 115, 84, 103, 57, 141]\n",
      "layer3.1.conv1 [169, 174, 64, 177, 29, 32, 99, 119, 114, 155, 4, 141, 93, 122, 74, 154, 118, 43, 31]\n",
      "layer3.2.conv2 [122, 64, 37, 12, 58, 115, 52, 67, 159, 79, 26, 163, 105, 47, 70, 50, 121, 102, 71]\n",
      "layer3.2.conv1 [109, 66, 130, 69, 3, 67, 12, 4, 147, 102, 75, 118, 119, 25, 51, 165, 112, 121, 114]\n",
      "layer3.3.conv2 [52, 20, 102, 53, 110, 144, 146, 76, 154, 51, 132, 12, 92, 119, 136, 38, 149, 77, 86]\n",
      "layer3.3.conv1 [119, 37, 134, 110, 123, 144, 14, 175, 136, 131, 73, 56, 16, 124, 95, 91, 57, 161, 147]\n",
      "layer3.4.conv2 [168, 36, 110, 28, 18, 152, 61, 117, 54, 7, 147, 155, 91, 45, 144, 114, 172, 29, 21]\n",
      "layer3.4.conv1 [5, 142, 154, 125, 49, 153, 84, 139, 57, 19, 173, 7, 145, 8, 122, 127, 87, 107, 9]\n",
      "layer3.5.conv2 [55, 86, 22, 78, 50, 166, 18, 158, 2, 119, 113, 107, 97, 134, 49, 132, 114, 7, 129]\n",
      "layer3.5.conv1 [104, 152, 101, 27, 4, 59, 18, 165, 102, 23, 159, 8, 54, 136, 53, 35, 22, 32, 98]\n",
      "layer4.0.conv2 [224, 111, 114, 277, 116, 74, 178, 32, 118, 298, 35, 237, 191, 144, 225, 303, 44, 161, 90, 110, 296, 209, 218, 117, 46, 339, 154, 11, 312, 241, 347, 352, 98, 246, 268, 171, 357, 322]\n",
      "layer4.0.conv1 [92, 34, 328, 229, 113, 247, 33, 319, 212, 0, 165, 208, 171, 67, 91, 346, 265, 304, 128, 307, 251, 163, 255, 343, 112, 273, 86, 254, 180, 311, 44, 60, 134, 119, 233, 315, 149, 140]\n",
      "layer4.1.conv2 [56, 61, 208, 200, 341, 19, 95, 75, 131, 23, 68, 32, 189, 353, 111, 53, 185, 41, 138, 195, 92, 81, 166, 213, 254, 269, 168, 263, 10, 229, 62, 46, 309, 104, 247, 123, 175, 109]\n",
      "layer4.1.conv1 [88, 43, 92, 136, 45, 91, 65, 184, 185, 50, 93, 224, 262, 216, 39, 55, 236, 56, 57, 239, 265, 268, 67, 302, 269, 169, 99, 80, 195, 76, 166, 113, 207, 264, 41, 33, 254, 153]\n",
      "layer4.2.conv2 [244, 40, 254, 238, 100, 179, 235, 199, 44, 162, 208, 93, 115, 218, 20, 198, 35, 22, 175, 192, 252, 290, 217, 165, 111, 347, 49, 355, 148, 176, 241, 310, 320, 24, 304, 57, 350, 315]\n",
      "layer4.2.conv1 [44, 70, 71, 247, 347, 73, 246, 244, 346, 242, 345, 76, 241, 240, 237, 78, 341, 80, 229, 227, 81, 217, 82, 83, 84, 340, 211, 86, 87, 90, 92, 93, 94, 95, 336, 97, 334, 333]\n",
      "Pruning step: 5 multiply–accumulate (macs): 1645940520.0 number of parameters 10478480\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 40, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(640, 1280, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
      ")\n",
      "Pruning sparsity: 0.4375\n",
      "layer4.0.downsample.0 [143, 1561, 1126, 1154, 892, 1447, 338, 108, 898, 1349, 991, 1058, 12, 112, 1326, 653, 1288, 1449, 1427, 100, 311, 831, 1465, 275, 1827, 351, 93, 1257, 2035, 1748, 61, 1099, 1694, 1888, 1542, 167, 437, 1993, 2046, 80, 309, 583, 1492, 533, 854, 899, 1253, 416, 560, 1980, 124, 218, 745, 839, 1144, 327, 1158, 728, 1958, 1727, 1530, 1532, 1009, 605, 751, 1850, 663, 66, 968, 478, 619, 296, 468, 794, 881, 1555, 1077, 1906, 1201, 847, 563, 1344, 1999, 1124, 1156, 1925, 305, 1292, 700, 1868, 1880, 204, 32, 715, 449, 955, 144, 2, 1743, 1070, 1510, 1051, 808, 1056, 1568, 570, 929, 1444, 861, 307, 695, 1726, 455, 1460, 362, 1974, 241, 1496, 7, 1192, 1578, 1819, 1619, 195, 301, 1262, 660, 456, 1371, 2040, 1312, 610, 1843, 1608, 1941, 415, 1477, 48, 1193, 1932, 1055, 685, 427, 860, 1968, 1570, 1221, 16, 40, 1108, 158, 1929, 1749, 623, 801, 833, 1318, 622, 1718, 975, 2020, 207, 726, 1375, 706, 382, 1613, 526, 128, 734, 1770, 1246, 1428, 688, 1676, 1600, 2042, 472, 1693, 909]\n",
      "layer3.0.downsample.0 [853, 962, 170, 486, 1018, 544, 197, 657, 412, 1023, 491, 644, 60, 803, 151, 303, 1017, 906, 595, 500, 741, 96, 980, 729, 18, 501, 419, 927, 590, 444, 194, 51, 923, 928, 16, 778, 709, 685, 609, 656, 38, 487, 352, 91, 92, 123, 728, 966, 511, 514, 149, 748, 331, 311, 759, 494, 83, 1011, 541, 340, 732, 390, 825, 310, 647, 371, 610, 45, 972, 619, 105, 744, 900, 536, 772, 747, 766, 620, 478, 1022, 873, 118, 579, 37, 475, 205, 662, 701, 909, 776]\n",
      "layer2.0.downsample.0 [387, 176, 246, 243, 404, 347, 100, 412, 34, 11, 424, 163, 114, 33, 0, 43, 53, 98, 66, 363, 495, 326, 24, 379, 371, 311, 85, 207, 509, 166, 438, 188, 149, 40, 192, 60, 309, 133, 81, 339, 372, 361, 353, 10, 382]\n",
      "layer1.0.downsample.0 [144, 108, 214, 150, 112, 77, 131, 58, 103, 68, 29, 225, 235, 31, 156, 92, 0, 233, 10, 195, 231, 36, 63]\n",
      "conv1 [44, 13, 42, 52, 57, 11]\n",
      "layer1.0.conv2 [0, 1, 44, 19, 22, 61]\n",
      "layer1.0.conv1 [38, 1, 58, 45, 56, 5]\n",
      "layer1.1.conv2 [44, 38, 6, 41, 25, 45]\n",
      "layer1.1.conv1 [42, 41, 38, 23, 4, 40]\n",
      "layer1.2.conv2 [11, 7, 4, 57, 24, 39]\n",
      "layer1.2.conv1 [2, 49, 39, 45, 63, 52]\n",
      "layer2.0.conv2 [35, 51, 119, 3, 69, 4, 29, 90, 101, 111, 53, 120]\n",
      "layer2.0.conv1 [112, 92, 89, 63, 104, 8, 68, 66, 14, 61, 110, 2]\n",
      "layer2.1.conv2 [10, 93, 26, 9, 29, 77, 46, 100, 109, 54, 120, 121]\n",
      "layer2.1.conv1 [1, 83, 3, 69, 5, 79, 76, 63, 14, 58, 118, 112]\n",
      "layer2.2.conv2 [29, 56, 18, 39, 34, 75, 101, 43, 2, 125, 22, 12]\n",
      "layer2.2.conv1 [63, 75, 120, 117, 112, 38, 102, 12, 40, 6, 124, 123]\n",
      "layer2.3.conv2 [127, 17, 36, 124, 0, 76, 21, 113, 111, 67, 19, 8]\n",
      "layer2.3.conv1 [120, 74, 6, 114, 4, 49, 37, 9, 52, 23, 79, 33]\n",
      "layer3.0.conv2 [13, 4, 151, 106, 248, 250, 157, 152, 35, 141, 54, 133, 232, 207, 254, 2, 150, 221, 222, 115, 116, 199, 194]\n",
      "layer3.0.conv1 [254, 4, 89, 90, 220, 110, 48, 148, 245, 136, 18, 135, 152, 244, 92, 50, 134, 236, 225, 139, 194, 196, 73]\n",
      "layer3.1.conv2 [188, 235, 130, 229, 132, 133, 228, 7, 8, 9, 221, 191, 209, 100, 56, 42, 16, 127, 254, 250, 123, 111, 82]\n",
      "layer3.1.conv1 [32, 142, 171, 172, 144, 149, 173, 79, 150, 50, 41, 54, 103, 13, 77, 76, 231, 75, 229, 194, 73, 65, 225]\n",
      "layer3.2.conv2 [79, 149, 35, 196, 117, 43, 108, 17, 233, 157, 99, 156, 56, 234, 47, 245, 87, 14, 153, 81, 240, 30, 186]\n",
      "layer3.2.conv1 [164, 1, 153, 181, 155, 23, 99, 105, 51, 97, 30, 47, 242, 29, 167, 134, 192, 212, 20, 210, 24, 100, 56]\n",
      "layer3.3.conv2 [190, 247, 148, 127, 35, 146, 85, 34, 26, 131, 197, 161, 82, 157, 169, 37, 71, 43, 100, 119, 217, 255, 38]\n",
      "layer3.3.conv1 [180, 124, 195, 71, 181, 240, 254, 75, 79, 100, 219, 31, 189, 58, 19, 59, 24, 214, 41, 244, 217, 9, 167]\n",
      "layer3.4.conv2 [244, 42, 105, 19, 79, 50, 252, 144, 169, 186, 242, 116, 126, 53, 35, 41, 165, 241, 16, 149, 117, 115, 96]\n",
      "layer3.4.conv1 [208, 100, 242, 55, 6, 48, 8, 10, 40, 204, 26, 122, 73, 108, 110, 19, 21, 99, 164, 20, 71, 123, 193]\n",
      "layer3.5.conv2 [91, 183, 94, 85, 186, 215, 219, 142, 203, 206, 221, 38, 77, 105, 59, 222, 143, 239, 52, 141, 137, 208, 8]\n",
      "layer3.5.conv1 [133, 1, 29, 248, 70, 5, 114, 126, 200, 246, 10, 112, 203, 204, 197, 220, 16, 190, 81, 38, 250, 249, 84]\n",
      "layer4.0.conv2 [284, 84, 266, 326, 171, 388, 231, 319, 306, 409, 506, 80, 12, 46, 143, 15, 91, 48, 236, 78, 286, 461, 61, 492, 422, 192, 365, 244, 178, 127, 371, 157, 111, 381, 383, 386, 160, 272, 269, 203, 268, 453, 238, 144, 441]\n",
      "layer4.0.conv1 [128, 284, 510, 234, 501, 488, 487, 485, 8, 467, 10, 457, 12, 53, 124, 15, 16, 55, 436, 126, 431, 429, 425, 189, 416, 132, 447, 219, 406, 394, 383, 338, 336, 225, 34, 326, 107, 227, 314, 253, 230, 203, 309, 112, 0]\n",
      "layer4.1.conv2 [18, 223, 352, 214, 134, 291, 292, 480, 505, 355, 205, 224, 12, 204, 475, 470, 202, 469, 36, 465, 464, 280, 228, 229, 294, 459, 507, 277, 28, 237, 194, 31, 163, 269, 454, 35, 267, 448, 193, 256, 40, 299, 185, 442, 439]\n",
      "layer4.1.conv1 [128, 302, 301, 294, 228, 229, 292, 7, 231, 9, 10, 11, 12, 306, 233, 234, 286, 17, 236, 19, 285, 284, 22, 222, 280, 25, 241, 27, 441, 29, 30, 31, 32, 243, 244, 35, 275, 246, 247, 274, 269, 41, 264, 43, 44]\n",
      "layer4.2.conv2 [0, 307, 156, 277, 302, 294, 99, 125, 8, 243, 158, 284, 219, 26, 328, 245, 160, 453, 441, 440, 283, 331, 281, 426, 425, 469, 270, 419, 266, 92, 173, 333, 32, 33, 257, 417, 176, 508, 507, 502, 178, 336, 213, 43, 403]\n",
      "layer4.2.conv1 [64, 460, 398, 3, 464, 5, 6, 7, 466, 396, 395, 394, 392, 13, 14, 15, 16, 468, 18, 19, 511, 382, 380, 23, 24, 379, 26, 378, 376, 29, 30, 375, 371, 471, 34, 473, 370, 37, 38, 39, 367, 41, 366, 364, 44]\n",
      "Pruning step: 1 multiply–accumulate (macs): 3423238924.0 number of parameters 21402189\n",
      "layer4.0.downsample.0 [1478, 1533, 1452, 298, 988, 474, 1314, 1235, 1137, 1660, 83, 562, 124, 202, 1725, 1455, 1544, 953, 174, 47, 628, 1303, 68, 625, 1311, 1171, 407, 1532, 734, 1226, 786, 1573, 1290, 1755, 318, 1791, 267, 884, 428, 1023, 411, 1184, 417, 781, 1511, 811, 1662, 222, 640, 1775, 453, 943, 1537, 1601, 823, 1336, 1613, 1065, 676, 911, 1763, 646, 383, 64, 914, 1535, 615, 655, 939, 1646, 1624, 1549, 622, 108, 432, 259, 1561, 722, 152, 1214, 435, 1196, 1118, 355, 225, 1416, 539, 287, 386, 1643, 614, 1499, 1703, 1490, 107, 264, 957, 1512, 591, 1699, 1700, 1042, 967, 1094, 1005, 1626, 1670, 1087, 95, 673, 450, 1717, 729, 1084, 1740, 73, 1543, 1583, 341, 381, 932, 44, 699, 1597, 994, 196, 1460, 135, 274, 1800, 80, 1059, 862, 260, 744, 1218, 1811, 1645, 1112, 1722, 8, 1006, 1588, 219, 1734, 1820, 1179, 1101, 233, 1019, 895, 1315, 1653, 406, 785, 1060, 864, 669, 105, 358, 1784, 1555, 447, 561, 1849, 1806, 1782, 851, 1797, 1102, 37, 1077, 275, 631, 804, 935, 395, 921, 1647]\n",
      "layer3.0.downsample.0 [855, 888, 302, 379, 661, 730, 306, 609, 175, 789, 437, 648, 339, 841, 88, 349, 277, 512, 657, 208, 532, 537, 729, 852, 699, 500, 426, 845, 103, 493, 763, 715, 627, 622, 83, 71, 388, 118, 806, 19, 89, 441, 745, 473, 42, 180, 449, 296, 102, 554, 361, 229, 544, 137, 415, 44, 4, 878, 875, 856, 566, 113, 492, 753, 394, 704, 150, 711, 844, 183, 562, 140, 541, 352, 775, 307, 91, 644, 747, 56, 14, 557, 145, 23, 900, 344, 518, 303, 24, 78]\n",
      "layer2.0.downsample.0 [83, 422, 371, 130, 404, 243, 125, 49, 259, 87, 205, 299, 55, 253, 206, 430, 115, 306, 163, 281, 159, 344, 234, 22, 444, 399, 324, 228, 122, 460, 7, 73, 267, 214, 181, 220, 61, 346, 34, 442, 284, 156, 207, 176, 285]\n",
      "layer1.0.downsample.0 [222, 121, 61, 87, 69, 151, 178, 199, 54, 12, 19, 133, 94, 17, 128, 50, 155, 196, 100, 186, 126, 176]\n",
      "conv1 [29, 53, 52, 44, 2, 26]\n",
      "layer1.0.conv2 [7, 24, 55, 54, 12, 39]\n",
      "layer1.0.conv1 [42, 18, 19, 39, 5, 21]\n",
      "layer1.1.conv2 [16, 9, 28, 37, 25, 52]\n",
      "layer1.1.conv1 [14, 49, 8, 12, 50, 41]\n",
      "layer1.2.conv2 [38, 31, 52, 40, 43, 46]\n",
      "layer1.2.conv1 [32, 10, 52, 51, 54, 18]\n",
      "layer2.0.conv2 [105, 101, 55, 48, 34, 36, 107, 91, 0, 20, 115]\n",
      "layer2.0.conv1 [10, 110, 58, 109, 92, 79, 4, 51, 98, 112, 1]\n",
      "layer2.1.conv2 [34, 86, 114, 26, 102, 88, 110, 77, 43, 84, 91]\n",
      "layer2.1.conv1 [101, 92, 98, 24, 25, 52, 54, 57, 41, 26, 105]\n",
      "layer2.2.conv2 [76, 29, 86, 80, 59, 100, 4, 39, 92, 27, 109]\n",
      "layer2.2.conv1 [42, 108, 82, 70, 103, 23, 100, 62, 77, 15, 2]\n",
      "layer2.3.conv2 [98, 102, 31, 37, 106, 87, 96, 5, 97, 104, 49]\n",
      "layer2.3.conv1 [26, 38, 95, 108, 2, 104, 0, 115, 19, 93, 15]\n",
      "layer3.0.conv2 [146, 194, 40, 227, 119, 118, 105, 202, 193, 207, 220, 178, 127, 19, 139, 39, 55, 64, 114, 77, 172, 192]\n",
      "layer3.0.conv1 [95, 174, 40, 141, 51, 116, 81, 190, 163, 37, 1, 66, 195, 87, 27, 157, 78, 117, 42, 74, 226, 17]\n",
      "layer3.1.conv2 [132, 141, 225, 66, 100, 81, 150, 78, 19, 20, 153, 217, 68, 201, 196, 43, 172, 93, 211, 51, 149, 89]\n",
      "layer3.1.conv1 [202, 86, 84, 146, 81, 149, 77, 169, 74, 168, 40, 162, 226, 221, 201, 197, 148, 196, 110, 117, 26, 224]\n",
      "layer3.2.conv2 [209, 33, 152, 172, 8, 66, 27, 165, 73, 80, 137, 183, 81, 118, 10, 164, 31, 3, 91, 100, 227, 37]\n",
      "layer3.2.conv1 [134, 220, 86, 53, 194, 163, 7, 176, 106, 25, 145, 140, 188, 74, 172, 224, 129, 62, 186, 183, 50, 75]\n",
      "layer3.3.conv2 [113, 215, 175, 197, 153, 200, 165, 187, 69, 134, 168, 102, 119, 184, 17, 46, 51, 151, 155, 132, 20, 81]\n",
      "layer3.3.conv1 [103, 36, 230, 194, 56, 89, 111, 192, 196, 116, 207, 63, 29, 39, 19, 178, 173, 216, 71, 186, 182, 74]\n",
      "layer3.4.conv2 [188, 194, 35, 148, 203, 156, 159, 193, 191, 134, 161, 19, 179, 76, 78, 31, 174, 177, 198, 92, 63, 212]\n",
      "layer3.4.conv1 [75, 50, 95, 37, 126, 1, 55, 180, 90, 149, 21, 64, 171, 205, 105, 146, 45, 67, 186, 11, 173, 123]\n",
      "layer3.5.conv2 [0, 118, 226, 77, 28, 76, 126, 202, 43, 3, 105, 205, 229, 106, 50, 201, 171, 165, 150, 83, 225, 18]\n",
      "layer3.5.conv1 [86, 42, 61, 49, 228, 2, 184, 153, 120, 140, 96, 52, 187, 122, 175, 28, 100, 147, 161, 206, 217, 51]\n",
      "layer4.0.conv2 [131, 466, 411, 119, 344, 341, 272, 303, 274, 56, 247, 380, 257, 382, 60, 197, 20, 243, 33, 211, 142, 191, 308, 79, 208, 437, 116, 455, 106, 148, 322, 265, 310, 67, 94, 23, 192, 440, 261, 412, 1, 100, 367, 222, 36]\n",
      "layer4.0.conv1 [374, 231, 431, 230, 287, 236, 436, 280, 12, 141, 457, 439, 320, 18, 245, 265, 301, 396, 461, 392, 210, 378, 173, 443, 103, 453, 202, 322, 167, 198, 84, 194, 163, 387, 290, 253, 175, 203, 291, 25, 216, 188, 408, 464, 211]\n",
      "layer4.1.conv2 [56, 81, 345, 111, 79, 228, 112, 230, 371, 236, 239, 136, 321, 54, 140, 354, 71, 450, 318, 69, 278, 68, 317, 145, 283, 147, 303, 287, 113, 389, 343, 390, 174, 170, 169, 60, 154, 168, 299, 39, 41, 297, 163, 44, 161]\n",
      "layer4.1.conv1 [116, 289, 445, 179, 440, 439, 433, 432, 181, 430, 429, 427, 426, 425, 183, 184, 420, 419, 418, 417, 185, 187, 188, 407, 405, 403, 189, 27, 28, 29, 60, 191, 399, 33, 192, 398, 36, 397, 286, 392, 40, 391, 42, 43, 390]\n",
      "layer4.2.conv2 [334, 78, 329, 333, 326, 335, 64, 304, 280, 279, 317, 173, 56, 40, 320, 41, 348, 352, 48, 47, 89, 452, 172, 315, 81, 361, 141, 9, 97, 422, 74, 440, 259, 154, 167, 13, 3, 6, 186, 32, 351, 314, 268, 92, 29]\n",
      "layer4.2.conv1 [58, 229, 396, 230, 235, 393, 232, 390, 389, 386, 385, 398, 400, 402, 405, 377, 374, 373, 406, 407, 372, 371, 370, 412, 367, 25, 415, 27, 28, 29, 418, 466, 339, 66, 338, 419, 36, 336, 38, 335, 421, 434, 334, 43, 44]\n",
      "Pruning step: 2 multiply–accumulate (macs): 2806647960.0 number of parameters 17663237\n",
      "layer4.0.downsample.0 [74, 938, 604, 1162, 1650, 988, 617, 963, 393, 755, 1196, 1367, 1442, 57, 694, 1466, 1668, 1257, 1339, 1004, 1128, 1033, 1194, 557, 616, 592, 1044, 155, 1150, 1043, 1301, 1005, 772, 643, 1441, 798, 1400, 1392, 434, 263, 269, 165, 1323, 786, 1514, 1411, 1516, 383, 805, 10, 56, 1627, 651, 1275, 492, 1530, 1100, 770, 1455, 278, 793, 582, 460, 989, 76, 619, 184, 901, 1210, 225, 1428, 491, 340, 572, 1361, 1572, 11, 1007, 1541, 1104, 1097, 81, 1076, 1586, 1625, 424, 432, 752, 1468, 1006, 1603, 476, 999, 420, 1494, 388, 1159, 1050, 8, 944, 1168, 236, 890, 1099, 1621, 1491, 753, 1557, 1020, 210, 1169, 1058, 164, 1390, 1126, 305, 518, 1142, 24, 262, 537, 1208, 1188, 1001, 871, 478, 1317, 561, 1496, 290, 479, 318, 1543, 1270, 631, 1641, 795, 1444, 1612, 459, 976, 63, 17, 1684, 100, 1158, 293, 962, 625, 1481, 1662, 1410, 1508, 1580, 133, 1149, 375, 594, 230, 654, 1262, 1529, 1125, 360, 456, 771, 317, 1655, 911, 1678, 1242, 1163, 1083, 977, 862, 433, 241, 421, 1403]\n",
      "layer3.0.downsample.0 [35, 209, 57, 56, 648, 163, 238, 412, 22, 69, 227, 667, 774, 271, 353, 730, 459, 571, 553, 362, 340, 484, 269, 355, 786, 632, 46, 701, 208, 659, 548, 761, 236, 784, 290, 221, 316, 495, 624, 98, 84, 143, 444, 393, 799, 836, 80, 263, 76, 100, 388, 677, 397, 751, 731, 561, 52, 395, 44, 823, 687, 77, 500, 305, 333, 114, 73, 807, 210, 427, 570, 418, 523, 261, 178, 778, 284, 371, 302, 733, 288, 513, 692, 65, 139, 478, 361, 626, 231]\n",
      "layer2.0.downsample.0 [222, 64, 116, 180, 364, 407, 161, 226, 366, 336, 371, 183, 351, 145, 291, 325, 308, 398, 34, 375, 109, 306, 214, 276, 111, 412, 360, 408, 130, 322, 281, 20, 27, 35, 421, 92, 238, 149, 137, 381, 54, 384, 413, 338, 285]\n",
      "layer1.0.downsample.0 [140, 21, 157, 185, 86, 122, 25, 167, 20, 26, 4, 97, 198, 92, 7, 65, 203, 49, 147, 84, 3, 17, 46]\n",
      "conv1 [29, 25, 26, 16, 2]\n",
      "layer1.0.conv2 [27, 13, 40, 6, 33]\n",
      "layer1.0.conv1 [27, 45, 21, 38, 39]\n",
      "layer1.1.conv2 [18, 10, 46, 16, 38]\n",
      "layer1.1.conv1 [32, 28, 48, 15, 36]\n",
      "layer1.2.conv2 [0, 8, 48, 27, 42]\n",
      "layer1.2.conv1 [45, 51, 1, 11, 35]\n",
      "layer2.0.conv2 [21, 95, 62, 9, 93, 23, 70, 19, 87, 10, 22]\n",
      "layer2.0.conv1 [91, 94, 16, 65, 47, 39, 84, 83, 70, 81, 18]\n",
      "layer2.1.conv2 [85, 71, 38, 88, 7, 53, 83, 98, 58, 5, 25]\n",
      "layer2.1.conv1 [46, 20, 27, 58, 24, 11, 14, 82, 13, 62, 63]\n",
      "layer2.2.conv2 [30, 41, 37, 35, 47, 73, 67, 13, 56, 91, 16]\n",
      "layer2.2.conv1 [45, 52, 19, 50, 37, 41, 90, 64, 11, 92, 8]\n",
      "layer2.3.conv2 [41, 0, 62, 7, 34, 65, 87, 58, 47, 104, 57]\n",
      "layer2.3.conv1 [33, 30, 44, 81, 10, 58, 54, 51, 28, 8, 48]\n",
      "layer3.0.conv2 [185, 95, 87, 50, 209, 140, 84, 80, 100, 207, 28, 150, 151, 204, 78, 11, 34, 53, 118, 139, 162, 76, 96]\n",
      "layer3.0.conv1 [4, 161, 129, 70, 45, 204, 141, 209, 156, 67, 23, 1, 183, 27, 78, 100, 89, 157, 64, 195, 107, 119, 135]\n",
      "layer3.1.conv2 [39, 45, 205, 32, 107, 61, 188, 127, 172, 20, 133, 170, 145, 163, 14, 156, 75, 179, 106, 46, 93, 185, 88]\n",
      "layer3.1.conv1 [166, 131, 112, 34, 31, 196, 110, 139, 18, 157, 14, 176, 105, 116, 164, 20, 187, 193, 178, 33, 66, 11, 49]\n",
      "layer3.2.conv2 [44, 85, 112, 3, 137, 78, 30, 8, 59, 104, 157, 134, 198, 63, 101, 13, 159, 93, 56, 132, 52, 23, 66]\n",
      "layer3.2.conv1 [189, 93, 195, 155, 42, 144, 176, 22, 167, 121, 194, 108, 105, 21, 6, 7, 56, 143, 141, 133, 15, 26, 14]\n",
      "layer3.3.conv2 [34, 38, 153, 15, 23, 180, 87, 162, 14, 164, 189, 177, 124, 9, 171, 172, 149, 179, 155, 111, 117, 143, 139]\n",
      "layer3.3.conv1 [114, 90, 164, 134, 49, 120, 187, 59, 168, 42, 126, 174, 60, 9, 131, 154, 76, 96, 159, 167, 112, 181, 88]\n",
      "layer3.4.conv2 [18, 47, 155, 163, 57, 14, 17, 117, 150, 168, 75, 45, 25, 53, 203, 37, 201, 202, 77, 198, 32, 94, 41]\n",
      "layer3.4.conv1 [120, 36, 163, 196, 5, 181, 147, 190, 32, 88, 63, 187, 160, 54, 209, 168, 156, 29, 6, 77, 114, 208, 167]\n",
      "layer3.5.conv2 [202, 41, 122, 126, 106, 99, 129, 77, 107, 139, 158, 25, 125, 145, 135, 156, 115, 44, 164, 65, 35, 20, 45]\n",
      "layer3.5.conv1 [63, 90, 8, 137, 22, 12, 184, 17, 209, 31, 72, 188, 2, 60, 146, 75, 172, 23, 180, 179, 196, 74, 6]\n",
      "layer4.0.conv2 [54, 60, 14, 271, 176, 207, 93, 393, 75, 375, 283, 398, 28, 194, 41, 133, 86, 306, 326, 288, 407, 238, 347, 37, 118, 309, 35, 152, 64, 148, 134, 327, 226, 311, 49, 387, 168, 269, 25, 213, 158, 136, 154, 130, 350]\n",
      "layer4.0.conv1 [394, 172, 395, 320, 327, 234, 153, 252, 87, 30, 142, 391, 217, 106, 194, 379, 98, 81, 123, 156, 225, 385, 354, 92, 125, 216, 152, 280, 380, 249, 147, 227, 6, 47, 400, 71, 10, 263, 163, 211, 335, 99, 0, 144, 331]\n",
      "layer4.1.conv2 [318, 44, 352, 110, 47, 48, 73, 299, 50, 298, 300, 321, 141, 361, 93, 145, 305, 176, 350, 78, 259, 86, 316, 108, 212, 98, 380, 97, 267, 49, 158, 80, 96, 409, 8, 116, 326, 308, 161, 390, 101, 320, 335, 29, 331]\n",
      "layer4.1.conv1 [408, 407, 406, 149, 404, 163, 165, 261, 147, 145, 144, 260, 257, 279, 140, 139, 282, 135, 362, 361, 360, 358, 285, 356, 355, 256, 174, 284, 176, 255, 178, 352, 350, 250, 245, 348, 132, 346, 244, 39, 129, 343, 242, 128, 340]\n",
      "layer4.2.conv2 [147, 137, 352, 326, 235, 267, 393, 71, 53, 340, 188, 183, 320, 236, 400, 127, 83, 187, 4, 139, 242, 211, 258, 317, 159, 376, 2, 5, 47, 380, 27, 51, 419, 282, 389, 134, 334, 330, 228, 238, 194, 155, 8, 237, 259]\n",
      "layer4.2.conv1 [104, 311, 156, 237, 236, 309, 163, 307, 230, 306, 305, 166, 302, 227, 299, 298, 297, 296, 173, 174, 175, 176, 294, 293, 292, 291, 223, 290, 222, 179, 181, 182, 287, 286, 220, 217, 185, 37, 186, 39, 189, 192, 284, 283, 193]\n",
      "Pruning step: 3 multiply–accumulate (macs): 2257949142.0 number of parameters 14260554\n",
      "layer4.0.downsample.0 [856, 1400, 850, 1383, 404, 796, 538, 1252, 309, 981, 175, 192, 681, 886, 1159, 1442, 1458, 456, 1439, 560, 1361, 240, 950, 518, 482, 1323, 1317, 1303, 104, 389, 844, 433, 158, 95, 1067, 1480, 1406, 1032, 544, 488, 1497, 1018, 1382, 664, 1339, 345, 1229, 1218, 663, 1169, 647, 747, 880, 526, 678, 38, 969, 852, 729, 1363, 87, 82, 842, 587, 148, 1376, 900, 223, 1259, 1264, 427, 1289, 418, 1420, 1047, 632, 531, 695, 291, 496, 1235, 1306, 279, 380, 1507, 249, 101, 625, 1504, 1360, 749, 728, 1059, 245, 432, 1134, 1459, 308, 1250, 1324, 964, 943, 241, 830, 1219, 457, 1217, 210, 502, 1412, 378, 743, 1362, 458, 72, 1024, 936, 294, 296, 1440, 152, 851, 1280, 1116, 14, 1485, 413, 1263, 1394, 171, 26, 215, 305, 411, 252, 383, 1085, 449, 979, 1149, 1098, 266, 626, 1397, 1450, 730, 985, 159, 540, 1431, 907, 99, 812, 8, 909, 1396, 867, 989, 1194, 393, 1079, 1184, 974, 1118, 1386, 1405, 1132, 322, 788, 1253, 1081, 525, 1214, 931, 504, 1296, 755, 340, 1105]\n",
      "layer3.0.downsample.0 [580, 335, 241, 152, 684, 28, 388, 231, 679, 38, 728, 32, 115, 382, 693, 102, 118, 400, 529, 488, 257, 483, 709, 675, 515, 652, 718, 638, 402, 8, 221, 616, 185, 692, 134, 753, 439, 189, 734, 733, 197, 548, 349, 224, 162, 526, 212, 459, 604, 121, 77, 462, 676, 416, 426, 431, 354, 324, 500, 730, 374, 9, 445, 436, 432, 531, 481, 595, 648, 169, 310, 606, 446, 47, 302, 524, 337, 512, 639, 658, 418, 168, 366, 131, 435, 170, 226, 719, 240, 378]\n",
      "layer2.0.downsample.0 [52, 132, 288, 342, 310, 235, 240, 147, 326, 88, 196, 315, 295, 51, 22, 248, 184, 68, 368, 67, 357, 299, 11, 110, 3, 283, 216, 267, 284, 76, 346, 81, 143, 144, 351, 158, 266, 239, 353, 19, 366, 94, 213, 163, 126]\n",
      "layer1.0.downsample.0 [166, 180, 171, 149, 46, 174, 119, 181, 43, 153, 126, 44, 131, 14, 161, 41, 29, 164, 23, 182, 162, 61]\n",
      "conv1 [43, 38, 3, 9, 35, 0]\n",
      "layer1.0.conv2 [10, 23, 39, 41, 21, 25]\n",
      "layer1.0.conv1 [43, 15, 27, 7, 24, 28]\n",
      "layer1.1.conv2 [34, 1, 32, 2, 0, 38]\n",
      "layer1.1.conv1 [31, 24, 6, 16, 2, 35]\n",
      "layer1.2.conv2 [0, 13, 5, 38, 3, 33]\n",
      "layer1.2.conv1 [8, 35, 1, 29, 18, 45]\n",
      "layer2.0.conv2 [17, 9, 71, 81, 6, 27, 19, 74, 33, 8, 90]\n",
      "layer2.0.conv1 [65, 77, 89, 88, 41, 75, 78, 34, 6, 85, 74]\n",
      "layer2.1.conv2 [59, 38, 4, 62, 6, 81, 48, 83, 67, 89, 91]\n",
      "layer2.1.conv1 [84, 40, 90, 62, 28, 29, 10, 74, 69, 86, 45]\n",
      "layer2.2.conv2 [89, 14, 27, 36, 61, 68, 62, 87, 69, 17, 16]\n",
      "layer2.2.conv1 [72, 34, 86, 71, 58, 17, 44, 49, 35, 91, 67]\n",
      "layer2.3.conv2 [25, 81, 59, 70, 74, 28, 32, 4, 93, 0, 21]\n",
      "layer2.3.conv1 [69, 16, 15, 70, 85, 75, 10, 30, 46, 2, 89]\n",
      "layer3.0.conv2 [126, 7, 97, 74, 80, 86, 42, 137, 95, 83, 184, 179, 93, 155, 68, 47, 145, 45, 112, 107, 117, 33]\n",
      "layer3.0.conv1 [87, 86, 119, 176, 187, 6, 151, 112, 185, 5, 61, 138, 147, 27, 156, 123, 95, 36, 120, 153, 24, 75]\n",
      "layer3.1.conv2 [81, 29, 99, 140, 71, 36, 106, 25, 6, 112, 66, 128, 179, 15, 53, 171, 110, 42, 117, 133, 138, 96]\n",
      "layer3.1.conv1 [22, 180, 114, 177, 86, 169, 183, 148, 160, 30, 168, 176, 120, 117, 104, 79, 44, 72, 133, 27, 159, 7]\n",
      "layer3.2.conv2 [182, 30, 69, 28, 78, 123, 128, 75, 157, 165, 72, 49, 185, 40, 65, 127, 13, 12, 84, 39, 71, 26]\n",
      "layer3.2.conv1 [122, 99, 27, 13, 80, 110, 69, 12, 0, 107, 70, 131, 138, 155, 71, 108, 52, 20, 114, 120, 173, 126]\n",
      "layer3.3.conv2 [116, 29, 45, 183, 157, 127, 88, 81, 52, 106, 80, 96, 77, 143, 20, 31, 134, 40, 100, 55, 60, 102]\n",
      "layer3.3.conv1 [92, 28, 61, 154, 26, 149, 130, 1, 134, 19, 131, 79, 103, 3, 14, 13, 55, 144, 66, 11, 132, 98]\n",
      "layer3.4.conv2 [146, 4, 100, 163, 175, 107, 37, 136, 164, 89, 95, 41, 178, 184, 50, 133, 131, 45, 30, 61, 20, 12]\n",
      "layer3.4.conv1 [183, 32, 10, 144, 66, 7, 61, 90, 148, 60, 80, 170, 70, 5, 24, 162, 23, 116, 185, 153, 93, 8]\n",
      "layer3.5.conv2 [2, 152, 47, 114, 54, 175, 112, 42, 48, 141, 13, 59, 36, 97, 142, 82, 143, 81, 24, 134, 53, 167]\n",
      "layer3.5.conv1 [107, 37, 153, 29, 57, 143, 6, 19, 4, 115, 70, 35, 89, 148, 51, 28, 74, 101, 24, 169, 154, 30]\n",
      "layer4.0.conv2 [137, 185, 77, 317, 216, 354, 301, 233, 218, 34, 27, 19, 146, 115, 145, 280, 366, 126, 251, 9, 255, 148, 226, 350, 311, 214, 355, 66, 230, 257, 11, 140, 120, 152, 153, 35, 209, 309, 358, 79, 357, 247, 273, 82, 253]\n",
      "layer4.0.conv1 [114, 173, 220, 166, 86, 288, 87, 349, 268, 136, 232, 347, 91, 303, 133, 216, 66, 311, 34, 259, 130, 90, 189, 238, 249, 262, 186, 115, 92, 325, 169, 256, 207, 343, 337, 214, 243, 167, 354, 17, 33, 127, 241, 296, 364]\n",
      "layer4.1.conv2 [158, 351, 75, 260, 69, 120, 349, 256, 271, 199, 126, 191, 4, 275, 356, 211, 201, 26, 178, 146, 154, 27, 361, 11, 338, 46, 79, 258, 9, 47, 134, 100, 267, 53, 195, 278, 219, 122, 37, 18, 250, 63, 164, 2, 224]\n",
      "layer4.1.conv1 [47, 249, 273, 139, 245, 270, 83, 142, 269, 86, 144, 224, 89, 90, 146, 65, 66, 267, 68, 96, 195, 193, 263, 374, 101, 373, 372, 104, 262, 71, 106, 364, 72, 109, 260, 250, 112, 113, 77, 115, 310, 299, 297, 165, 295]\n",
      "layer4.2.conv2 [206, 351, 256, 50, 191, 292, 267, 114, 176, 281, 239, 104, 194, 68, 122, 37, 139, 328, 212, 269, 230, 67, 89, 169, 113, 127, 26, 374, 126, 250, 31, 322, 307, 221, 161, 109, 177, 240, 84, 101, 333, 238, 313, 159, 158]\n",
      "layer4.2.conv1 [47, 219, 274, 110, 108, 217, 216, 215, 214, 212, 144, 376, 232, 106, 196, 147, 105, 104, 148, 98, 223, 177, 150, 179, 152, 190, 189, 183, 184, 95, 185, 186, 187, 374, 373, 93, 372, 371, 92, 230, 346, 225, 86, 350, 44]\n",
      "Pruning step: 4 multiply–accumulate (macs): 1762729463.0 number of parameters 11239802\n",
      "layer4.0.downsample.0 [1031, 784, 432, 998, 179, 479, 485, 1052, 1009, 547, 1041, 241, 153, 535, 880, 450, 531, 1309, 397, 528, 25, 272, 505, 1315, 200, 553, 617, 1098, 979, 722, 29, 812, 958, 30, 476, 1190, 306, 622, 1209, 319, 964, 791, 54, 510, 1280, 1062, 1277, 494, 286, 213, 1302, 865, 1195, 290, 35, 109, 48, 1228, 1275, 310, 901, 97, 16, 771, 821, 512, 966, 1207, 108, 1057, 894, 839, 203, 1108, 848, 871, 963, 960, 5, 1036, 742, 1080, 1262, 712, 209, 412, 978, 594, 991, 700, 335, 1236, 1113, 572, 458, 635, 884, 1110, 939, 129, 659, 981, 1202, 817, 524, 647, 380, 445, 820, 573, 249, 616, 1082, 1100, 416, 341, 525, 76, 1323, 38, 1056, 1279, 519, 860, 945, 365, 1156, 0, 1015, 477, 893, 790, 997, 40, 36, 337, 558, 100, 900, 1243, 59, 731, 135, 1060, 778, 777, 814, 37, 302, 138, 355, 126, 623, 710, 1314, 244, 917, 1258, 142, 1310, 46, 1013, 1179, 930, 1133, 220, 542, 491, 439, 564, 920, 1237, 1165, 356, 985, 1246, 147, 715, 1067]\n",
      "layer3.0.downsample.0 [140, 162, 500, 150, 146, 100, 243, 596, 97, 119, 567, 89, 457, 26, 200, 224, 317, 486, 148, 16, 357, 190, 639, 307, 471, 462, 270, 171, 393, 382, 207, 645, 439, 360, 383, 459, 135, 155, 355, 571, 569, 652, 327, 366, 37, 250, 102, 258, 541, 451, 222, 213, 649, 585, 291, 107, 276, 516, 575, 310, 566, 447, 281, 607, 189, 549, 642, 627, 490, 265, 306, 661, 116, 523, 346, 502, 257, 354, 55, 20, 477, 590, 658, 293, 592, 316, 525, 398, 118]\n",
      "layer2.0.downsample.0 [71, 4, 295, 300, 313, 325, 188, 72, 67, 2, 258, 40, 183, 27, 212, 171, 149, 64, 287, 170, 201, 237, 209, 28, 80, 159, 143, 164, 7, 35, 86, 204, 284, 127, 49, 116, 229, 312, 270, 292, 186, 146, 9, 144]\n",
      "layer1.0.downsample.0 [148, 47, 29, 57, 40, 28, 34, 55, 151, 15, 121, 102, 8, 163, 23, 21, 68, 139, 56, 118, 115, 70]\n",
      "conv1 [36, 35, 16, 23, 26]\n",
      "layer1.0.conv2 [30, 24, 10, 18, 39]\n",
      "layer1.0.conv1 [39, 1, 35, 19, 21]\n",
      "layer1.1.conv2 [9, 3, 26, 39, 40]\n",
      "layer1.1.conv1 [24, 7, 8, 1, 20]\n",
      "layer1.2.conv2 [10, 12, 40, 20, 38]\n",
      "layer1.2.conv1 [13, 23, 38, 32, 27]\n",
      "layer2.0.conv2 [48, 10, 46, 39, 9, 14, 64, 54, 71, 57, 28]\n",
      "layer2.0.conv1 [78, 39, 44, 8, 58, 38, 40, 80, 61, 33, 42]\n",
      "layer2.1.conv2 [5, 63, 60, 7, 55, 82, 80, 56, 64, 8, 81]\n",
      "layer2.1.conv1 [9, 61, 77, 50, 63, 36, 12, 39, 76, 2, 64]\n",
      "layer2.2.conv2 [71, 32, 79, 39, 57, 2, 20, 37, 72, 25, 53]\n",
      "layer2.2.conv1 [77, 60, 27, 28, 80, 54, 44, 24, 71, 26, 76]\n",
      "layer2.3.conv2 [32, 13, 37, 25, 72, 0, 73, 42, 30, 28, 29]\n",
      "layer2.3.conv1 [13, 27, 15, 35, 41, 26, 16, 17, 9, 4, 73]\n",
      "layer3.0.conv2 [71, 30, 22, 54, 108, 50, 73, 129, 137, 98, 19, 135, 6, 160, 28, 53, 68, 62, 77, 132, 42, 120]\n",
      "layer3.0.conv1 [103, 90, 50, 165, 92, 23, 49, 96, 117, 45, 25, 156, 4, 64, 94, 24, 8, 159, 143, 55, 98, 146]\n",
      "layer3.1.conv2 [56, 97, 37, 88, 136, 129, 83, 140, 13, 146, 67, 9, 94, 126, 119, 28, 4, 124, 62, 111, 107, 139]\n",
      "layer3.1.conv1 [148, 29, 131, 4, 104, 153, 144, 112, 164, 69, 66, 108, 60, 78, 147, 126, 20, 28, 90, 70, 114, 82]\n",
      "layer3.2.conv2 [135, 159, 68, 10, 100, 95, 74, 165, 118, 93, 31, 151, 53, 85, 106, 144, 105, 112, 61, 147, 11, 52]\n",
      "layer3.2.conv1 [65, 44, 96, 163, 23, 63, 102, 118, 145, 89, 13, 5, 31, 79, 110, 117, 3, 22, 72, 35, 61, 55]\n",
      "layer3.3.conv2 [141, 86, 135, 100, 35, 12, 32, 72, 76, 99, 42, 108, 115, 49, 102, 92, 48, 51, 4, 68, 24, 143]\n",
      "layer3.3.conv1 [37, 127, 111, 88, 121, 1, 100, 107, 144, 135, 104, 12, 76, 43, 60, 5, 33, 52, 148, 53, 152, 114]\n",
      "layer3.4.conv2 [124, 104, 81, 84, 69, 48, 9, 83, 136, 102, 29, 7, 123, 144, 40, 109, 130, 160, 46, 20, 6, 106]\n",
      "layer3.4.conv1 [97, 143, 119, 6, 18, 68, 62, 7, 114, 48, 131, 132, 39, 93, 161, 94, 117, 17, 64, 60, 141, 78]\n",
      "layer3.5.conv2 [122, 71, 129, 21, 2, 115, 22, 117, 104, 123, 109, 74, 68, 51, 91, 65, 139, 69, 32, 37, 132, 76]\n",
      "layer3.5.conv1 [146, 2, 8, 5, 126, 161, 97, 119, 46, 94, 89, 155, 15, 160, 123, 61, 149, 117, 63, 132, 57, 139]\n",
      "layer4.0.conv2 [84, 129, 209, 40, 92, 168, 206, 26, 246, 144, 108, 35, 10, 275, 200, 326, 100, 261, 244, 53, 136, 79, 322, 173, 143, 11, 273, 298, 225, 158, 203, 132, 284, 25, 126, 247, 152, 236, 241, 248, 155, 98, 42, 269]\n",
      "layer4.0.conv1 [21, 256, 132, 259, 166, 228, 270, 232, 41, 299, 17, 303, 300, 289, 100, 7, 285, 2, 189, 25, 274, 90, 268, 231, 275, 30, 292, 79, 124, 57, 82, 220, 254, 110, 137, 135, 12, 65, 246, 245, 293, 128, 159, 323]\n",
      "layer4.1.conv2 [152, 56, 283, 221, 160, 49, 125, 72, 76, 153, 145, 207, 177, 132, 280, 244, 206, 25, 130, 175, 98, 126, 78, 100, 158, 193, 10, 178, 18, 141, 171, 181, 325, 42, 312, 235, 314, 306, 322, 250, 106, 149, 298, 224]\n",
      "layer4.1.conv1 [55, 107, 244, 51, 46, 247, 47, 45, 102, 250, 83, 57, 81, 119, 188, 164, 28, 237, 180, 138, 129, 126, 70, 329, 59, 56, 275, 319, 277, 204, 121, 232, 265, 30, 153, 38, 98, 80, 302, 41, 72, 62, 33, 165]\n",
      "layer4.2.conv2 [14, 159, 5, 200, 322, 157, 70, 305, 86, 213, 24, 9, 56, 225, 325, 73, 222, 50, 237, 231, 302, 37, 168, 271, 52, 108, 46, 163, 31, 141, 88, 236, 264, 331, 4, 193, 63, 203, 281, 89, 242, 106, 239, 253]\n",
      "layer4.2.conv1 [82, 115, 52, 53, 116, 55, 56, 57, 190, 59, 123, 126, 62, 312, 236, 64, 235, 313, 66, 67, 68, 230, 69, 315, 101, 72, 73, 54, 74, 75, 76, 320, 78, 79, 80, 81, 219, 324, 210, 104, 218, 105, 106, 325]\n",
      "Pruning step: 5 multiply–accumulate (macs): 1341807112.0 number of parameters 8606476\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 36, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(144, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(144, 288, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(288, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(288, 576, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(576, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(288, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(576, 1152, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1152, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(288, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1152, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(288, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=1152, out_features=1000, bias=True)\n",
      ")\n",
      "Pruning sparsity: 0.5\n",
      "layer4.0.downsample.0 [1051, 351, 2, 1561, 831, 678, 1993, 207, 80, 854, 1154, 1530, 1748, 1978, 158, 311, 275, 839, 1477, 1344, 898, 892, 745, 605, 619, 218, 991, 675, 1925, 327, 1850, 338, 1772, 143, 1880, 100, 653, 93, 112, 1810, 1144, 1257, 1868, 1694, 1906, 560, 16, 167, 1568, 102, 2046, 449, 468, 1464, 1193, 1999, 1532, 1201, 1156, 1555, 760, 1492, 1009, 1736, 794, 1980, 887, 1595, 1349, 416, 108, 955, 1292, 1253, 968, 533, 362, 660, 1077, 1726, 1427, 1727, 48, 616, 1126, 307, 695, 1888, 427, 1578, 1743, 950, 1326, 1604, 415, 1974, 847, 1221, 1444, 1819, 204, 583, 1958, 296, 899, 1619, 1056, 455, 563, 1496, 833, 1460, 1192, 629, 32, 497, 305, 77, 1645, 1929, 2020, 1592, 1312, 1055, 472, 1371, 724, 526, 808, 1375, 663, 195, 241, 1093, 1099, 94, 1166, 1570, 623, 144, 1046, 301, 975, 685, 861, 2040, 480, 1600, 1973, 1322, 447, 1658, 333, 1249, 1262, 1749, 1843, 2003, 1510, 478, 40, 622, 1770, 1203, 456, 382, 688, 1961, 220, 235, 801, 1817, 1081, 610, 1437, 706, 107, 1718, 1139, 194, 1429, 726, 1286, 721, 83, 1087, 868, 617, 1802, 1357, 66, 1390, 1028, 952, 1680, 1070, 1338, 1920, 474, 1441, 1692, 1608, 140, 121, 331]\n",
      "layer3.0.downsample.0 [962, 853, 486, 1018, 197, 544, 1023, 500, 170, 595, 644, 412, 491, 906, 91, 657, 352, 51, 709, 741, 18, 729, 151, 303, 96, 778, 759, 927, 803, 536, 444, 966, 38, 923, 311, 685, 60, 105, 928, 297, 1017, 980, 123, 194, 92, 390, 579, 656, 609, 501, 728, 83, 1011, 388, 836, 487, 514, 541, 149, 683, 407, 590, 701, 801, 16, 310, 766, 744, 620, 325, 127, 45, 494, 716, 972, 55, 468, 37, 678, 589, 419, 825, 662, 748, 767, 511, 365, 205, 647, 14, 475, 329, 340, 900, 99, 936, 720, 881, 706, 132, 611, 747, 732]\n",
      "layer2.0.downsample.0 [176, 246, 243, 412, 404, 347, 387, 53, 100, 11, 163, 363, 34, 114, 43, 371, 207, 24, 96, 66, 326, 98, 0, 33, 438, 372, 166, 311, 184, 509, 188, 361, 147, 81, 495, 424, 192, 65, 177, 85, 60, 442, 328, 339, 86, 353, 229, 58, 72, 285, 335, 133]\n",
      "layer1.0.downsample.0 [144, 108, 214, 150, 77, 58, 131, 103, 92, 29, 235, 0, 156, 225, 31, 63, 112, 231, 36, 233, 97, 68, 135, 245, 196, 69]\n",
      "conv1 [13, 44, 42, 52, 57, 31, 11]\n",
      "layer1.0.conv2 [0, 1, 60, 22, 59, 9, 28]\n",
      "layer1.0.conv1 [38, 1, 56, 49, 5, 7, 48]\n",
      "layer1.1.conv2 [17, 44, 6, 45, 25, 41, 38]\n",
      "layer1.1.conv1 [56, 19, 2, 42, 4, 41, 40]\n",
      "layer1.2.conv2 [11, 57, 7, 24, 8, 35, 4]\n",
      "layer1.2.conv1 [2, 39, 49, 45, 11, 63, 19]\n",
      "layer2.0.conv2 [35, 69, 90, 4, 119, 51, 115, 110, 12, 47, 29, 3, 111]\n",
      "layer2.0.conv1 [112, 92, 104, 63, 89, 8, 66, 68, 2, 14, 61, 110, 122]\n",
      "layer2.1.conv2 [10, 100, 121, 54, 29, 120, 9, 109, 46, 93, 77, 26, 112]\n",
      "layer2.1.conv1 [14, 1, 69, 3, 5, 79, 111, 58, 63, 28, 29, 118, 108]\n",
      "layer2.2.conv2 [29, 39, 18, 56, 34, 75, 101, 32, 86, 35, 12, 43, 40]\n",
      "layer2.2.conv1 [120, 63, 117, 112, 38, 75, 102, 6, 40, 88, 12, 76, 124]\n",
      "layer2.3.conv2 [127, 124, 0, 67, 36, 17, 111, 105, 76, 19, 77, 21, 110]\n",
      "layer2.3.conv1 [9, 114, 120, 74, 6, 37, 79, 52, 30, 49, 23, 4, 33]\n",
      "layer3.0.conv2 [157, 116, 2, 106, 250, 54, 151, 248, 133, 141, 222, 13, 4, 207, 152, 44, 35, 115, 194, 160, 247, 221, 199, 150, 219, 232]\n",
      "layer3.0.conv1 [18, 4, 220, 245, 136, 148, 90, 139, 48, 254, 110, 44, 89, 196, 225, 39, 42, 86, 70, 194, 103, 236, 55, 212, 238, 135]\n",
      "layer3.1.conv2 [16, 85, 146, 108, 209, 191, 72, 7, 8, 111, 238, 250, 235, 133, 100, 132, 130, 123, 56, 127, 82, 229, 228, 23, 24, 155]\n",
      "layer3.1.conv1 [32, 76, 225, 152, 216, 103, 162, 97, 95, 131, 50, 11, 222, 13, 92, 221, 194, 54, 249, 217, 65, 201, 88, 211, 244, 85]\n",
      "layer3.2.conv2 [35, 79, 196, 117, 108, 149, 157, 156, 17, 131, 56, 190, 82, 233, 166, 47, 14, 99, 228, 43, 30, 153, 106, 245, 186, 37]\n",
      "layer3.2.conv1 [1, 242, 30, 59, 105, 164, 153, 216, 119, 192, 24, 29, 56, 100, 99, 47, 97, 51, 167, 20, 155, 243, 181, 212, 161, 127]\n",
      "layer3.3.conv2 [148, 190, 35, 247, 131, 127, 146, 71, 161, 112, 34, 37, 76, 157, 100, 119, 169, 218, 38, 43, 173, 82, 46, 171, 17, 217]\n",
      "layer3.3.conv1 [19, 211, 214, 207, 58, 79, 9, 219, 181, 41, 40, 189, 84, 75, 31, 100, 195, 71, 180, 158, 60, 59, 124, 24, 209, 252]\n",
      "layer3.4.conv2 [105, 41, 244, 242, 169, 252, 53, 19, 126, 116, 144, 50, 79, 38, 150, 186, 42, 165, 149, 210, 35, 164, 207, 213, 212, 68]\n",
      "layer3.4.conv1 [40, 73, 111, 110, 108, 60, 6, 99, 26, 240, 10, 100, 192, 55, 87, 204, 164, 48, 21, 199, 8, 227, 200, 122, 20, 242]\n",
      "layer3.5.conv2 [203, 137, 141, 221, 219, 142, 143, 91, 206, 94, 38, 186, 183, 105, 215, 249, 8, 127, 115, 178, 59, 52, 16, 248, 135, 252]\n",
      "layer3.5.conv1 [16, 1, 248, 3, 220, 5, 190, 29, 204, 251, 10, 250, 249, 126, 95, 81, 199, 203, 114, 112, 205, 70, 153, 246, 55, 67]\n",
      "layer4.0.conv2 [236, 326, 409, 178, 103, 511, 319, 306, 65, 405, 290, 244, 12, 111, 390, 386, 286, 383, 284, 157, 381, 272, 78, 269, 160, 80, 378, 163, 253, 266, 84, 227, 335, 87, 371, 35, 127, 461, 38, 365, 130, 492, 91, 231, 203, 348, 46, 342, 48, 61, 454, 143]\n",
      "layer4.0.conv1 [203, 34, 284, 143, 220, 314, 312, 268, 8, 18, 10, 416, 12, 132, 510, 15, 16, 227, 114, 230, 231, 487, 483, 53, 394, 124, 471, 383, 467, 457, 48, 336, 326, 219, 225, 234, 406, 316, 1, 500, 122, 291, 300, 270, 107, 259, 408, 24, 432, 436, 410, 298]\n",
      "layer4.1.conv2 [36, 442, 2, 480, 172, 439, 122, 437, 348, 476, 475, 428, 12, 170, 426, 169, 469, 422, 18, 465, 421, 464, 347, 459, 163, 454, 448, 258, 28, 261, 251, 131, 249, 162, 333, 35, 134, 331, 403, 329, 40, 267, 277, 313, 153, 317, 46, 229, 48, 148, 391, 51]\n",
      "layer4.1.conv1 [64, 203, 204, 444, 206, 207, 448, 7, 450, 9, 10, 210, 211, 452, 213, 214, 215, 17, 460, 19, 217, 462, 22, 464, 220, 25, 221, 222, 465, 29, 470, 31, 471, 474, 475, 35, 228, 229, 477, 231, 478, 41, 233, 234, 44, 45, 46, 47, 484, 485, 486, 51]\n",
      "layer4.2.conv2 [0, 188, 353, 99, 171, 350, 381, 169, 8, 9, 348, 11, 384, 26, 385, 15, 243, 160, 394, 158, 156, 155, 337, 46, 92, 333, 277, 173, 331, 368, 328, 367, 32, 33, 403, 150, 410, 37, 416, 417, 419, 425, 426, 176, 309, 366, 187, 47, 308, 178, 307, 359]\n",
      "layer4.2.conv1 [64, 469, 486, 466, 464, 5, 460, 7, 8, 459, 457, 456, 450, 13, 488, 15, 16, 492, 18, 19, 445, 444, 443, 23, 24, 440, 26, 438, 436, 29, 493, 435, 434, 33, 34, 35, 431, 37, 38, 428, 427, 497, 424, 423, 44, 422, 46, 498, 48, 49, 50, 417]\n",
      "Pruning step: 1 multiply–accumulate (macs): 3334201847.0 number of parameters 20837770\n",
      "layer4.0.downsample.0 [1591, 1508, 812, 444, 1436, 623, 813, 1175, 401, 653, 1270, 1772, 369, 1636, 1700, 615, 262, 1623, 49, 1169, 1210, 771, 1140, 518, 312, 800, 688, 198, 150, 873, 1692, 1601, 634, 797, 612, 628, 1516, 1399, 1523, 609, 900, 643, 603, 1622, 269, 931, 425, 1301, 1620, 754, 1514, 631, 903, 1540, 375, 531, 927, 349, 1528, 1181, 1199, 1097, 1471, 1491, 944, 1663, 1479, 955, 1677, 220, 1164, 63, 1387, 1079, 1028, 1753, 107, 662, 669, 910, 254, 352, 1792, 1272, 1534, 718, 411, 1070, 427, 665, 1645, 839, 83, 1713, 949, 1157, 462, 1522, 822, 699, 384, 46, 1449, 1101, 1251, 958, 439, 1364, 1737, 283, 270, 133, 524, 1459, 105, 1009, 1643, 255, 1086, 56, 497, 1579, 1625, 274, 1110, 1709, 647, 673, 656, 1794, 1678, 1285, 465, 991, 1005, 405, 1480, 1003, 733, 217, 1826, 832, 228, 510, 1291, 1648, 1769, 580, 1092, 188, 1139, 71, 6, 1751, 1565, 686, 864, 67, 1010, 1777, 288, 980, 1206, 1356, 303, 1295, 1185, 380, 1686, 842, 81, 431, 1682, 1695, 1064, 199, 1722, 1228, 319, 391, 214, 1614, 1765, 1439, 552, 316, 1154, 1046, 658, 1234, 1325, 1822, 618, 1715, 1063, 761, 637, 1834, 500, 1410, 775, 884, 1505, 85, 1675]\n",
      "layer3.0.downsample.0 [839, 437, 343, 600, 171, 103, 338, 717, 545, 529, 553, 407, 81, 732, 504, 624, 561, 492, 146, 418, 524, 225, 832, 785, 441, 100, 62, 337, 380, 63, 842, 179, 606, 623, 76, 846, 799, 818, 835, 699, 601, 557, 99, 299, 703, 740, 485, 831, 91, 734, 261, 41, 395, 690, 291, 297, 874, 501, 364, 886, 533, 259, 82, 245, 797, 873, 273, 386, 85, 423, 828, 51, 856, 634, 199, 694, 432, 18, 388, 204, 385, 301, 775, 483, 295, 635, 912, 484, 153, 111, 817, 456, 254, 133, 761, 434, 920, 250, 77, 861, 450, 565]\n",
      "layer2.0.downsample.0 [415, 435, 237, 9, 335, 228, 128, 274, 233, 423, 200, 112, 338, 437, 84, 307, 444, 23, 247, 130, 365, 337, 173, 449, 279, 119, 260, 176, 147, 276, 340, 222, 98, 193, 316, 101, 397, 278, 125, 59, 396, 116, 392, 35, 412, 318, 445, 373, 425, 7, 383]\n",
      "layer1.0.downsample.0 [9, 197, 25, 69, 20, 149, 93, 99, 174, 194, 13, 29, 131, 7, 106, 126, 171, 154, 124, 55, 3, 184, 4, 221, 153, 163]\n",
      "conv1 [51, 52, 43, 2, 26, 31]\n",
      "layer1.0.conv2 [11, 16, 29, 54, 44, 39]\n",
      "layer1.0.conv1 [18, 30, 42, 41, 24, 20]\n",
      "layer1.1.conv2 [9, 36, 11, 51, 17, 27]\n",
      "layer1.1.conv1 [7, 39, 13, 27, 37, 34]\n",
      "layer1.2.conv2 [33, 0, 1, 23, 14, 37]\n",
      "layer1.2.conv1 [30, 53, 46, 50, 2, 47]\n",
      "layer2.0.conv2 [90, 92, 46, 47, 107, 10, 33, 102, 100, 22, 15, 54, 85]\n",
      "layer2.0.conv1 [10, 109, 90, 99, 70, 4, 111, 92, 108, 86, 74, 50, 76]\n",
      "layer2.1.conv2 [26, 113, 34, 88, 86, 91, 109, 77, 25, 61, 74, 43, 93]\n",
      "layer2.1.conv1 [39, 92, 73, 100, 52, 55, 104, 50, 20, 24, 79, 28, 48]\n",
      "layer2.2.conv2 [58, 37, 20, 112, 71, 75, 5, 84, 45, 38, 54, 50, 2]\n",
      "layer2.2.conv1 [111, 96, 45, 42, 23, 69, 98, 101, 87, 2, 15, 54, 106]\n",
      "layer2.3.conv2 [97, 96, 105, 52, 37, 98, 103, 102, 2, 62, 46, 32, 7]\n",
      "layer2.3.conv1 [2, 114, 49, 37, 94, 92, 59, 10, 104, 107, 32, 12, 103]\n",
      "layer3.0.conv2 [117, 54, 89, 104, 19, 217, 126, 228, 170, 118, 113, 204, 191, 106, 63, 176, 138, 52, 76, 192, 11, 119, 39, 227, 201, 35]\n",
      "layer3.0.conv1 [143, 1, 220, 188, 161, 81, 30, 135, 84, 75, 201, 112, 113, 147, 139, 155, 173, 27, 223, 229, 172, 2, 178, 213, 65, 71]\n",
      "layer3.1.conv2 [197, 200, 37, 79, 67, 145, 192, 221, 228, 87, 51, 208, 135, 81, 183, 167, 65, 169, 7, 91, 101, 223, 21, 126, 148, 168]\n",
      "layer3.1.conv1 [40, 171, 38, 156, 205, 157, 172, 165, 72, 70, 69, 67, 128, 130, 135, 31, 207, 109, 119, 175, 123, 136, 203, 51, 155, 149]\n",
      "layer3.2.conv2 [77, 96, 31, 3, 27, 215, 72, 162, 10, 65, 179, 15, 224, 62, 135, 91, 116, 209, 99, 41, 150, 81, 95, 2, 156, 8]\n",
      "layer3.2.conv1 [75, 7, 221, 119, 133, 213, 170, 21, 174, 139, 86, 184, 88, 26, 161, 101, 74, 144, 53, 188, 0, 128, 62, 45, 118, 129]\n",
      "layer3.3.conv2 [25, 187, 229, 176, 174, 149, 171, 117, 75, 130, 153, 211, 184, 111, 45, 206, 190, 64, 133, 196, 181, 135, 19, 132, 161, 156]\n",
      "layer3.3.conv1 [69, 100, 29, 219, 193, 190, 211, 215, 129, 228, 113, 170, 202, 151, 15, 3, 9, 179, 201, 174, 171, 86, 63, 108, 54, 94]\n",
      "layer3.4.conv2 [20, 161, 87, 156, 19, 60, 16, 92, 183, 106, 62, 75, 173, 126, 179, 101, 35, 218, 194, 32, 159, 174, 82, 14, 199, 27]\n",
      "layer3.4.conv1 [1, 176, 46, 33, 87, 7, 38, 164, 185, 123, 105, 90, 126, 55, 6, 104, 175, 11, 135, 173, 171, 149, 36, 207, 146, 12]\n",
      "layer3.5.conv2 [199, 76, 0, 204, 72, 216, 27, 200, 42, 137, 106, 77, 201, 87, 17, 148, 3, 133, 84, 38, 28, 171, 118, 126, 100, 50]\n",
      "layer3.5.conv1 [65, 159, 201, 215, 74, 111, 183, 93, 119, 181, 89, 27, 12, 42, 5, 71, 149, 173, 22, 151, 51, 196, 17, 8, 97, 32]\n",
      "layer4.0.conv2 [373, 268, 171, 14, 343, 374, 405, 240, 213, 244, 146, 81, 455, 24, 430, 189, 126, 29, 21, 102, 434, 409, 448, 32, 39, 138, 239, 443, 194, 151, 371, 334, 55, 182, 333, 129, 355, 157, 16, 339, 232, 112, 181, 314, 404, 65, 285, 219, 127, 270, 432]\n",
      "layer4.0.conv1 [89, 113, 277, 272, 424, 172, 438, 94, 228, 457, 187, 44, 292, 207, 226, 386, 421, 402, 165, 314, 82, 371, 400, 312, 343, 10, 263, 431, 139, 156, 151, 0, 244, 450, 201, 350, 197, 281, 428, 388, 210, 378, 366, 101, 415, 6, 161, 208, 106, 382, 171]\n",
      "layer4.1.conv2 [57, 65, 317, 66, 272, 233, 94, 68, 343, 264, 253, 106, 204, 203, 157, 158, 101, 342, 159, 73, 341, 105, 336, 76, 335, 78, 110, 334, 81, 163, 194, 165, 267, 185, 184, 182, 178, 321, 174, 455, 453, 441, 318, 86, 44, 430, 47, 48, 49, 50, 53]\n",
      "layer4.1.conv1 [57, 285, 156, 284, 157, 456, 455, 454, 450, 447, 446, 445, 444, 280, 443, 279, 442, 439, 438, 209, 159, 183, 161, 408, 273, 407, 406, 401, 271, 270, 400, 162, 208, 165, 206, 392, 167, 268, 38, 391, 169, 389, 42, 239, 44, 172, 185, 387, 48, 386, 385]\n",
      "layer4.2.conv2 [275, 254, 51, 256, 267, 240, 401, 268, 76, 112, 442, 388, 417, 389, 59, 69, 194, 258, 257, 450, 456, 43, 455, 411, 244, 73, 324, 356, 92, 303, 148, 34, 42, 380, 199, 426, 427, 224, 347, 204, 422, 297, 118, 310, 430, 249, 159, 317, 412, 2, 160]\n",
      "layer4.2.conv1 [57, 309, 202, 204, 206, 232, 306, 210, 211, 212, 213, 305, 304, 214, 303, 216, 300, 217, 223, 299, 225, 226, 231, 297, 228, 296, 295, 229, 294, 310, 311, 312, 314, 315, 291, 35, 318, 37, 319, 39, 80, 322, 42, 43, 324, 330, 46, 386, 332, 333, 281]\n",
      "Pruning step: 2 multiply–accumulate (macs): 2647792566.0 number of parameters 16641302\n",
      "layer4.0.downsample.0 [298, 59, 236, 925, 596, 1188, 1366, 340, 1626, 467, 1412, 50, 747, 1167, 438, 677, 226, 479, 950, 1068, 729, 992, 519, 1352, 1385, 1223, 1157, 9, 981, 1025, 1000, 1576, 370, 962, 1447, 571, 1312, 1511, 8, 1355, 779, 1383, 319, 603, 1465, 1094, 1508, 93, 935, 1599, 413, 916, 937, 1122, 1570, 1604, 1633, 1052, 1632, 936, 1528, 377, 1348, 1152, 773, 1536, 702, 1617, 133, 556, 155, 250, 801, 772, 978, 1252, 221, 12, 1463, 1329, 302, 495, 566, 997, 1562, 164, 821, 1172, 1121, 311, 1055, 131, 558, 1603, 1577, 107, 724, 111, 116, 908, 883, 1418, 144, 1397, 797, 746, 97, 1296, 1470, 1409, 244, 1431, 301, 1424, 1230, 1554, 979, 417, 91, 407, 222, 542, 1125, 385, 227, 1420, 1225, 420, 1475, 761, 642, 730, 233, 1170, 526, 99, 1344, 1477, 1207, 1509, 1545, 1318, 1235, 1449, 1039, 1174, 1438, 1560, 1452, 260, 685, 630, 1211, 1451, 1224, 1369, 243, 1574, 1065, 239, 1131, 447, 1350, 270, 1564, 1361, 501, 693, 1304, 81, 20, 1563, 1380, 1073, 206, 212, 1067, 1623, 534, 1527, 1398, 884, 1021, 1362, 19, 580, 837, 540, 768, 1087, 1365, 1630, 688, 415, 620, 1162, 13, 1113, 1313, 328, 297, 739, 1580, 631, 494]\n",
      "layer3.0.downsample.0 [157, 387, 371, 55, 486, 153, 51, 712, 545, 630, 799, 487, 352, 267, 209, 206, 783, 64, 38, 481, 47, 78, 208, 120, 762, 22, 4, 190, 295, 669, 491, 309, 164, 616, 607, 25, 265, 413, 442, 674, 649, 632, 84, 428, 236, 696, 263, 125, 530, 373, 333, 21, 672, 19, 717, 740, 659, 483, 255, 386, 266, 257, 77, 143, 599, 303, 221, 392, 528, 281, 277, 113, 683, 796, 797, 382, 447, 464, 452, 535, 817, 67, 32, 412, 76, 474, 771, 734, 41, 617, 470, 404, 17, 117, 138, 332, 258, 613, 310, 795, 710, 422, 359]\n",
      "layer2.0.downsample.0 [182, 402, 362, 32, 301, 219, 108, 363, 387, 140, 64, 111, 178, 36, 374, 189, 195, 281, 230, 331, 266, 340, 86, 145, 317, 153, 126, 235, 27, 385, 273, 233, 20, 366, 310, 342, 211, 169, 5, 357, 11, 333, 96, 57, 8, 87, 156, 323, 304, 35, 397]\n",
      "layer1.0.downsample.0 [89, 181, 179, 42, 18, 22, 15, 161, 167, 62, 46, 192, 118, 33, 196, 50, 142, 144, 53, 175, 48, 81, 88, 177, 163]\n",
      "conv1 [25, 26, 2, 47, 42, 16, 10]\n",
      "layer1.0.conv2 [13, 35, 6, 32, 25, 11, 43]\n",
      "layer1.0.conv1 [45, 34, 17, 28, 47, 25, 43]\n",
      "layer1.1.conv2 [45, 36, 16, 21, 37, 1, 2]\n",
      "layer1.1.conv1 [10, 31, 27, 35, 43, 18, 16]\n",
      "layer1.2.conv2 [0, 39, 40, 50, 41, 22, 1]\n",
      "layer1.2.conv1 [46, 34, 8, 37, 10, 19, 50]\n",
      "layer2.0.conv2 [0, 9, 31, 62, 18, 17, 57, 21, 87, 60, 42, 37, 79]\n",
      "layer2.0.conv1 [89, 45, 81, 84, 55, 73, 82, 70, 10, 99, 48, 80, 7]\n",
      "layer2.1.conv2 [37, 71, 65, 5, 1, 63, 52, 7, 4, 9, 77, 95, 99]\n",
      "layer2.1.conv1 [59, 23, 11, 13, 55, 60, 79, 61, 14, 82, 10, 98, 9]\n",
      "layer2.2.conv2 [73, 86, 35, 72, 39, 95, 67, 19, 78, 98, 66, 64, 13]\n",
      "layer2.2.conv1 [69, 56, 19, 94, 8, 89, 50, 38, 20, 79, 32, 65, 37]\n",
      "layer2.3.conv2 [89, 45, 1, 101, 37, 80, 5, 81, 86, 43, 38, 34, 56]\n",
      "layer2.3.conv1 [12, 79, 33, 30, 50, 16, 0, 47, 56, 18, 11, 53, 77]\n",
      "layer3.0.conv2 [27, 83, 134, 77, 171, 75, 112, 43, 156, 133, 7, 94, 79, 89, 73, 198, 91, 92, 201, 158, 145, 50, 197, 101, 121]\n",
      "layer3.0.conv1 [45, 96, 110, 198, 15, 107, 40, 140, 188, 68, 181, 6, 203, 60, 133, 97, 167, 30, 106, 3, 64, 126, 70, 89, 78]\n",
      "layer3.1.conv2 [40, 46, 166, 141, 31, 45, 104, 128, 38, 14, 30, 131, 6, 179, 174, 120, 125, 16, 59, 72, 39, 182, 88, 43, 86]\n",
      "layer3.1.conv1 [13, 133, 113, 171, 19, 185, 26, 33, 32, 202, 64, 188, 135, 126, 199, 17, 159, 107, 196, 172, 109, 93, 195, 25, 129]\n",
      "layer3.2.conv2 [126, 106, 29, 140, 12, 63, 50, 191, 42, 198, 99, 150, 72, 11, 88, 96, 2, 152, 30, 121, 54, 141, 82, 74, 201]\n",
      "layer3.2.conv1 [188, 147, 5, 159, 33, 103, 183, 114, 14, 136, 163, 170, 160, 26, 168, 126, 25, 20, 4, 86, 201, 135, 78, 77, 21]\n",
      "layer3.3.conv2 [149, 137, 167, 94, 87, 145, 34, 173, 14, 160, 90, 15, 47, 174, 142, 171, 199, 106, 58, 127, 62, 170, 117, 60, 111]\n",
      "layer3.3.conv1 [127, 122, 74, 93, 58, 34, 165, 41, 140, 16, 27, 56, 87, 163, 98, 75, 64, 175, 83, 109, 169, 108, 145, 57, 69]\n",
      "layer3.4.conv2 [67, 115, 157, 155, 156, 91, 43, 183, 70, 16, 41, 195, 145, 97, 37, 191, 187, 21, 49, 63, 125, 143, 123, 12, 194]\n",
      "layer3.4.conv1 [11, 176, 51, 52, 201, 9, 33, 160, 5, 93, 17, 55, 157, 58, 174, 73, 63, 67, 77, 202, 34, 106, 125, 22, 25]\n",
      "layer3.5.conv2 [62, 63, 195, 38, 122, 131, 102, 57, 137, 41, 118, 95, 119, 45, 42, 121, 152, 154, 69, 36, 190, 52, 166, 145, 156]\n",
      "layer3.5.conv1 [69, 163, 179, 5, 140, 128, 32, 158, 102, 66, 58, 181, 83, 68, 164, 166, 31, 198, 202, 180, 38, 7, 11, 184, 27]\n",
      "layer4.0.conv2 [264, 231, 166, 316, 241, 270, 153, 336, 34, 183, 51, 376, 38, 204, 224, 1, 86, 142, 82, 351, 12, 131, 148, 328, 280, 57, 20, 387, 381, 169, 170, 386, 90, 255, 339, 125, 61, 123, 346, 160, 232, 262, 301, 168, 50, 88, 129, 276, 281, 152, 249]\n",
      "layer4.0.conv1 [157, 93, 78, 388, 270, 203, 144, 91, 269, 344, 28, 272, 240, 350, 222, 297, 135, 323, 209, 137, 204, 253, 154, 175, 311, 366, 288, 190, 252, 35, 376, 328, 102, 228, 362, 147, 360, 181, 184, 164, 90, 200, 356, 118, 379, 44, 282, 384, 353, 182, 105]\n",
      "layer4.1.conv2 [111, 148, 299, 73, 308, 254, 374, 305, 311, 166, 46, 89, 90, 192, 105, 229, 149, 317, 87, 27, 130, 326, 204, 7, 168, 289, 194, 282, 137, 11, 71, 183, 260, 56, 159, 243, 120, 368, 293, 312, 9, 381, 135, 172, 78, 145, 387, 366, 23, 49, 18]\n",
      "layer4.1.conv1 [51, 311, 125, 146, 147, 355, 306, 305, 111, 302, 353, 113, 114, 301, 299, 297, 295, 294, 201, 161, 162, 163, 351, 349, 117, 287, 167, 285, 282, 278, 120, 121, 277, 273, 346, 123, 343, 270, 337, 129, 267, 262, 130, 261, 258, 331, 327, 47, 134, 135, 237]\n",
      "layer4.2.conv2 [78, 54, 387, 161, 315, 5, 157, 406, 72, 236, 2, 281, 4, 209, 201, 173, 186, 86, 135, 48, 287, 267, 75, 343, 367, 8, 215, 265, 233, 257, 175, 139, 324, 278, 192, 126, 321, 25, 405, 59, 379, 65, 408, 58, 102, 258, 237, 309, 247, 352, 187]\n",
      "layer4.2.conv1 [229, 246, 164, 244, 242, 167, 239, 137, 237, 171, 298, 139, 174, 175, 176, 177, 231, 230, 294, 180, 210, 182, 183, 228, 293, 226, 225, 187, 224, 221, 190, 162, 291, 219, 218, 193, 288, 287, 286, 211, 284, 209, 148, 152, 155, 156, 406, 47, 48, 49, 50]\n",
      "Pruning step: 3 multiply–accumulate (macs): 2033869720.0 number of parameters 12935549\n",
      "layer4.0.downsample.0 [34, 804, 1196, 1006, 769, 1367, 104, 409, 563, 227, 1101, 376, 522, 1086, 480, 1319, 326, 657, 570, 1030, 559, 400, 286, 1371, 982, 717, 1314, 380, 1043, 1311, 1167, 40, 949, 543, 232, 142, 598, 812, 221, 806, 311, 1417, 393, 1344, 465, 362, 291, 413, 85, 511, 853, 762, 793, 1018, 660, 41, 828, 931, 1205, 896, 1330, 374, 817, 926, 839, 144, 871, 98, 972, 1190, 647, 292, 1248, 705, 252, 1109, 692, 432, 272, 1131, 429, 1333, 1244, 1136, 444, 1360, 27, 165, 567, 373, 1238, 969, 254, 1257, 35, 1028, 1198, 29, 276, 415, 43, 396, 228, 720, 907, 1054, 979, 904, 1294, 848, 789, 304, 238, 1332, 694, 730, 945, 448, 1296, 1092, 234, 599, 794, 1114, 463, 1412, 1192, 17, 745, 1061, 532, 658, 592, 991, 131, 1042, 529, 1143, 725, 897, 876, 631, 147, 1120, 687, 1138, 9, 693, 2, 894, 329, 185, 18, 1162, 492, 1070, 57, 1237, 45, 1338, 870, 1362, 862, 1195, 774, 873, 963, 305, 1221, 596, 1040, 574, 954, 702, 140, 874, 156, 548, 466, 324, 162, 1380, 900, 948, 1331, 932, 1283, 1409, 711, 939, 847, 841, 1389, 1137, 1055, 1180, 107, 537, 1379, 515, 1038, 936, 680, 586, 663]\n",
      "layer3.0.downsample.0 [98, 615, 111, 221, 359, 159, 104, 433, 393, 213, 671, 627, 412, 146, 657, 148, 184, 472, 695, 420, 379, 656, 641, 644, 528, 411, 437, 436, 638, 355, 81, 519, 154, 125, 156, 8, 712, 179, 419, 35, 489, 43, 157, 244, 112, 238, 500, 241, 258, 352, 162, 684, 381, 323, 26, 634, 173, 569, 296, 469, 484, 331, 683, 325, 366, 403, 255, 182, 602, 334, 203, 374, 142, 482, 632, 558, 158, 73, 395, 79, 23, 455, 497, 408, 608, 406, 506, 298, 93, 288, 495, 57, 386, 576, 375, 660, 617, 236, 689, 310, 507, 38]\n",
      "layer2.0.downsample.0 [196, 83, 270, 253, 350, 283, 41, 48, 334, 309, 200, 123, 325, 135, 19, 281, 86, 68, 175, 216, 227, 182, 16, 36, 271, 223, 357, 320, 95, 153, 180, 130, 64, 336, 174, 194, 316, 346, 57, 134, 51, 124, 225, 232, 269, 244, 3, 221, 73, 8, 146]\n",
      "layer1.0.downsample.0 [22, 23, 172, 63, 157, 129, 108, 160, 52, 43, 24, 156, 61, 17, 166, 37, 72, 8, 32, 110, 117, 176, 124, 102, 0, 62]\n",
      "conv1 [34, 39, 3, 25, 18, 28]\n",
      "layer1.0.conv2 [10, 23, 38, 32, 20, 18]\n",
      "layer1.0.conv1 [7, 26, 38, 15, 39, 21]\n",
      "layer1.1.conv2 [10, 30, 37, 35, 0, 42]\n",
      "layer1.1.conv1 [40, 25, 31, 8, 17, 9]\n",
      "layer1.2.conv2 [35, 12, 19, 42, 0, 4]\n",
      "layer1.2.conv1 [1, 24, 34, 14, 29, 27]\n",
      "layer2.0.conv2 [55, 10, 18, 63, 62, 66, 8, 6, 88, 42, 57, 75, 72]\n",
      "layer2.0.conv1 [45, 80, 82, 1, 38, 85, 74, 62, 15, 43, 44, 17, 42]\n",
      "layer2.1.conv2 [4, 61, 64, 74, 70, 35, 45, 56, 48, 87, 7, 62, 86]\n",
      "layer2.1.conv1 [80, 27, 37, 38, 11, 26, 82, 43, 67, 2, 66, 81, 64]\n",
      "layer2.2.conv2 [83, 36, 27, 85, 15, 17, 47, 75, 76, 77, 0, 14, 40]\n",
      "layer2.2.conv1 [43, 82, 33, 48, 28, 86, 65, 47, 64, 58, 38, 55, 10]\n",
      "layer2.3.conv2 [21, 75, 40, 66, 36, 28, 72, 32, 68, 25, 3, 1, 60]\n",
      "layer2.3.conv1 [66, 14, 5, 15, 28, 38, 10, 78, 71, 2, 30, 84, 18]\n",
      "layer3.0.conv2 [175, 130, 118, 77, 126, 173, 53, 19, 45, 66, 100, 43, 109, 146, 22, 149, 44, 75, 78, 116, 6, 131, 140, 143, 171, 28]\n",
      "layer3.0.conv1 [106, 171, 90, 177, 24, 178, 28, 5, 20, 135, 100, 49, 68, 64, 35, 115, 86, 133, 143, 81, 59, 148, 140, 96, 26, 118]\n",
      "layer3.1.conv2 [88, 9, 151, 37, 92, 137, 64, 162, 123, 57, 130, 83, 170, 12, 85, 13, 71, 118, 165, 89, 93, 147, 0, 141, 29, 4]\n",
      "layer3.1.conv1 [29, 113, 171, 170, 162, 143, 78, 26, 128, 139, 74, 94, 4, 71, 32, 110, 115, 121, 153, 163, 114, 64, 70, 5, 154, 158]\n",
      "layer3.2.conv2 [59, 68, 25, 123, 52, 121, 60, 6, 78, 37, 150, 115, 164, 79, 95, 18, 11, 172, 71, 165, 80, 103, 158, 152, 102, 160]\n",
      "layer3.2.conv1 [119, 68, 4, 131, 124, 12, 118, 13, 70, 53, 76, 34, 26, 51, 121, 130, 38, 16, 46, 129, 110, 114, 75, 60, 103, 107]\n",
      "layer3.3.conv2 [31, 134, 121, 132, 37, 141, 40, 21, 79, 7, 112, 85, 47, 173, 58, 75, 9, 156, 77, 80, 127, 154, 76, 89, 137, 17]\n",
      "layer3.3.conv1 [175, 17, 141, 124, 161, 1, 10, 128, 117, 121, 2, 133, 137, 6, 89, 173, 106, 15, 42, 24, 38, 32, 93, 80, 113, 148]\n",
      "layer3.4.conv2 [145, 58, 168, 54, 30, 154, 175, 90, 28, 126, 52, 112, 62, 152, 75, 8, 144, 91, 44, 96, 133, 29, 172, 115, 4, 173]\n",
      "layer3.4.conv1 [161, 71, 126, 152, 141, 72, 6, 137, 144, 95, 102, 174, 64, 160, 70, 119, 122, 54, 176, 18, 116, 172, 81, 96, 97, 78]\n",
      "layer3.5.conv2 [144, 91, 45, 2, 159, 134, 111, 77, 80, 81, 130, 143, 19, 129, 40, 136, 135, 25, 50, 125, 37, 56, 23, 123, 7, 98]\n",
      "layer3.5.conv1 [102, 2, 105, 3, 71, 110, 69, 154, 23, 138, 53, 35, 140, 59, 33, 27, 161, 108, 18, 15, 139, 96, 103, 169, 91, 107]\n",
      "layer4.0.conv2 [244, 75, 352, 111, 154, 107, 266, 32, 243, 161, 297, 115, 79, 235, 25, 348, 33, 9, 208, 289, 147, 36, 11, 347, 339, 53, 141, 39, 152, 128, 64, 225, 320, 136, 238, 333, 116, 293, 295, 229, 189, 259, 143, 67, 338, 170, 28, 83, 357, 139, 306]\n",
      "layer4.0.conv1 [300, 231, 20, 324, 250, 233, 184, 134, 59, 279, 90, 327, 307, 199, 178, 111, 110, 149, 274, 65, 333, 133, 43, 252, 245, 281, 23, 144, 346, 83, 211, 319, 354, 296, 290, 2, 106, 276, 121, 331, 343, 248, 130, 7, 266, 255, 112, 320, 206, 38, 32]\n",
      "layer4.1.conv2 [176, 197, 83, 23, 341, 3, 244, 261, 330, 205, 258, 187, 345, 22, 113, 56, 21, 211, 135, 242, 192, 85, 163, 106, 139, 134, 61, 236, 177, 92, 277, 170, 28, 42, 190, 307, 108, 210, 168, 240, 80, 185, 116, 47, 297, 33, 78, 267, 224, 141, 321]\n",
      "layer4.1.conv1 [276, 199, 210, 72, 209, 208, 95, 51, 87, 61, 189, 188, 70, 93, 90, 50, 271, 104, 187, 185, 81, 69, 60, 54, 56, 75, 100, 80, 204, 98, 122, 94, 277, 125, 128, 62, 179, 42, 172, 36, 136, 77, 96, 192, 201, 22, 286, 337, 305, 106, 39]\n",
      "layer4.2.conv2 [205, 171, 67, 118, 5, 184, 101, 23, 209, 232, 186, 224, 46, 54, 156, 323, 213, 349, 174, 4, 170, 78, 330, 313, 59, 238, 237, 185, 352, 106, 194, 135, 258, 40, 38, 110, 256, 152, 68, 93, 176, 14, 226, 27, 294, 206, 41, 9, 142, 134, 222]\n",
      "layer4.2.conv1 [79, 352, 351, 357, 81, 82, 83, 273, 346, 85, 86, 92, 271, 91, 73, 338, 74, 208, 211, 336, 332, 331, 90, 328, 75, 326, 324, 76, 77, 275, 354, 128, 127, 124, 122, 121, 308, 252, 118, 117, 116, 253, 113, 110, 256, 108, 257, 106, 105, 291, 288]\n",
      "Pruning step: 4 multiply–accumulate (macs): 1506416684.0 number of parameters 9676689\n",
      "layer4.0.downsample.0 [530, 41, 267, 955, 331, 759, 312, 68, 1040, 1208, 10, 39, 1127, 483, 67, 587, 912, 1051, 1156, 1122, 542, 876, 5, 490, 460, 60, 946, 301, 917, 244, 489, 934, 674, 681, 516, 936, 512, 957, 719, 931, 1017, 484, 740, 655, 974, 932, 1210, 403, 1158, 98, 1221, 826, 211, 784, 1086, 286, 844, 1147, 1024, 585, 368, 329, 971, 278, 84, 812, 889, 417, 685, 223, 47, 456, 550, 51, 420, 1016, 713, 124, 1154, 507, 1037, 775, 1225, 102, 128, 657, 148, 179, 1109, 1063, 397, 704, 1023, 739, 1071, 495, 137, 564, 320, 486, 279, 789, 32, 663, 529, 549, 315, 180, 78, 639, 722, 1080, 835, 1160, 1111, 760, 715, 660, 1212, 1018, 22, 446, 236, 627, 843, 248, 309, 510, 1069, 36, 46, 1161, 635, 1056, 526, 544, 519, 605, 321, 763, 310, 205, 106, 601, 702, 258, 435, 902, 1139, 594, 731, 184, 176, 4, 961, 340, 69, 1220, 202, 452, 434, 478, 830, 496, 93, 890, 825, 16, 257, 400, 45, 1219, 317, 409, 666, 414, 1181, 398, 872, 531, 752, 289, 1224, 776, 130, 8, 521, 1028, 581, 447, 617, 979, 1159, 612, 1177, 995, 473, 618, 865, 870, 839, 361, 747, 980]\n",
      "layer3.0.downsample.0 [593, 599, 484, 530, 492, 457, 185, 117, 58, 562, 8, 141, 481, 243, 299, 183, 138, 284, 476, 499, 26, 418, 557, 458, 421, 147, 110, 447, 408, 523, 93, 228, 69, 510, 348, 220, 361, 456, 253, 297, 314, 578, 384, 332, 325, 173, 146, 174, 47, 291, 498, 158, 281, 236, 19, 329, 494, 350, 545, 309, 506, 413, 527, 435, 474, 449, 267, 270, 16, 479, 133, 290, 592, 426, 101, 199, 417, 144, 396, 382, 341, 46, 554, 323, 321, 232, 188, 602, 119, 285, 589, 195, 431, 502, 75, 155, 21, 441, 23, 68, 107, 216]\n",
      "layer2.0.downsample.0 [170, 216, 270, 172, 73, 2, 123, 1, 76, 262, 43, 249, 265, 118, 92, 217, 231, 210, 64, 60, 218, 67, 137, 243, 25, 23, 235, 131, 134, 116, 237, 140, 225, 147, 184, 153, 165, 88, 190, 234, 162, 24, 254, 77, 171, 299, 143, 106, 149, 206, 294]\n",
      "layer1.0.downsample.0 [115, 25, 61, 148, 127, 140, 36, 104, 67, 147, 47, 78, 20, 130, 34, 101, 19, 98, 23, 57, 80, 48, 124, 13, 49]\n",
      "conv1 [23, 35, 6, 19, 24, 33]\n",
      "layer1.0.conv2 [36, 2, 26, 18, 22, 27]\n",
      "layer1.0.conv1 [20, 1, 23, 35, 22, 36]\n",
      "layer1.1.conv2 [37, 3, 11, 25, 0, 4]\n",
      "layer1.1.conv1 [8, 18, 5, 3, 17, 30]\n",
      "layer1.2.conv2 [24, 7, 34, 6, 16, 31]\n",
      "layer1.2.conv1 [34, 20, 10, 33, 36, 1]\n",
      "layer2.0.conv2 [13, 5, 22, 8, 15, 52, 35, 12, 11, 68, 16, 63]\n",
      "layer2.0.conv1 [7, 66, 32, 33, 40, 72, 38, 10, 8, 12, 57, 44]\n",
      "layer2.1.conv2 [66, 43, 42, 28, 58, 6, 74, 45, 44, 0, 5, 56]\n",
      "layer2.1.conv1 [11, 46, 58, 69, 19, 14, 12, 35, 70, 20, 66, 75]\n",
      "layer2.2.conv2 [53, 74, 2, 13, 24, 38, 46, 45, 59, 70, 48, 41]\n",
      "layer2.2.conv1 [70, 38, 28, 20, 65, 24, 69, 12, 13, 54, 43, 34]\n",
      "layer2.3.conv2 [27, 0, 59, 65, 13, 73, 8, 18, 49, 71, 37, 9]\n",
      "layer2.3.conv1 [22, 49, 25, 35, 54, 34, 12, 33, 11, 0, 53, 27]\n",
      "layer3.0.conv2 [135, 119, 19, 49, 77, 26, 57, 125, 53, 72, 152, 63, 27, 60, 56, 28, 15, 74, 111, 41, 118, 70, 48, 90, 9]\n",
      "layer3.0.conv1 [37, 79, 84, 51, 46, 146, 94, 55, 128, 23, 92, 145, 62, 143, 87, 8, 89, 90, 4, 100, 108, 139, 142, 97, 88]\n",
      "layer3.1.conv2 [110, 109, 103, 86, 63, 18, 58, 87, 115, 31, 62, 11, 126, 102, 78, 133, 55, 97, 120, 75, 148, 134, 60, 73, 41]\n",
      "layer3.1.conv1 [136, 104, 38, 74, 6, 77, 45, 66, 4, 16, 86, 141, 19, 21, 94, 147, 124, 10, 101, 117, 142, 121, 29, 57, 123]\n",
      "layer3.2.conv2 [5, 118, 110, 88, 6, 107, 82, 45, 22, 12, 10, 8, 55, 16, 94, 35, 152, 27, 64, 99, 43, 151, 136, 66, 70]\n",
      "layer3.2.conv1 [62, 139, 55, 79, 13, 10, 40, 69, 86, 148, 92, 152, 131, 122, 37, 143, 4, 132, 7, 113, 91, 64, 11, 137, 3]\n",
      "layer3.3.conv2 [21, 80, 41, 59, 125, 28, 31, 11, 16, 76, 47, 109, 113, 142, 95, 35, 57, 24, 15, 86, 105, 104, 26, 149, 122]\n",
      "layer3.3.conv1 [38, 40, 96, 109, 81, 8, 134, 105, 48, 104, 9, 47, 146, 23, 86, 120, 110, 75, 90, 58, 60, 45, 111, 148, 97]\n",
      "layer3.4.conv2 [148, 42, 76, 142, 127, 133, 38, 108, 78, 100, 19, 35, 27, 88, 115, 111, 69, 31, 114, 77, 12, 120, 9, 67, 6]\n",
      "layer3.4.conv1 [119, 62, 75, 108, 10, 76, 130, 37, 6, 99, 59, 68, 3, 101, 20, 120, 65, 140, 142, 81, 121, 144, 86, 52, 89]\n",
      "layer3.5.conv2 [61, 78, 6, 73, 150, 5, 27, 102, 120, 34, 60, 62, 114, 117, 112, 79, 38, 99, 2, 69, 4, 64, 44, 126, 63]\n",
      "layer3.5.conv1 [148, 4, 0, 122, 65, 127, 58, 150, 13, 15, 137, 124, 111, 115, 18, 85, 109, 141, 103, 7, 54, 125, 6, 105, 48]\n",
      "layer4.0.conv2 [224, 162, 28, 48, 123, 253, 4, 85, 143, 161, 192, 172, 264, 229, 301, 38, 177, 230, 186, 219, 243, 140, 187, 116, 155, 21, 254, 266, 77, 180, 24, 209, 91, 206, 271, 286, 141, 291, 111, 10, 185, 52, 227, 208, 255, 69, 44, 290, 150, 188, 163]\n",
      "layer4.0.conv1 [79, 131, 256, 193, 117, 37, 147, 103, 209, 298, 278, 229, 124, 250, 57, 303, 65, 52, 159, 25, 55, 292, 48, 21, 194, 14, 217, 16, 164, 202, 104, 241, 32, 215, 20, 23, 135, 76, 212, 204, 64, 127, 54, 150, 121, 15, 296, 3, 180, 252, 134]\n",
      "layer4.1.conv2 [60, 128, 258, 123, 161, 204, 153, 215, 97, 156, 236, 133, 289, 297, 129, 23, 287, 77, 101, 10, 140, 182, 165, 274, 138, 176, 275, 273, 244, 225, 137, 102, 164, 218, 148, 92, 251, 183, 68, 43, 48, 282, 260, 249, 124, 213, 189, 199, 270, 42, 75]\n",
      "layer4.1.conv1 [214, 57, 167, 280, 248, 61, 210, 262, 221, 84, 30, 33, 106, 179, 172, 136, 153, 56, 43, 304, 52, 155, 119, 232, 285, 180, 274, 264, 8, 89, 58, 67, 158, 149, 53, 306, 251, 187, 198, 147, 254, 228, 253, 183, 126, 284, 245, 224, 204, 168, 256]\n",
      "layer4.2.conv2 [68, 222, 96, 85, 82, 26, 203, 20, 175, 52, 50, 28, 251, 131, 79, 138, 53, 73, 217, 99, 233, 61, 237, 211, 179, 102, 78, 244, 98, 130, 205, 178, 266, 51, 150, 259, 219, 216, 121, 256, 93, 127, 23, 240, 159, 299, 54, 45, 170, 148, 149]\n",
      "layer4.2.conv1 [226, 80, 71, 70, 90, 68, 66, 87, 251, 64, 86, 61, 53, 250, 55, 59, 58, 54, 56, 145, 224, 119, 248, 283, 24, 199, 169, 152, 69, 89, 198, 255, 74, 178, 300, 168, 212, 48, 246, 304, 280, 57, 18, 238, 302, 118, 173, 161, 31, 102, 10]\n",
      "Pruning step: 5 multiply–accumulate (macs): 1068682472.0 number of parameters 6917640\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n",
      "Pruning sparsity: 0.5625\n",
      "layer4.0.downsample.0 [605, 351, 2, 991, 898, 1925, 854, 1154, 1530, 899, 1051, 663, 112, 1099, 167, 653, 16, 309, 1288, 338, 471, 839, 1326, 100, 93, 1058, 583, 1126, 1427, 955, 1748, 275, 1993, 1827, 1510, 1349, 311, 892, 143, 675, 1201, 1542, 468, 102, 616, 1592, 1980, 1253, 218, 808, 745, 1868, 1193, 1568, 1077, 968, 1888, 1906, 478, 1144, 1743, 301, 2046, 1292, 415, 1578, 1156, 1056, 1014, 1532, 1555, 619, 728, 563, 1727, 1492, 1192, 108, 1344, 2020, 456, 695, 1702, 80, 1477, 307, 1444, 660, 1973, 327, 1645, 1262, 153, 1932, 1929, 623, 1843, 1726, 1880, 1093, 362, 1336, 1496, 1974, 455, 1595, 558, 1941, 950, 1371, 622, 833, 194, 204, 751, 1819, 861, 119, 794, 1968, 1055, 1441, 1898, 1619, 715, 12, 2003, 144, 1087, 533, 1958, 303, 382, 929, 449, 305, 77, 1460, 241, 1693, 706, 195, 2040, 801, 868, 1286, 975, 617, 1406, 427, 32, 1608, 296, 1139, 66, 1211, 54, 685, 743, 1817, 2042, 1203, 1429, 1428, 1820, 1600, 472, 1191, 1301, 140, 755, 734, 1312, 1718, 1249, 1692, 1769, 447, 1889, 1270, 526, 94, 1046, 721, 1680, 377, 1225, 964, 771, 1357, 1598, 331, 895, 474, 1393, 1967, 1658, 220, 353, 1081, 1770, 247, 705, 803, 1908, 2022, 754, 83, 974, 1412, 302, 1724, 1036, 910, 1613, 1028, 863, 1414, 687, 1685, 578, 1614, 453, 1003, 936, 244, 1757, 1683, 319, 250, 916]\n",
      "layer3.0.downsample.0 [962, 486, 1023, 1018, 853, 412, 197, 657, 18, 491, 544, 501, 91, 644, 906, 96, 803, 170, 303, 45, 759, 729, 595, 741, 1017, 60, 51, 105, 980, 778, 500, 923, 123, 444, 83, 609, 38, 419, 151, 927, 685, 728, 590, 478, 716, 514, 701, 966, 744, 390, 928, 388, 194, 873, 487, 817, 297, 662, 311, 709, 656, 283, 511, 352, 579, 748, 325, 149, 1011, 417, 732, 620, 16, 956, 468, 589, 972, 836, 825, 801, 678, 475, 800, 371, 767, 619, 819, 683, 536, 706, 863, 747, 37, 340, 407, 924, 72, 457, 664, 1022, 92, 919, 610, 766, 205, 118, 331, 192, 365, 541, 556, 44, 772, 132, 21, 4]\n",
      "layer2.0.downsample.0 [387, 176, 246, 243, 404, 347, 34, 163, 100, 24, 412, 11, 66, 424, 363, 114, 53, 43, 96, 371, 0, 33, 207, 495, 326, 166, 379, 98, 382, 361, 311, 85, 147, 309, 65, 438, 192, 328, 188, 442, 465, 339, 509, 60, 81, 133, 10, 372, 279, 117, 184, 177, 229, 58, 102, 411, 260, 269]\n",
      "layer1.0.downsample.0 [144, 77, 108, 214, 150, 131, 58, 112, 156, 29, 10, 235, 31, 92, 233, 245, 68, 225, 36, 196, 103, 63, 193, 97, 231, 218, 69, 0, 135]\n",
      "conv1 [42, 13, 44, 52, 57, 11, 31, 58]\n",
      "layer1.0.conv2 [0, 1, 19, 22, 61, 9, 60, 59]\n",
      "layer1.0.conv1 [27, 1, 60, 58, 38, 7, 35, 56]\n",
      "layer1.1.conv2 [17, 41, 25, 44, 45, 6, 38, 30]\n",
      "layer1.1.conv1 [23, 2, 4, 38, 47, 55, 9, 45]\n",
      "layer1.2.conv2 [11, 7, 24, 57, 39, 4, 21, 18]\n",
      "layer1.2.conv1 [2, 39, 49, 45, 63, 52, 11, 33]\n",
      "layer2.0.conv2 [35, 90, 119, 69, 51, 110, 120, 54, 115, 29, 12, 3, 4, 0, 113]\n",
      "layer2.0.conv1 [92, 63, 112, 104, 68, 8, 66, 89, 12, 110, 14, 99, 61, 2, 122]\n",
      "layer2.1.conv2 [29, 9, 10, 77, 46, 100, 109, 93, 54, 120, 121, 38, 126, 30, 81]\n",
      "layer2.1.conv1 [1, 102, 3, 5, 111, 69, 56, 83, 79, 58, 76, 14, 63, 28, 29]\n",
      "layer2.2.conv2 [29, 56, 34, 18, 39, 2, 101, 75, 125, 35, 32, 47, 97, 43, 12]\n",
      "layer2.2.conv1 [112, 75, 120, 117, 38, 102, 63, 40, 12, 6, 88, 124, 110, 46, 76]\n",
      "layer2.3.conv2 [127, 36, 105, 17, 113, 67, 111, 124, 0, 19, 21, 76, 116, 42, 2]\n",
      "layer2.3.conv1 [74, 9, 6, 114, 120, 4, 52, 79, 49, 37, 30, 33, 23, 44, 127]\n",
      "layer3.0.conv2 [133, 54, 2, 35, 221, 116, 106, 141, 13, 248, 157, 194, 250, 232, 151, 4, 152, 160, 222, 207, 111, 115, 247, 127, 192, 44, 199, 150, 126]\n",
      "layer3.0.conv1 [136, 245, 4, 220, 18, 48, 90, 139, 148, 254, 160, 89, 196, 44, 134, 70, 103, 110, 212, 244, 42, 92, 19, 197, 39, 225, 189, 194, 125]\n",
      "layer3.1.conv2 [9, 221, 254, 123, 130, 111, 127, 7, 8, 132, 246, 133, 72, 235, 56, 100, 16, 155, 146, 229, 108, 228, 74, 23, 24, 88, 42, 191, 188]\n",
      "layer3.1.conv1 [32, 75, 231, 76, 77, 79, 171, 165, 50, 229, 85, 162, 92, 13, 54, 97, 227, 225, 222, 103, 221, 152, 150, 149, 217, 194, 144, 142, 133]\n",
      "layer3.2.conv2 [35, 196, 79, 117, 108, 149, 43, 76, 157, 47, 166, 56, 156, 34, 17, 190, 99, 14, 233, 153, 186, 30, 202, 37, 112, 250, 73, 241, 81]\n",
      "layer3.2.conv1 [30, 192, 47, 105, 196, 51, 23, 29, 97, 155, 134, 20, 148, 212, 99, 100, 164, 56, 216, 181, 161, 167, 1, 242, 83, 62, 59, 95, 71]\n",
      "layer3.3.conv2 [190, 148, 247, 127, 35, 157, 100, 146, 34, 218, 43, 82, 161, 236, 37, 221, 71, 197, 255, 124, 169, 131, 38, 152, 52, 145, 194, 76, 171]\n",
      "layer3.3.conv1 [219, 181, 58, 217, 9, 31, 189, 195, 144, 211, 214, 24, 19, 100, 59, 124, 240, 71, 254, 41, 155, 236, 128, 79, 114, 244, 213, 227, 74]\n",
      "layer3.4.conv2 [116, 186, 50, 42, 105, 244, 242, 41, 144, 19, 126, 53, 252, 169, 79, 150, 35, 164, 165, 38, 179, 149, 210, 212, 241, 202, 174, 198, 213]\n",
      "layer3.4.conv1 [6, 55, 164, 48, 45, 73, 10, 108, 87, 110, 190, 26, 99, 100, 204, 21, 240, 1, 227, 111, 8, 121, 65, 14, 153, 199, 60, 71, 122]\n",
      "layer3.5.conv2 [94, 186, 38, 142, 221, 239, 91, 77, 178, 203, 59, 135, 143, 215, 219, 206, 105, 137, 115, 183, 0, 127, 52, 45, 53, 128, 8, 222, 224]\n",
      "layer3.5.conv1 [16, 1, 81, 3, 5, 203, 29, 204, 10, 220, 70, 166, 133, 126, 153, 95, 251, 190, 197, 249, 246, 114, 84, 199, 200, 33, 250, 205, 55]\n",
      "layer4.0.conv2 [268, 326, 84, 306, 290, 492, 111, 78, 166, 335, 163, 342, 12, 91, 461, 453, 244, 160, 178, 203, 204, 157, 511, 286, 126, 284, 61, 60, 130, 419, 365, 274, 272, 269, 253, 245, 371, 375, 378, 388, 386, 143, 144, 383, 48, 50, 381, 236, 142, 35, 192, 409, 231, 33, 374, 238, 46, 415]\n",
      "layer4.0.conv1 [225, 143, 467, 457, 252, 34, 53, 328, 510, 488, 10, 429, 329, 219, 487, 15, 338, 268, 189, 349, 132, 383, 309, 314, 124, 394, 312, 107, 431, 316, 471, 326, 241, 388, 304, 336, 479, 234, 500, 251, 253, 259, 436, 254, 112, 114, 191, 230, 472, 231, 340, 12, 227, 220, 483, 232, 55, 31]\n",
      "layer4.1.conv2 [32, 153, 2, 375, 118, 497, 120, 122, 370, 487, 369, 126, 368, 355, 480, 352, 144, 351, 18, 348, 148, 347, 475, 470, 333, 469, 155, 465, 331, 464, 30, 328, 162, 163, 327, 35, 36, 169, 170, 172, 40, 317, 459, 177, 457, 454, 46, 178, 179, 448, 313, 51, 183, 442, 54, 439, 437, 57]\n",
      "layer4.1.conv1 [64, 435, 436, 203, 204, 441, 206, 7, 207, 9, 10, 208, 442, 210, 211, 443, 213, 17, 444, 19, 215, 448, 217, 450, 452, 25, 220, 460, 222, 29, 30, 31, 462, 464, 465, 35, 467, 470, 228, 229, 471, 41, 231, 43, 44, 45, 46, 47, 48, 472, 233, 51, 52, 474, 54, 475, 236, 477]\n",
      "layer4.2.conv2 [0, 213, 155, 158, 368, 160, 166, 7, 8, 362, 302, 11, 507, 80, 171, 15, 173, 219, 295, 359, 294, 176, 502, 178, 87, 353, 26, 348, 494, 486, 92, 187, 188, 33, 337, 96, 336, 37, 333, 99, 331, 284, 328, 43, 201, 283, 309, 47, 281, 308, 105, 307, 469, 463, 54, 277, 440, 243]\n",
      "layer4.2.conv1 [64, 435, 434, 328, 431, 5, 6, 468, 428, 427, 424, 423, 473, 13, 14, 15, 16, 475, 18, 19, 418, 478, 415, 412, 24, 411, 26, 410, 409, 29, 479, 483, 407, 33, 34, 164, 36, 443, 38, 405, 403, 485, 163, 396, 395, 394, 162, 447, 48, 49, 50, 329, 382, 486, 159, 381, 488, 157]\n",
      "Pruning step: 1 multiply–accumulate (macs): 3239550232.0 number of parameters 20301833\n",
      "layer4.0.downsample.0 [628, 1489, 183, 616, 913, 1163, 1601, 526, 1282, 746, 1626, 600, 262, 254, 889, 371, 631, 1213, 1714, 1182, 767, 64, 976, 1460, 1518, 929, 1507, 1037, 1452, 1598, 1087, 1472, 939, 1654, 1064, 1674, 1740, 56, 1657, 577, 1058, 347, 1769, 461, 44, 106, 1386, 1543, 1023, 621, 1690, 419, 1706, 1656, 1013, 1560, 406, 151, 1071, 228, 1032, 93, 1082, 243, 1217, 1157, 19, 607, 1597, 1643, 1394, 1165, 1600, 47, 180, 762, 422, 639, 1608, 1579, 1113, 1147, 1185, 830, 643, 105, 1782, 300, 629, 780, 714, 200, 1539, 506, 1281, 786, 83, 1302, 828, 1502, 1052, 10, 1273, 1623, 965, 376, 344, 397, 691, 1080, 35, 613, 255, 85, 1138, 1742, 292, 1050, 256, 1104, 1380, 812, 945, 1188, 1726, 147, 94, 1606, 1733, 598, 617, 1698, 892, 975, 440, 434, 12, 1359, 1550, 1065, 1602, 108, 6, 844, 1467, 387, 1440, 67, 1723, 1271, 692, 1244, 1247, 367, 1183, 995, 364, 159, 1486, 259, 201, 1392, 557, 81, 1036, 209, 385, 554, 291, 754, 9, 654, 1628, 1382, 1193, 597, 1076, 679, 63, 1559, 667, 736, 1570, 652, 1592, 13, 1336, 1760, 1749, 426, 112, 842, 610, 673, 36, 1661, 330, 851, 242, 1049, 1124, 1488, 437, 1294, 451, 1218, 1089, 312, 1005, 862, 1346, 26, 1484, 110, 91, 671, 1512, 226, 496, 635, 497, 1572, 881, 1641, 1774, 1078, 340, 494, 1297, 708]\n",
      "layer3.0.downsample.0 [870, 61, 642, 435, 827, 696, 145, 580, 87, 730, 487, 594, 84, 518, 403, 39, 496, 617, 202, 874, 539, 692, 177, 79, 289, 687, 781, 109, 75, 444, 547, 335, 293, 862, 480, 340, 258, 839, 132, 53, 599, 427, 223, 67, 391, 74, 298, 381, 424, 382, 135, 13, 361, 110, 98, 451, 83, 755, 852, 527, 835, 711, 25, 57, 343, 197, 700, 523, 445, 616, 820, 542, 299, 643, 800, 479, 282, 830, 248, 628, 229, 295, 831, 436, 22, 368, 551, 230, 818, 460, 558, 242, 80, 900, 140, 729, 390, 252, 478, 808, 684, 297, 607, 281, 785, 627, 170, 21, 384, 590, 475, 430, 418, 847, 327]\n",
      "layer2.0.downsample.0 [295, 431, 22, 429, 58, 221, 271, 154, 417, 308, 311, 121, 249, 192, 334, 60, 127, 392, 118, 207, 443, 336, 111, 275, 213, 316, 274, 69, 170, 172, 35, 7, 331, 438, 195, 52, 427, 399, 199, 175, 92, 447, 391, 394, 25, 342, 412, 34, 61, 72, 256, 403, 155, 407, 93, 387, 314, 129]\n",
      "layer1.0.downsample.0 [174, 54, 130, 12, 105, 19, 68, 92, 17, 100, 24, 98, 192, 148, 182, 152, 50, 170, 123, 214, 28, 125, 218, 153, 181, 133, 29, 162, 7]\n",
      "conv1 [51, 43, 2, 26, 31, 27, 17]\n",
      "layer1.0.conv2 [11, 23, 39, 38, 29, 6, 14]\n",
      "layer1.0.conv1 [19, 21, 40, 18, 50, 37, 44]\n",
      "layer1.1.conv2 [9, 11, 35, 17, 49, 24, 40]\n",
      "layer1.1.conv1 [10, 36, 26, 12, 33, 35, 29]\n",
      "layer1.2.conv2 [43, 1, 24, 44, 29, 45, 2]\n",
      "layer1.2.conv1 [17, 49, 50, 46, 52, 2, 36]\n",
      "layer2.0.conv2 [91, 46, 9, 89, 100, 14, 21, 53, 18, 19, 112, 68, 56, 96]\n",
      "layer2.0.conv1 [49, 97, 107, 109, 4, 78, 90, 57, 106, 91, 100, 74, 50, 69]\n",
      "layer2.1.conv2 [108, 84, 75, 86, 100, 24, 89, 26, 55, 91, 82, 5, 69, 4]\n",
      "layer2.1.conv1 [94, 97, 51, 103, 39, 54, 24, 28, 101, 20, 89, 48, 62, 67]\n",
      "layer2.2.conv2 [43, 74, 89, 70, 78, 57, 37, 75, 84, 51, 19, 59, 49, 108]\n",
      "layer2.2.conv1 [109, 104, 97, 23, 68, 15, 21, 103, 9, 48, 12, 55, 95, 53]\n",
      "layer2.3.conv2 [86, 96, 82, 5, 95, 100, 92, 6, 98, 97, 36, 102, 60, 34]\n",
      "layer2.3.conv1 [93, 106, 102, 48, 37, 58, 2, 103, 55, 12, 91, 15, 62, 52]\n",
      "layer3.0.conv2 [188, 123, 214, 201, 225, 187, 11, 112, 196, 39, 63, 100, 105, 54, 89, 167, 76, 219, 85, 135, 148, 116, 222, 29, 92, 198, 103, 224, 35]\n",
      "layer3.0.conv1 [78, 184, 1, 159, 210, 71, 48, 134, 197, 209, 84, 93, 75, 29, 120, 43, 138, 112, 153, 77, 145, 170, 5, 74, 226, 225, 33, 26, 133]\n",
      "layer3.1.conv2 [49, 190, 211, 186, 75, 72, 195, 222, 143, 205, 180, 146, 165, 85, 32, 41, 201, 166, 89, 142, 113, 182, 14, 220, 39, 79, 99, 139, 6]\n",
      "layer3.1.conv1 [189, 220, 39, 79, 110, 41, 151, 167, 166, 160, 152, 61, 215, 69, 194, 117, 85, 52, 27, 11, 102, 177, 179, 145, 35, 170, 20, 137, 119]\n",
      "layer3.2.conv2 [3, 160, 10, 74, 15, 207, 217, 88, 202, 113, 27, 8, 62, 11, 61, 147, 40, 213, 34, 69, 93, 38, 57, 115, 133, 4, 148, 143, 154]\n",
      "layer3.2.conv1 [184, 167, 21, 7, 214, 141, 134, 125, 126, 136, 72, 164, 218, 45, 26, 209, 37, 208, 182, 178, 8, 127, 102, 152, 113, 203, 142, 116, 158]\n",
      "layer3.3.conv2 [76, 26, 134, 109, 162, 183, 205, 37, 193, 25, 177, 119, 180, 165, 51, 175, 160, 102, 148, 20, 41, 149, 14, 189, 17, 187, 195, 101, 81]\n",
      "layer3.3.conv1 [171, 142, 36, 123, 74, 110, 89, 188, 135, 56, 180, 190, 224, 39, 29, 71, 184, 151, 176, 66, 3, 202, 31, 181, 105, 63, 164, 99, 19]\n",
      "layer3.4.conv2 [50, 166, 132, 20, 197, 175, 185, 173, 206, 76, 48, 19, 88, 127, 78, 176, 214, 81, 14, 161, 177, 63, 192, 27, 107, 58, 32, 18, 124]\n",
      "layer3.4.conv1 [14, 40, 45, 168, 33, 213, 174, 101, 180, 181, 84, 197, 12, 87, 141, 159, 122, 171, 6, 80, 36, 32, 21, 15, 62, 125, 119, 144, 7]\n",
      "layer3.5.conv2 [44, 84, 215, 196, 103, 27, 74, 220, 145, 199, 125, 219, 73, 28, 114, 77, 185, 168, 81, 17, 14, 223, 148, 68, 97, 130, 172, 134, 38]\n",
      "layer3.5.conv1 [100, 148, 192, 17, 22, 157, 59, 31, 80, 68, 120, 211, 88, 177, 50, 6, 93, 118, 96, 65, 79, 2, 131, 23, 92, 171, 5, 41, 49]\n",
      "layer4.0.conv2 [166, 256, 191, 186, 442, 265, 280, 21, 47, 77, 398, 205, 368, 129, 98, 293, 35, 185, 179, 354, 426, 311, 24, 332, 114, 367, 71, 16, 420, 104, 57, 263, 249, 240, 58, 312, 171, 376, 375, 145, 92, 156, 429, 424, 150, 349, 281, 147, 428, 64, 160, 437, 202, 427, 399, 14, 65, 138]\n",
      "layer4.0.conv1 [188, 8, 371, 431, 250, 160, 399, 104, 360, 270, 210, 261, 451, 444, 365, 397, 205, 15, 361, 417, 143, 281, 169, 117, 385, 380, 1, 0, 21, 204, 215, 352, 212, 421, 108, 268, 246, 282, 175, 368, 115, 386, 161, 101, 424, 112, 165, 267, 231, 98, 319, 164, 35, 240, 418, 254, 173, 12]\n",
      "layer4.1.conv2 [56, 201, 116, 177, 186, 190, 191, 252, 195, 62, 196, 64, 65, 343, 67, 72, 334, 385, 383, 75, 240, 239, 77, 333, 346, 100, 379, 80, 105, 85, 235, 104, 87, 93, 360, 220, 221, 233, 356, 348, 176, 280, 230, 228, 157, 447, 271, 47, 165, 49, 119, 166, 52, 266, 174, 26, 297, 40]\n",
      "layer4.1.conv1 [112, 171, 172, 173, 324, 322, 320, 177, 352, 319, 179, 317, 344, 314, 147, 310, 148, 343, 341, 303, 302, 298, 295, 294, 292, 287, 286, 282, 277, 153, 276, 271, 270, 338, 268, 203, 155, 267, 38, 205, 40, 337, 265, 263, 44, 208, 157, 158, 254, 161, 331, 51, 52, 53, 54, 247, 283, 57]\n",
      "layer4.2.conv2 [330, 108, 59, 368, 334, 352, 133, 239, 235, 375, 343, 51, 374, 333, 366, 37, 401, 389, 6, 72, 158, 450, 306, 148, 138, 425, 84, 226, 303, 350, 205, 3, 317, 381, 194, 214, 316, 135, 26, 301, 250, 252, 344, 186, 251, 420, 411, 121, 359, 451, 43, 258, 86, 340, 198, 254, 407, 57]\n",
      "layer4.2.conv1 [298, 299, 302, 306, 307, 308, 309, 158, 159, 312, 315, 316, 163, 317, 319, 327, 328, 329, 169, 331, 171, 332, 333, 174, 334, 335, 338, 340, 341, 345, 181, 182, 183, 184, 349, 350, 187, 353, 189, 190, 391, 393, 396, 43, 194, 401, 404, 47, 197, 407, 50, 408, 200, 201, 410, 203, 227, 57]\n",
      "Pruning step: 2 multiply–accumulate (macs): 2486448119.0 number of parameters 15672450\n",
      "layer4.0.downsample.0 [1310, 1073, 445, 1244, 1128, 1507, 87, 719, 1382, 1442, 319, 1351, 568, 648, 1146, 103, 1117, 1192, 1054, 220, 703, 1019, 1376, 1478, 1355, 254, 757, 1460, 1462, 268, 1524, 426, 1162, 1307, 242, 955, 885, 1552, 1530, 524, 1028, 697, 417, 241, 352, 1090, 1091, 606, 394, 941, 440, 471, 159, 979, 1017, 1518, 666, 897, 1112, 1511, 448, 307, 98, 1439, 100, 298, 431, 1313, 866, 1315, 1383, 1423, 1001, 1064, 826, 616, 1263, 1582, 1153, 770, 1180, 624, 1459, 210, 1456, 1557, 399, 1111, 1384, 391, 1183, 475, 1399, 1528, 327, 1335, 506, 962, 939, 573, 1450, 244, 81, 950, 1246, 1426, 224, 536, 1445, 444, 172, 1300, 280, 854, 1297, 1400, 243, 94, 906, 44, 1303, 499, 987, 663, 38, 313, 1512, 534, 1466, 26, 1556, 682, 653, 153, 1075, 1015, 790, 1269, 1479, 251, 781, 743, 752, 387, 380, 1000, 604, 1389, 1199, 209, 1487, 1103, 1295, 404, 502, 1363, 1165, 215, 1281, 1275, 833, 14, 858, 932, 1182, 1436, 772, 1506, 645, 1567, 330, 1053, 56, 360, 1050, 120, 1102, 406, 1168, 1023, 1115, 1083, 141, 1365, 1126, 1577, 1352, 989, 742, 269, 2, 1571, 1509, 295, 466, 701, 1301, 482, 1048, 1218, 1413, 192, 457, 148, 150, 249, 1354, 112, 514, 716, 349, 1265, 1317, 806, 870, 231, 235, 874, 474, 1268, 1447, 1130, 505, 424, 1147, 910, 983, 555, 1104, 306, 698]\n",
      "layer3.0.downsample.0 [719, 18, 74, 43, 108, 736, 248, 773, 371, 591, 201, 452, 755, 254, 236, 106, 45, 463, 465, 78, 150, 36, 670, 137, 94, 256, 396, 468, 71, 82, 643, 692, 527, 710, 168, 119, 791, 157, 132, 238, 594, 397, 706, 271, 374, 166, 585, 700, 357, 276, 292, 298, 246, 450, 296, 750, 41, 679, 393, 583, 226, 176, 129, 624, 688, 472, 267, 684, 369, 112, 184, 552, 726, 331, 776, 323, 126, 561, 417, 287, 714, 183, 361, 771, 733, 199, 490, 127, 345, 116, 28, 761, 204, 745, 92, 320, 515, 441, 509, 446, 654, 457, 334, 359, 728, 19, 695, 456, 434, 686, 409, 577, 770, 489, 9]\n",
      "layer2.0.downsample.0 [309, 383, 264, 103, 53, 101, 151, 226, 330, 139, 201, 385, 320, 26, 11, 128, 325, 135, 174, 269, 306, 257, 382, 359, 214, 34, 296, 322, 312, 349, 388, 248, 335, 215, 369, 210, 69, 20, 87, 307, 367, 249, 224, 373, 118, 8, 19, 395, 68, 221, 244, 387, 294, 354, 202, 190, 162]\n",
      "layer1.0.downsample.0 [3, 174, 61, 190, 19, 158, 42, 82, 33, 45, 16, 4, 162, 87, 191, 176, 128, 41, 60, 52, 173, 142, 170, 141, 72, 27, 119, 192, 36]\n",
      "conv1 [24, 2, 45, 40, 9, 10, 4]\n",
      "layer1.0.conv2 [37, 10, 23, 30, 41, 25, 43]\n",
      "layer1.0.conv1 [38, 27, 36, 4, 16, 25, 21]\n",
      "layer1.1.conv2 [16, 1, 2, 35, 33, 0, 43]\n",
      "layer1.1.conv1 [31, 14, 41, 27, 35, 5, 45]\n",
      "layer1.2.conv2 [43, 32, 4, 47, 1, 15, 6]\n",
      "layer1.2.conv1 [48, 8, 43, 10, 1, 36, 38]\n",
      "layer2.0.conv2 [29, 9, 27, 91, 77, 55, 17, 63, 75, 8, 6, 20, 87, 16, 36]\n",
      "layer2.0.conv1 [87, 80, 40, 17, 79, 45, 1, 81, 78, 10, 91, 7, 9, 94, 19]\n",
      "layer2.1.conv2 [85, 35, 82, 92, 50, 6, 64, 69, 72, 10, 38, 94, 52, 87, 96]\n",
      "layer2.1.conv1 [23, 67, 89, 58, 10, 44, 13, 33, 11, 95, 32, 14, 75, 77, 74]\n",
      "layer2.2.conv2 [16, 19, 48, 30, 17, 41, 93, 84, 95, 37, 72, 42, 67, 92, 65]\n",
      "layer2.2.conv1 [2, 53, 66, 39, 62, 87, 35, 36, 76, 37, 52, 77, 72, 96, 18]\n",
      "layer2.3.conv2 [4, 35, 6, 46, 63, 56, 98, 29, 47, 26, 84, 78, 36, 33, 44]\n",
      "layer2.3.conv1 [31, 81, 0, 75, 74, 9, 76, 29, 19, 18, 51, 12, 22, 94, 13]\n",
      "layer3.0.conv2 [51, 194, 18, 79, 74, 48, 43, 130, 109, 141, 98, 76, 7, 46, 145, 85, 167, 100, 189, 90, 183, 49, 193, 88, 140, 61, 30, 122, 32]\n",
      "layer3.0.conv1 [1, 91, 193, 192, 84, 114, 162, 92, 133, 156, 56, 126, 28, 65, 74, 102, 174, 185, 130, 57, 139, 22, 119, 6, 165, 58, 7, 160, 181]\n",
      "layer3.1.conv2 [120, 42, 29, 18, 100, 174, 85, 111, 154, 137, 69, 168, 144, 41, 14, 39, 57, 169, 44, 104, 140, 147, 117, 181, 24, 79, 74, 83, 55]\n",
      "layer3.1.conv1 [190, 179, 182, 24, 176, 110, 4, 185, 130, 109, 167, 13, 31, 175, 186, 80, 29, 189, 119, 165, 125, 154, 17, 139, 34, 193, 84, 196, 62]\n",
      "layer3.2.conv2 [118, 117, 39, 109, 63, 76, 57, 11, 134, 191, 145, 27, 147, 83, 96, 2, 135, 195, 69, 51, 28, 85, 128, 12, 10, 103, 136, 192, 64]\n",
      "layer3.2.conv1 [0, 156, 102, 90, 138, 13, 41, 166, 20, 6, 158, 77, 76, 164, 114, 132, 25, 195, 15, 45, 21, 14, 80, 75, 145, 96, 134, 127, 26]\n",
      "layer3.3.conv2 [146, 137, 59, 40, 83, 9, 121, 112, 119, 193, 131, 86, 166, 98, 47, 123, 151, 168, 132, 31, 90, 155, 142, 37, 84, 54, 3, 140, 82]\n",
      "layer3.3.conv1 [8, 57, 155, 47, 135, 169, 158, 149, 13, 144, 108, 73, 157, 154, 19, 136, 11, 139, 17, 163, 85, 68, 106, 107, 40, 74, 151, 14, 131]\n",
      "layer3.4.conv2 [141, 38, 92, 98, 51, 88, 79, 48, 182, 189, 29, 170, 66, 144, 185, 70, 63, 15, 45, 140, 100, 103, 39, 194, 138, 188, 21, 190, 34]\n",
      "layer3.4.conv1 [147, 175, 7, 71, 156, 196, 48, 178, 145, 5, 53, 168, 195, 81, 191, 92, 20, 151, 23, 21, 31, 177, 58, 109, 152, 10, 87, 80, 74]\n",
      "layer3.5.conv2 [152, 107, 20, 134, 185, 45, 93, 51, 100, 41, 119, 162, 116, 50, 125, 42, 37, 145, 146, 120, 151, 62, 153, 85, 117, 148, 52, 137, 73]\n",
      "layer3.5.conv1 [155, 169, 78, 37, 172, 165, 5, 9, 26, 196, 64, 116, 133, 111, 121, 11, 66, 30, 146, 156, 10, 173, 112, 31, 91, 174, 20, 25, 114]\n",
      "layer4.0.conv2 [205, 29, 81, 162, 232, 267, 70, 25, 326, 141, 339, 298, 292, 260, 72, 240, 266, 59, 391, 129, 86, 307, 327, 36, 243, 1, 170, 84, 13, 179, 123, 160, 297, 211, 20, 370, 161, 253, 365, 247, 88, 204, 12, 124, 353, 153, 375, 223, 14, 274, 195, 230, 172, 38, 262, 246, 273]\n",
      "layer4.0.conv1 [36, 244, 9, 356, 270, 20, 118, 131, 173, 220, 259, 355, 298, 177, 180, 342, 277, 167, 137, 330, 320, 361, 80, 143, 334, 79, 4, 8, 5, 135, 364, 271, 69, 93, 339, 86, 98, 161, 19, 47, 368, 196, 229, 140, 224, 276, 70, 41, 285, 203, 24, 372, 309, 354, 254, 134, 206]\n",
      "layer4.1.conv2 [220, 45, 288, 160, 87, 207, 85, 11, 124, 27, 354, 312, 341, 364, 369, 145, 298, 271, 101, 129, 70, 245, 299, 391, 49, 187, 153, 282, 215, 131, 28, 308, 38, 367, 3, 19, 286, 175, 94, 261, 76, 142, 317, 378, 379, 12, 208, 267, 290, 365, 32, 221, 184, 164, 69, 230, 213]\n",
      "layer4.1.conv1 [88, 392, 391, 390, 309, 126, 113, 383, 276, 112, 369, 382, 381, 111, 379, 378, 375, 109, 76, 313, 122, 93, 368, 298, 362, 117, 106, 105, 101, 296, 99, 200, 201, 193, 202, 191, 115, 82, 207, 212, 331, 310, 330, 328, 213, 327, 326, 325, 218, 51, 152, 320, 55, 56, 57, 150, 222]\n",
      "layer4.2.conv2 [308, 255, 244, 81, 70, 178, 224, 372, 221, 152, 2, 297, 52, 252, 311, 331, 243, 202, 320, 186, 111, 245, 234, 283, 97, 225, 388, 218, 369, 120, 7, 116, 4, 179, 267, 266, 148, 156, 129, 61, 205, 128, 92, 261, 325, 254, 57, 346, 47, 200, 393, 192, 8, 140, 133, 12, 187]\n",
      "layer4.2.conv1 [232, 238, 240, 247, 183, 243, 245, 248, 200, 145, 187, 188, 189, 190, 191, 192, 142, 254, 140, 257, 203, 394, 112, 133, 225, 391, 129, 390, 389, 388, 386, 128, 210, 270, 383, 125, 272, 382, 381, 273, 122, 208, 377, 120, 118, 117, 116, 113, 207, 106, 395, 359, 357, 54, 55, 56, 57]\n",
      "Pruning step: 3 multiply–accumulate (macs): 1827763596.0 number of parameters 11655453\n",
      "layer4.0.downsample.0 [845, 512, 760, 131, 1204, 1146, 398, 1224, 882, 991, 767, 1068, 978, 675, 37, 832, 623, 618, 1223, 801, 7, 138, 54, 554, 1137, 465, 642, 253, 551, 820, 1020, 1098, 802, 658, 1042, 30, 1172, 74, 47, 407, 849, 1063, 773, 106, 16, 1194, 975, 270, 653, 27, 536, 1153, 1331, 1052, 286, 38, 862, 1003, 306, 824, 300, 1221, 1278, 242, 384, 1111, 909, 878, 1180, 970, 1140, 134, 1271, 1350, 45, 1272, 617, 647, 535, 29, 664, 684, 1134, 1023, 234, 474, 150, 1125, 1026, 559, 444, 749, 1262, 1281, 640, 853, 595, 702, 885, 976, 287, 730, 717, 570, 1079, 592, 364, 78, 481, 9, 922, 1259, 1334, 1047, 490, 197, 445, 311, 810, 833, 560, 745, 1337, 993, 530, 1252, 1346, 198, 1298, 1056, 479, 322, 1306, 1253, 972, 797, 297, 176, 586, 822, 553, 477, 375, 563, 1159, 928, 478, 547, 523, 488, 1332, 58, 911, 189, 284, 1270, 714, 1260, 432, 428, 852, 122, 899, 60, 35, 1353, 1127, 144, 1024, 1349, 790, 51, 800, 296, 224, 507, 843, 1038, 1073, 98, 984, 199, 36, 609, 1275, 548, 379, 912, 260, 1130, 443, 315, 1295, 789, 274, 574, 979, 1225, 10, 1027, 1316, 332, 1254, 895, 961, 343, 416, 1263, 997, 636, 485, 527, 509, 655, 160, 823, 1300, 464, 42, 954, 267, 780, 1274, 1216, 705, 1070, 983, 1050, 1232, 501]\n",
      "layer3.0.downsample.0 [62, 178, 647, 53, 96, 608, 588, 466, 312, 374, 657, 8, 358, 536, 552, 540, 469, 411, 559, 216, 545, 15, 192, 127, 491, 204, 360, 291, 34, 589, 343, 581, 361, 385, 124, 475, 521, 389, 445, 390, 398, 25, 543, 148, 146, 470, 619, 252, 119, 57, 37, 74, 329, 153, 575, 624, 150, 42, 110, 655, 498, 66, 277, 580, 172, 427, 459, 547, 202, 397, 465, 210, 665, 28, 259, 136, 19, 654, 118, 230, 533, 354, 464, 367, 557, 440, 579, 52, 310, 639, 163, 267, 562, 620, 116, 317, 260, 24, 307, 664, 162, 509, 191, 21, 425, 244, 485, 642, 120, 403, 605, 524, 16, 156, 457]\n",
      "layer2.0.downsample.0 [193, 28, 2, 49, 29, 260, 69, 67, 292, 133, 132, 81, 114, 217, 297, 189, 64, 266, 152, 259, 83, 155, 183, 131, 36, 209, 278, 285, 130, 148, 244, 242, 27, 165, 167, 177, 243, 150, 229, 214, 149, 87, 295, 9, 70, 139, 191, 321, 272, 5, 170, 108, 72, 142, 65, 245, 234, 301]\n",
      "layer1.0.downsample.0 [158, 148, 40, 14, 155, 39, 104, 121, 42, 152, 105, 55, 97, 57, 21, 29, 149, 58, 13, 20, 115, 8, 16, 163, 139, 78, 166, 89, 70]\n",
      "conv1 [32, 23, 19, 16, 24, 37, 0]\n",
      "layer1.0.conv2 [31, 20, 10, 18, 29, 25, 40]\n",
      "layer1.0.conv1 [7, 40, 37, 24, 1, 23, 25]\n",
      "layer1.1.conv2 [33, 40, 12, 26, 3, 9, 41]\n",
      "layer1.1.conv1 [14, 8, 27, 7, 34, 9, 17]\n",
      "layer1.2.conv2 [40, 39, 0, 27, 1, 19, 12]\n",
      "layer1.2.conv1 [16, 24, 40, 13, 38, 27, 29]\n",
      "layer2.0.conv2 [22, 59, 69, 63, 13, 48, 9, 10, 71, 55, 15, 54, 8, 81]\n",
      "layer2.0.conv1 [81, 39, 61, 60, 71, 7, 38, 40, 31, 67, 79, 41, 57, 37]\n",
      "layer2.1.conv2 [5, 8, 36, 1, 49, 69, 40, 56, 43, 39, 62, 81, 48, 76]\n",
      "layer2.1.conv1 [9, 36, 41, 2, 78, 77, 64, 83, 14, 51, 22, 62, 75, 12]\n",
      "layer2.2.conv2 [14, 72, 27, 74, 4, 53, 73, 58, 16, 17, 12, 76, 40, 35]\n",
      "layer2.2.conv1 [78, 61, 27, 28, 65, 45, 81, 20, 40, 24, 55, 72, 36, 12]\n",
      "layer2.3.conv2 [32, 26, 0, 81, 77, 14, 73, 54, 19, 53, 30, 1, 57, 28]\n",
      "layer2.3.conv1 [12, 2, 14, 26, 28, 5, 27, 42, 16, 60, 0, 17, 41, 74]\n",
      "layer3.0.conv2 [41, 122, 6, 99, 164, 93, 111, 130, 72, 49, 139, 30, 19, 76, 136, 70, 61, 98, 133, 142, 52, 129, 128, 109, 140, 78, 60, 22, 160]\n",
      "layer3.0.conv1 [167, 110, 88, 86, 22, 65, 37, 161, 99, 95, 163, 82, 128, 47, 4, 61, 54, 56, 60, 41, 136, 105, 103, 93, 101, 108, 168, 97, 32]\n",
      "layer3.1.conv2 [82, 88, 32, 98, 103, 28, 9, 127, 160, 56, 22, 70, 94, 80, 132, 65, 62, 122, 142, 99, 109, 89, 85, 129, 12, 84, 30, 63, 116]\n",
      "layer3.1.conv1 [109, 62, 134, 90, 115, 30, 157, 80, 152, 68, 69, 148, 111, 41, 151, 147, 25, 102, 20, 124, 17, 5, 112, 31, 129, 22, 145, 110, 132]\n",
      "layer3.2.conv2 [64, 151, 53, 66, 128, 73, 56, 153, 117, 163, 33, 91, 46, 147, 54, 59, 141, 98, 16, 108, 62, 168, 10, 78, 75, 120, 19, 8, 30]\n",
      "layer3.2.conv1 [42, 155, 64, 11, 71, 97, 104, 168, 49, 3, 101, 103, 24, 5, 148, 89, 62, 73, 113, 75, 44, 4, 111, 121, 130, 27, 14, 147, 56]\n",
      "layer3.3.conv2 [51, 124, 50, 49, 92, 144, 115, 95, 11, 97, 139, 72, 87, 12, 136, 88, 104, 3, 54, 111, 137, 29, 70, 6, 20, 134, 43, 123, 113]\n",
      "layer3.3.conv1 [2, 83, 55, 54, 48, 38, 118, 70, 155, 1, 108, 165, 44, 151, 111, 163, 104, 89, 101, 20, 138, 34, 114, 28, 125, 6, 56, 46, 124]\n",
      "layer3.4.conv2 [126, 35, 43, 104, 146, 12, 46, 29, 52, 86, 111, 87, 108, 8, 122, 107, 30, 106, 9, 96, 132, 139, 72, 75, 22, 55, 141, 81, 163]\n",
      "layer3.4.conv1 [145, 117, 137, 159, 20, 111, 121, 52, 114, 96, 79, 17, 84, 166, 92, 61, 119, 53, 131, 132, 93, 64, 101, 7, 71, 4, 143, 3, 156]\n",
      "layer3.5.conv2 [149, 24, 77, 117, 49, 23, 4, 31, 2, 134, 74, 131, 70, 91, 48, 125, 10, 3, 121, 9, 166, 78, 62, 109, 30, 135, 69, 146, 55]\n",
      "layer3.5.conv1 [117, 29, 157, 89, 163, 16, 148, 162, 132, 23, 2, 149, 43, 138, 92, 49, 6, 14, 111, 5, 48, 65, 95, 98, 82, 165, 135, 59, 53]\n",
      "layer4.0.conv2 [169, 141, 276, 135, 207, 30, 162, 126, 35, 279, 273, 50, 102, 328, 161, 133, 228, 244, 329, 283, 25, 105, 43, 277, 74, 226, 235, 212, 137, 31, 41, 318, 338, 9, 155, 289, 116, 37, 240, 303, 333, 94, 27, 191, 158, 192, 196, 331, 86, 320, 129, 172, 230, 140, 224, 218, 280, 180]\n",
      "layer4.0.conv1 [88, 103, 262, 102, 264, 79, 36, 28, 248, 81, 229, 214, 287, 153, 327, 167, 279, 53, 256, 75, 283, 158, 26, 117, 270, 299, 122, 305, 132, 234, 138, 307, 295, 273, 192, 334, 202, 271, 278, 319, 335, 124, 123, 326, 141, 205, 18, 301, 2, 260, 98, 259, 110, 223, 78, 240, 197, 61]\n",
      "layer4.1.conv2 [37, 86, 6, 276, 200, 231, 180, 108, 119, 158, 187, 87, 165, 332, 201, 232, 175, 188, 80, 305, 141, 54, 40, 282, 239, 292, 228, 8, 131, 20, 75, 115, 146, 202, 135, 171, 12, 26, 96, 103, 163, 110, 306, 253, 147, 279, 178, 214, 184, 45, 129, 273, 130, 179, 125, 208, 104, 102]\n",
      "layer4.1.conv1 [108, 63, 243, 127, 114, 107, 111, 61, 66, 278, 60, 280, 84, 71, 178, 284, 36, 103, 79, 285, 44, 269, 58, 236, 8, 185, 129, 246, 158, 191, 329, 198, 138, 97, 59, 39, 174, 247, 73, 338, 291, 82, 17, 293, 215, 45, 67, 87, 332, 54, 23, 125, 123, 337, 21, 299, 83, 336]\n",
      "layer4.2.conv2 [239, 163, 89, 22, 54, 205, 236, 73, 19, 26, 40, 330, 243, 288, 24, 65, 214, 111, 310, 93, 147, 76, 58, 33, 167, 49, 4, 227, 115, 277, 127, 230, 61, 146, 98, 181, 37, 64, 202, 270, 173, 245, 263, 31, 266, 208, 109, 198, 90, 186, 178, 313, 229, 242, 329, 21, 174, 168]\n",
      "layer4.2.conv1 [82, 76, 77, 65, 78, 64, 79, 63, 81, 91, 83, 62, 85, 61, 87, 60, 89, 90, 75, 73, 93, 300, 309, 99, 100, 195, 194, 197, 68, 71, 115, 315, 295, 41, 177, 334, 288, 105, 181, 55, 201, 328, 259, 280, 287, 172, 167, 108, 3, 5, 94, 317, 191, 26, 66, 39, 312, 45]\n",
      "Pruning step: 4 multiply–accumulate (macs): 1274471478.0 number of parameters 8217318\n",
      "layer4.0.downsample.0 [610, 341, 55, 623, 40, 777, 70, 4, 49, 161, 37, 327, 890, 819, 1111, 254, 287, 975, 962, 552, 778, 1047, 1017, 239, 663, 468, 874, 894, 38, 417, 165, 75, 978, 518, 753, 1036, 285, 1103, 219, 581, 176, 867, 479, 700, 56, 620, 384, 283, 776, 779, 708, 771, 64, 1062, 1061, 625, 985, 923, 375, 585, 198, 1037, 1123, 328, 677, 12, 636, 284, 713, 282, 457, 301, 666, 225, 184, 539, 823, 607, 911, 480, 92, 1087, 872, 1022, 313, 589, 459, 670, 976, 712, 306, 787, 412, 959, 953, 939, 799, 992, 425, 132, 180, 88, 187, 858, 170, 233, 789, 983, 359, 458, 121, 440, 1102, 971, 372, 146, 901, 717, 945, 774, 649, 451, 160, 986, 571, 201, 606, 1110, 735, 196, 522, 260, 1119, 1080, 532, 182, 326, 845, 667, 419, 658, 619, 193, 452, 528, 560, 800, 273, 163, 31, 629, 365, 1031, 766, 843, 3, 557, 1012, 952, 389, 885, 1069, 93, 443, 736, 410, 917, 691, 699, 262, 1049, 298, 772, 34, 300, 1082, 926, 593, 997, 102, 934, 936, 887, 577, 1043, 681, 347, 81, 516, 226, 659, 547, 185, 695, 635, 654, 830, 397, 1120, 143, 51, 1014, 430, 804, 286, 299, 969, 628, 178, 241, 441, 748, 762, 317, 103, 270, 806, 115, 829, 764, 562, 575, 1041, 53, 471, 83, 716, 448, 881, 294]\n",
      "layer3.0.downsample.0 [399, 285, 257, 184, 539, 417, 507, 300, 186, 283, 138, 130, 502, 244, 5, 84, 23, 15, 445, 142, 424, 61, 352, 546, 296, 176, 512, 14, 485, 523, 234, 530, 175, 505, 118, 212, 246, 163, 121, 477, 41, 541, 470, 81, 324, 117, 386, 442, 559, 128, 538, 289, 440, 425, 205, 169, 164, 302, 227, 273, 225, 556, 456, 308, 168, 420, 74, 500, 492, 410, 143, 179, 331, 166, 436, 276, 156, 326, 310, 521, 346, 160, 146, 243, 134, 531, 298, 219, 213, 415, 202, 67, 402, 260, 497, 275, 127, 261, 438, 209, 161, 295, 4, 360, 325, 113, 60, 95, 305, 433, 89, 68, 19, 114, 446]\n",
      "layer2.0.downsample.0 [77, 66, 240, 84, 65, 213, 26, 214, 102, 257, 174, 237, 231, 61, 189, 223, 88, 129, 41, 75, 155, 181, 211, 31, 53, 142, 131, 57, 2, 139, 1, 277, 233, 263, 23, 161, 143, 140, 168, 156, 193, 246, 138, 127, 39, 100, 38, 91, 205, 272, 70, 194, 98, 220, 206, 96, 170]\n",
      "layer1.0.downsample.0 [53, 90, 99, 17, 97, 120, 52, 44, 16, 22, 72, 19, 18, 73, 81, 119, 59, 67, 43, 31, 21, 122, 28, 0, 132, 115, 93, 6]\n",
      "conv1 [21, 2, 19, 20, 30, 16, 5]\n",
      "layer1.0.conv2 [17, 1, 2, 31, 25, 6, 32]\n",
      "layer1.0.conv1 [14, 19, 31, 33, 17, 29, 25]\n",
      "layer1.1.conv2 [6, 0, 24, 20, 5, 30, 1]\n",
      "layer1.1.conv1 [16, 1, 3, 15, 9, 12, 30]\n",
      "layer1.2.conv2 [24, 34, 5, 27, 2, 29, 6]\n",
      "layer1.2.conv1 [0, 2, 20, 29, 1, 10, 26]\n",
      "layer2.0.conv2 [11, 49, 66, 47, 5, 67, 1, 10, 9, 59, 23, 21, 43, 12]\n",
      "layer2.0.conv1 [58, 61, 53, 30, 39, 40, 8, 36, 55, 10, 25, 35, 38, 46]\n",
      "layer2.1.conv2 [4, 67, 58, 40, 35, 51, 22, 65, 41, 0, 69, 19, 54, 64]\n",
      "layer2.1.conv1 [65, 33, 13, 11, 4, 18, 3, 16, 51, 27, 67, 36, 62, 14]\n",
      "layer2.2.conv2 [41, 36, 18, 35, 38, 0, 23, 15, 46, 1, 32, 43, 64, 4]\n",
      "layer2.2.conv1 [68, 65, 49, 51, 25, 1, 23, 54, 64, 31, 34, 19, 44, 47]\n",
      "layer2.3.conv2 [23, 7, 56, 10, 16, 62, 34, 36, 8, 52, 38, 13, 21, 68]\n",
      "layer2.3.conv1 [26, 48, 44, 23, 55, 21, 30, 59, 16, 28, 31, 0, 10, 57]\n",
      "layer3.0.conv2 [19, 15, 124, 109, 64, 67, 49, 26, 91, 1, 55, 115, 113, 52, 88, 2, 102, 56, 110, 135, 87, 139, 9, 82, 79, 78, 38, 57]\n",
      "layer3.0.conv1 [60, 33, 133, 103, 68, 23, 121, 131, 89, 75, 122, 88, 90, 112, 66, 109, 7, 87, 20, 38, 137, 58, 73, 42, 47, 22, 0, 128]\n",
      "layer3.1.conv2 [79, 120, 31, 38, 108, 112, 58, 14, 4, 11, 22, 93, 61, 32, 63, 69, 39, 128, 110, 119, 15, 67, 127, 135, 0, 41, 88, 109]\n",
      "layer3.1.conv1 [17, 61, 71, 72, 6, 134, 129, 40, 80, 8, 111, 128, 114, 127, 0, 52, 113, 60, 101, 24, 130, 124, 73, 12, 55, 10, 28, 78]\n",
      "layer3.2.conv2 [4, 50, 91, 8, 79, 119, 25, 10, 94, 28, 81, 106, 134, 6, 129, 70, 13, 84, 51, 114, 14, 88, 128, 124, 87, 99, 61, 62]\n",
      "layer3.2.conv1 [8, 87, 79, 97, 131, 136, 38, 57, 18, 83, 135, 109, 105, 58, 33, 0, 110, 130, 82, 112, 10, 71, 125, 98, 41, 106, 7, 113]\n",
      "layer3.3.conv2 [13, 134, 96, 30, 129, 24, 22, 23, 59, 27, 60, 71, 97, 19, 50, 37, 31, 75, 118, 138, 117, 42, 40, 45, 109, 120, 33, 107]\n",
      "layer3.3.conv1 [133, 49, 108, 65, 42, 2, 71, 8, 135, 101, 122, 96, 98, 27, 13, 55, 83, 81, 22, 61, 90, 14, 46, 41, 107, 24, 53, 5]\n",
      "layer3.4.conv2 [34, 8, 93, 26, 36, 38, 100, 71, 127, 16, 106, 84, 41, 111, 17, 6, 5, 120, 9, 113, 19, 122, 92, 119, 88, 87, 4, 64]\n",
      "layer3.4.conv1 [80, 71, 83, 69, 59, 32, 93, 136, 42, 81, 79, 110, 74, 55, 101, 33, 58, 119, 67, 29, 82, 128, 131, 91, 76, 7, 126, 129]\n",
      "layer3.5.conv2 [59, 130, 4, 48, 101, 70, 93, 28, 57, 55, 3, 76, 23, 86, 77, 83, 73, 22, 85, 82, 1, 71, 98, 32, 15, 105, 65, 115]\n",
      "layer3.5.conv1 [107, 58, 51, 5, 106, 99, 125, 114, 0, 98, 101, 103, 129, 137, 63, 30, 80, 113, 14, 71, 135, 122, 110, 67, 50, 94, 16, 82]\n",
      "layer4.0.conv2 [262, 44, 4, 171, 240, 203, 20, 181, 112, 210, 277, 134, 237, 232, 66, 9, 107, 166, 192, 198, 152, 208, 254, 151, 87, 93, 53, 22, 131, 106, 113, 8, 247, 23, 120, 172, 148, 103, 6, 30, 155, 95, 242, 124, 70, 38, 180, 61, 98, 73, 222, 224, 31, 226, 209, 245, 266]\n",
      "layer4.0.conv1 [33, 220, 247, 109, 19, 199, 248, 147, 185, 105, 17, 240, 230, 197, 208, 270, 112, 44, 267, 145, 95, 24, 273, 167, 14, 152, 121, 122, 207, 154, 254, 41, 9, 175, 192, 210, 21, 217, 13, 194, 114, 5, 180, 22, 176, 37, 89, 190, 115, 225, 4, 58, 119, 242, 256, 87, 237]\n",
      "layer4.1.conv2 [92, 193, 129, 199, 87, 262, 264, 115, 153, 143, 195, 122, 272, 127, 11, 2, 237, 15, 54, 165, 250, 105, 70, 198, 154, 216, 194, 57, 209, 242, 109, 205, 50, 271, 0, 66, 170, 119, 249, 149, 113, 257, 110, 5, 111, 58, 243, 235, 73, 40, 187, 183, 51, 268, 228, 184, 74]\n",
      "layer4.1.conv1 [154, 62, 27, 165, 92, 269, 205, 212, 225, 117, 137, 187, 232, 235, 108, 181, 208, 121, 28, 46, 155, 112, 35, 279, 230, 96, 260, 141, 194, 82, 196, 233, 145, 183, 48, 113, 237, 210, 256, 167, 193, 77, 106, 188, 254, 131, 9, 66, 58, 178, 240, 90, 228, 135, 273, 171, 49]\n",
      "layer4.2.conv2 [199, 115, 30, 48, 84, 119, 11, 49, 50, 210, 160, 85, 162, 169, 88, 171, 67, 43, 265, 83, 117, 178, 140, 39, 215, 249, 232, 275, 224, 220, 280, 234, 137, 71, 174, 36, 17, 22, 23, 211, 207, 126, 241, 64, 182, 92, 105, 191, 5, 263, 193, 172, 186, 103, 153, 167, 201]\n",
      "layer4.2.conv1 [147, 226, 144, 273, 159, 59, 136, 127, 40, 243, 131, 166, 280, 197, 213, 236, 180, 101, 130, 99, 21, 148, 100, 276, 160, 188, 196, 4, 32, 183, 177, 172, 189, 28, 215, 187, 271, 123, 231, 66, 141, 17, 207, 145, 42, 121, 84, 41, 98, 134, 211, 48, 47, 96, 70, 75, 95]\n",
      "Pruning step: 5 multiply–accumulate (macs): 826566600.0 number of parameters 5411972\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 28, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(28, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(28, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(28, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(112, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(28, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(112, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(28, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(28, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(112, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(112, 224, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(224, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(224, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(224, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(56, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(224, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(224, 448, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(448, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(448, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(448, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(448, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(448, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(448, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(224, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(448, 896, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(896, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(224, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(896, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(224, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=896, out_features=1000, bias=True)\n",
      ")\n",
      "Pruning sparsity: 0.625\n",
      "layer4.0.downsample.0 [143, 1530, 663, 854, 1051, 1925, 311, 1501, 1158, 899, 1253, 80, 1748, 1292, 1201, 1492, 275, 327, 1694, 605, 100, 1427, 167, 437, 93, 338, 108, 112, 570, 351, 1542, 1592, 1154, 1193, 991, 751, 1736, 416, 653, 301, 1344, 1906, 745, 839, 1743, 1477, 1144, 1568, 1595, 1578, 16, 218, 478, 968, 1262, 1880, 560, 1980, 2046, 2040, 660, 1819, 1326, 456, 675, 1077, 728, 1349, 1999, 583, 1888, 1843, 1510, 847, 1156, 898, 619, 1974, 241, 468, 695, 1428, 1726, 1619, 1055, 1444, 204, 1702, 307, 153, 1941, 382, 1257, 195, 950, 1236, 1221, 1056, 1600, 1371, 955, 305, 1406, 929, 975, 1460, 2020, 296, 194, 1958, 558, 144, 1496, 623, 449, 808, 700, 1929, 1093, 1375, 1770, 861, 207, 706, 1099, 794, 362, 801, 622, 1794, 447, 1126, 66, 1087, 474, 617, 1120, 427, 1817, 1192, 1357, 1067, 1693, 1211, 119, 610, 939, 32, 1608, 734, 1393, 1286, 964, 472, 77, 1898, 2042, 1820, 1411, 687, 1249, 1760, 685, 1920, 128, 1944, 771, 140, 83, 691, 7, 54, 1437, 273, 1184, 1676, 453, 1334, 448, 220, 293, 1692, 96, 500, 1889, 526, 910, 1680, 1167, 754, 1203, 895, 863, 1046, 121, 300, 1036, 258, 1301, 1967, 107, 479, 461, 1757, 1187, 1685, 1166, 1930, 247, 803, 683, 1879, 1658, 1769, 302, 1006, 353, 709, 279, 1953, 937, 73, 1554, 122, 244, 1172, 1032, 1683, 1952, 1803, 1435, 1711, 769, 843, 420, 1699, 1223, 592, 1050, 712, 1106, 1314, 357, 278, 285, 1659, 290, 1637, 649, 666, 1646, 1864, 694, 819, 1105, 1430]\n",
      "layer3.0.downsample.0 [962, 853, 1018, 412, 1023, 486, 197, 491, 170, 501, 544, 657, 91, 18, 644, 96, 980, 803, 595, 906, 303, 45, 500, 729, 51, 38, 685, 609, 778, 923, 60, 728, 759, 1011, 444, 927, 966, 123, 388, 1017, 536, 194, 744, 928, 590, 487, 514, 709, 419, 390, 741, 873, 310, 325, 83, 747, 352, 656, 767, 92, 151, 468, 478, 589, 647, 766, 732, 407, 716, 311, 16, 701, 662, 748, 99, 511, 494, 329, 620, 149, 118, 340, 417, 475, 972, 836, 825, 105, 772, 371, 800, 331, 127, 365, 619, 205, 541, 132, 576, 553, 801, 933, 556, 817, 297, 881, 192, 985, 202, 665, 93, 543, 610, 683, 909, 21, 1022, 467, 936, 863, 534, 100, 706, 482, 886, 37, 228, 776]\n",
      "layer2.0.downsample.0 [387, 412, 243, 176, 246, 347, 404, 100, 163, 11, 34, 114, 24, 53, 66, 43, 424, 98, 363, 96, 371, 0, 149, 311, 166, 207, 85, 65, 188, 326, 60, 438, 353, 495, 509, 192, 372, 133, 339, 58, 269, 361, 442, 345, 379, 401, 33, 81, 309, 72, 307, 487, 10, 411, 285, 139, 465, 473, 177, 238, 381, 382, 131, 415]\n",
      "layer1.0.downsample.0 [144, 108, 150, 214, 77, 112, 103, 58, 131, 29, 233, 156, 92, 235, 0, 31, 225, 63, 36, 231, 245, 69, 196, 135, 78, 168, 97, 10, 68, 26, 218, 21]\n",
      "conv1 [13, 44, 42, 57, 52, 31, 11, 59]\n",
      "layer1.0.conv2 [0, 1, 44, 19, 22, 61, 9, 60]\n",
      "layer1.0.conv1 [38, 1, 48, 7, 46, 45, 42, 35]\n",
      "layer1.1.conv2 [38, 6, 25, 41, 45, 17, 44, 30]\n",
      "layer1.1.conv1 [56, 45, 2, 43, 4, 19, 41, 38]\n",
      "layer1.2.conv2 [11, 7, 57, 4, 51, 39, 48, 21]\n",
      "layer1.2.conv1 [2, 39, 49, 45, 63, 52, 11, 57]\n",
      "layer2.0.conv2 [35, 29, 4, 119, 90, 51, 69, 111, 54, 3, 53, 12, 115, 99, 38, 120]\n",
      "layer2.0.conv1 [92, 112, 89, 63, 104, 8, 68, 66, 61, 62, 14, 12, 77, 2, 121, 122]\n",
      "layer2.1.conv2 [9, 109, 121, 93, 120, 10, 29, 54, 46, 100, 96, 126, 77, 30, 38, 94]\n",
      "layer2.1.conv1 [5, 1, 111, 3, 29, 83, 59, 79, 102, 76, 112, 118, 69, 58, 14, 63]\n",
      "layer2.2.conv2 [56, 29, 18, 34, 75, 101, 39, 12, 90, 32, 96, 43, 22, 2, 86, 60]\n",
      "layer2.2.conv1 [63, 112, 75, 38, 120, 117, 102, 6, 12, 88, 76, 40, 105, 123, 124, 49]\n",
      "layer2.3.conv2 [124, 127, 36, 17, 0, 76, 113, 105, 37, 111, 106, 6, 67, 110, 77, 8]\n",
      "layer2.3.conv1 [9, 74, 6, 114, 79, 120, 52, 49, 23, 37, 30, 33, 4, 2, 103, 58]\n",
      "layer3.0.conv2 [2, 207, 4, 248, 54, 250, 106, 141, 13, 115, 157, 133, 194, 116, 151, 152, 247, 35, 160, 82, 221, 44, 150, 254, 222, 232, 219, 43, 192, 127, 199, 60]\n",
      "layer3.0.conv1 [4, 89, 139, 220, 136, 245, 48, 110, 148, 18, 103, 90, 196, 236, 44, 1, 160, 86, 244, 152, 225, 135, 92, 55, 254, 194, 212, 238, 118, 207, 126, 29]\n",
      "layer3.1.conv2 [7, 72, 221, 108, 191, 111, 155, 88, 8, 9, 254, 42, 146, 133, 132, 130, 56, 100, 123, 74, 127, 250, 209, 23, 24, 246, 235, 229, 82, 96, 228, 16]\n",
      "layer3.1.conv1 [32, 43, 225, 222, 73, 172, 75, 76, 77, 221, 165, 11, 50, 13, 85, 88, 162, 54, 217, 19, 216, 194, 92, 95, 97, 103, 188, 152, 187, 149, 144, 65]\n",
      "layer3.2.conv2 [35, 196, 117, 79, 149, 108, 157, 131, 14, 17, 43, 30, 99, 156, 112, 87, 47, 186, 233, 73, 234, 56, 190, 250, 240, 37, 182, 29, 166, 228, 122, 169]\n",
      "layer3.2.conv1 [153, 1, 167, 105, 51, 23, 47, 155, 20, 56, 164, 134, 242, 29, 30, 148, 97, 99, 100, 243, 216, 212, 192, 181, 59, 182, 196, 127, 8, 7, 119, 161]\n",
      "layer3.3.conv2 [247, 190, 35, 148, 37, 127, 34, 131, 82, 161, 157, 255, 218, 146, 100, 38, 236, 183, 217, 169, 221, 197, 112, 119, 186, 124, 150, 204, 14, 187, 171, 231]\n",
      "layer3.3.conv1 [240, 79, 254, 180, 181, 58, 100, 195, 9, 41, 40, 59, 211, 214, 31, 217, 124, 219, 24, 128, 189, 144, 227, 71, 99, 213, 236, 252, 207, 75, 199, 19]\n",
      "layer3.4.conv2 [126, 105, 50, 144, 53, 150, 169, 244, 242, 252, 19, 41, 116, 165, 38, 186, 42, 35, 79, 207, 18, 212, 210, 164, 20, 179, 202, 21, 174, 222, 198, 213]\n",
      "layer3.4.conv1 [6, 73, 110, 190, 164, 111, 8, 99, 10, 87, 55, 100, 122, 19, 204, 26, 242, 108, 48, 240, 165, 45, 20, 43, 227, 60, 121, 192, 104, 1, 71, 193]\n",
      "layer3.5.conv2 [221, 91, 143, 219, 186, 203, 183, 59, 38, 77, 94, 105, 142, 127, 215, 52, 239, 8, 82, 137, 135, 141, 206, 249, 208, 81, 45, 222, 114, 0, 30, 223]\n",
      "layer3.5.conv1 [10, 3, 246, 5, 81, 203, 70, 29, 200, 16, 114, 112, 251, 250, 204, 190, 220, 249, 74, 105, 236, 133, 126, 1, 84, 205, 166, 95, 199, 153, 132, 33]\n",
      "layer4.0.conv2 [492, 171, 290, 65, 61, 461, 84, 386, 421, 244, 326, 178, 103, 236, 388, 284, 160, 383, 272, 142, 143, 144, 46, 381, 48, 111, 371, 365, 238, 78, 268, 269, 253, 419, 80, 188, 163, 35, 12, 405, 409, 267, 60, 375, 231, 216, 303, 50, 354, 130, 400, 454, 499, 22, 91, 453, 126, 294, 335, 452, 483, 259, 401, 285]\n",
      "layer4.0.conv1 [34, 467, 55, 309, 53, 426, 487, 230, 132, 447, 10, 510, 268, 314, 143, 15, 16, 406, 227, 124, 394, 436, 457, 383, 312, 471, 12, 225, 431, 298, 328, 229, 336, 18, 189, 203, 8, 220, 488, 316, 231, 338, 112, 219, 326, 304, 254, 500, 433, 284, 410, 191, 508, 253, 114, 24, 252, 485, 100, 464, 182, 351, 349, 429]\n",
      "layer4.1.conv2 [128, 327, 2, 329, 377, 497, 493, 118, 8, 119, 376, 163, 122, 375, 368, 480, 131, 369, 18, 162, 370, 167, 475, 170, 331, 469, 172, 333, 177, 465, 30, 178, 179, 183, 313, 35, 36, 155, 185, 217, 40, 347, 308, 459, 256, 153, 46, 194, 48, 454, 348, 51, 448, 350, 54, 351, 442, 57, 58, 148, 60, 299, 439, 63]\n",
      "layer4.1.conv1 [64, 418, 182, 416, 184, 414, 186, 7, 412, 9, 10, 409, 189, 406, 394, 320, 193, 17, 194, 392, 390, 382, 22, 198, 381, 25, 200, 379, 202, 29, 30, 31, 203, 204, 376, 35, 375, 207, 369, 368, 210, 41, 211, 365, 44, 45, 46, 47, 48, 213, 364, 51, 215, 362, 54, 217, 56, 357, 58, 351, 60, 220, 348, 222]\n",
      "layer4.2.conv2 [0, 336, 333, 337, 368, 201, 80, 178, 8, 9, 331, 11, 12, 367, 362, 84, 277, 328, 183, 87, 359, 270, 187, 266, 294, 92, 26, 309, 213, 308, 188, 307, 32, 33, 353, 348, 96, 37, 256, 219, 347, 302, 99, 105, 508, 295, 507, 47, 502, 494, 478, 469, 464, 125, 54, 440, 431, 425, 419, 138, 417, 403, 62, 150]\n",
      "layer4.2.conv1 [64, 208, 278, 277, 211, 276, 6, 7, 213, 214, 274, 273, 379, 272, 14, 15, 16, 221, 18, 19, 376, 375, 269, 224, 24, 225, 26, 370, 367, 29, 227, 366, 364, 229, 34, 230, 233, 234, 235, 361, 360, 236, 237, 444, 249, 357, 258, 355, 48, 49, 50, 251, 354, 353, 252, 257, 254, 255, 350, 59, 394, 61, 396, 407]\n",
      "Pruning step: 1 multiply–accumulate (macs): 3172561832.0 number of parameters 19798176\n",
      "layer4.0.downsample.0 [1557, 1400, 926, 1631, 998, 1697, 356, 1136, 651, 1192, 57, 1573, 340, 676, 1102, 722, 368, 45, 627, 1743, 1172, 1364, 509, 1254, 1598, 1126, 491, 589, 1260, 197, 1146, 461, 1628, 795, 920, 1119, 271, 1337, 1035, 446, 282, 897, 1056, 1259, 258, 1082, 1582, 503, 392, 416, 1635, 1618, 1358, 1636, 596, 205, 1576, 186, 623, 262, 1245, 1689, 1656, 1162, 1397, 1742, 1421, 1440, 1402, 1664, 71, 1713, 410, 999, 1164, 1609, 48, 751, 857, 1063, 1323, 37, 1533, 1506, 2, 1275, 1085, 622, 505, 1434, 770, 883, 1751, 684, 1479, 537, 1555, 1150, 248, 1701, 1536, 427, 1500, 10, 126, 1370, 1252, 83, 489, 9, 979, 106, 1601, 135, 1629, 238, 1044, 1488, 790, 1377, 750, 405, 1648, 1580, 257, 90, 1148, 1721, 372, 1167, 1253, 1213, 846, 789, 616, 1373, 333, 1769, 148, 1508, 110, 323, 337, 1077, 1101, 1116, 1225, 687, 1410, 688, 1280, 284, 1066, 1112, 1058, 1727, 1719, 84, 1051, 1232, 873, 1556, 720, 307, 1666, 360, 506, 699, 1706, 1447, 1617, 577, 1756, 357, 642, 657, 65, 253, 177, 773, 398, 659, 992, 1575, 1652, 1527, 1733, 952, 745, 293, 424, 36, 444, 14, 1315, 1596, 645, 412, 1728, 365, 142, 1049, 176, 894, 1342, 377, 1307, 689, 156, 1129, 603, 1789, 223, 102, 867, 1244, 625, 1202, 1776, 587, 1411, 450, 1521, 813, 1722, 1285, 736, 1740, 77, 1608, 342, 1064, 247, 196, 931, 829, 1649, 843, 1782, 1504, 878, 235, 1230, 1572, 609, 519, 1563, 978, 996, 1154, 474, 546, 774, 287, 911, 1273]\n",
      "layer3.0.downsample.0 [806, 144, 789, 515, 511, 399, 682, 633, 686, 387, 619, 70, 819, 180, 810, 22, 173, 721, 99, 514, 473, 82, 98, 43, 851, 533, 424, 841, 63, 220, 279, 420, 295, 530, 364, 527, 720, 767, 584, 23, 833, 746, 410, 378, 415, 809, 715, 207, 597, 736, 377, 423, 454, 90, 131, 290, 518, 55, 559, 407, 421, 663, 109, 538, 4, 589, 608, 268, 195, 445, 823, 709, 542, 134, 249, 742, 48, 331, 126, 875, 227, 41, 618, 50, 124, 226, 835, 254, 86, 77, 39, 239, 339, 26, 245, 33, 856, 675, 323, 495, 873, 380, 759, 690, 292, 469, 507, 386, 888, 357, 281, 64, 634, 813, 87, 775, 607, 189, 286, 580, 512, 796, 256, 259, 148, 112, 539, 731]\n",
      "layer2.0.downsample.0 [424, 289, 199, 245, 125, 387, 227, 334, 231, 35, 115, 157, 441, 200, 274, 221, 275, 84, 213, 313, 399, 395, 145, 433, 330, 258, 71, 98, 195, 120, 432, 7, 390, 383, 58, 175, 61, 201, 388, 68, 422, 192, 296, 315, 172, 403, 374, 123, 232, 117, 437, 340, 159, 21, 240, 292, 138, 170, 408, 60, 153, 38, 29, 435]\n",
      "layer1.0.downsample.0 [127, 52, 95, 179, 102, 120, 189, 148, 12, 89, 149, 166, 122, 198, 130, 211, 26, 158, 3, 51, 200, 27, 178, 171, 97, 215, 68, 7, 47, 19, 216, 22]\n",
      "conv1 [51, 43, 2, 26, 31, 27, 17, 28]\n",
      "layer1.0.conv2 [11, 23, 53, 29, 43, 14, 38, 6]\n",
      "layer1.0.conv1 [21, 25, 48, 31, 52, 50, 18, 19]\n",
      "layer1.1.conv2 [9, 35, 50, 11, 17, 24, 49, 19]\n",
      "layer1.1.conv1 [7, 11, 40, 13, 34, 27, 30, 48]\n",
      "layer1.2.conv2 [31, 38, 44, 20, 0, 6, 4, 15]\n",
      "layer1.2.conv1 [31, 17, 47, 50, 37, 55, 29, 40]\n",
      "layer2.0.conv2 [98, 22, 103, 65, 89, 97, 111, 52, 0, 28, 85, 10, 83, 34, 20, 9]\n",
      "layer2.0.conv1 [96, 76, 97, 86, 106, 108, 90, 4, 50, 46, 89, 87, 73, 72, 100, 105]\n",
      "layer2.1.conv2 [99, 107, 76, 88, 24, 73, 55, 90, 39, 26, 69, 93, 83, 5, 7, 44]\n",
      "layer2.1.conv1 [24, 51, 20, 95, 40, 55, 29, 101, 25, 63, 68, 77, 49, 87, 90, 37]\n",
      "layer2.2.conv2 [28, 107, 87, 53, 51, 104, 38, 44, 31, 4, 40, 95, 70, 109, 76, 82]\n",
      "layer2.2.conv1 [21, 96, 104, 42, 99, 55, 53, 75, 23, 68, 2, 86, 40, 15, 61, 9]\n",
      "layer2.3.conv2 [97, 17, 95, 15, 34, 111, 37, 66, 40, 57, 45, 86, 44, 2, 82, 92]\n",
      "layer2.3.conv1 [104, 9, 57, 111, 31, 100, 11, 0, 33, 36, 54, 14, 37, 61, 91, 83]\n",
      "layer3.0.conv2 [103, 134, 199, 110, 101, 187, 114, 122, 86, 186, 97, 61, 19, 212, 51, 196, 222, 166, 89, 115, 11, 220, 147, 35, 46, 95, 7, 217, 78, 29, 170, 109]\n",
      "layer3.0.conv1 [44, 119, 38, 72, 157, 76, 111, 24, 170, 222, 174, 136, 151, 28, 78, 217, 63, 169, 4, 1, 132, 216, 16, 35, 84, 223, 196, 98, 66, 168, 220, 198]\n",
      "layer3.1.conv2 [165, 209, 74, 141, 188, 49, 203, 20, 163, 144, 131, 193, 152, 179, 140, 164, 97, 32, 137, 63, 14, 41, 189, 76, 111, 46, 196, 78, 40, 218, 181, 199]\n",
      "layer3.1.conv1 [199, 197, 174, 212, 149, 111, 184, 157, 124, 37, 30, 217, 104, 24, 67, 142, 172, 32, 222, 96, 13, 36, 119, 195, 115, 165, 203, 33, 215, 18, 49, 25]\n",
      "layer3.2.conv2 [210, 71, 34, 3, 89, 175, 66, 30, 40, 79, 147, 38, 132, 70, 134, 153, 168, 127, 114, 8, 121, 158, 217, 35, 10, 126, 103, 16, 93, 95, 191, 73]\n",
      "layer3.2.conv1 [19, 165, 126, 24, 51, 84, 182, 206, 0, 72, 215, 73, 99, 178, 188, 221, 140, 162, 135, 125, 175, 180, 60, 27, 83, 176, 151, 35, 6, 86, 150, 14]\n",
      "layer3.3.conv2 [120, 25, 38, 185, 177, 175, 135, 16, 182, 193, 156, 151, 14, 79, 133, 66, 36, 19, 71, 41, 162, 137, 9, 52, 24, 63, 171, 191, 84, 167, 154, 194]\n",
      "layer3.3.conv1 [151, 187, 52, 38, 101, 214, 175, 55, 182, 170, 29, 134, 70, 142, 122, 19, 95, 31, 73, 139, 104, 78, 64, 163, 179, 50, 154, 199, 9, 15, 168, 171]\n",
      "layer3.4.conv2 [212, 24, 129, 174, 85, 75, 134, 73, 157, 99, 104, 173, 47, 80, 60, 103, 57, 14, 37, 202, 16, 12, 206, 50, 41, 189, 171, 124, 78, 216, 90, 53]\n",
      "layer3.4.conv1 [21, 143, 15, 130, 13, 195, 6, 39, 53, 10, 44, 172, 175, 179, 201, 32, 100, 167, 118, 158, 171, 121, 62, 168, 26, 7, 193, 178, 165, 95, 5, 70]\n",
      "layer3.5.conv2 [47, 158, 101, 220, 2, 112, 194, 143, 132, 75, 27, 135, 131, 79, 14, 173, 128, 43, 46, 146, 17, 82, 183, 197, 37, 63, 68, 167, 3, 152, 95, 113]\n",
      "layer3.5.conv1 [174, 31, 155, 168, 45, 180, 17, 109, 22, 60, 80, 154, 88, 176, 6, 50, 95, 41, 51, 92, 96, 5, 190, 200, 195, 48, 68, 2, 38, 47, 222, 128]\n",
      "layer4.0.conv2 [154, 291, 331, 178, 16, 137, 261, 299, 204, 419, 265, 91, 422, 167, 101, 186, 248, 390, 126, 75, 369, 365, 384, 31, 360, 35, 146, 305, 215, 279, 310, 442, 201, 95, 328, 64, 238, 111, 135, 57, 266, 447, 179, 234, 14, 68, 143, 209, 278, 190, 169, 226, 297, 431, 185, 304, 158, 289, 282, 80, 23, 28, 63, 33]\n",
      "layer4.0.conv1 [368, 73, 114, 439, 229, 267, 11, 343, 152, 381, 239, 143, 195, 199, 40, 96, 21, 158, 205, 208, 336, 191, 392, 207, 211, 162, 82, 157, 373, 261, 7, 214, 102, 351, 278, 415, 251, 83, 0, 105, 280, 414, 421, 308, 289, 161, 171, 372, 338, 140, 185, 149, 377, 101, 202, 411, 410, 222, 231, 94, 400, 179, 356, 435]\n",
      "layer4.1.conv2 [255, 124, 244, 73, 180, 202, 232, 61, 350, 171, 63, 356, 336, 214, 188, 194, 81, 231, 193, 168, 222, 83, 52, 100, 101, 189, 441, 308, 103, 305, 258, 368, 384, 375, 114, 373, 369, 341, 346, 420, 143, 71, 160, 170, 25, 404, 76, 3, 68, 415, 282, 99, 278, 60, 310, 406, 241, 245, 321, 11, 403, 329, 418, 147]\n",
      "layer4.1.conv1 [56, 114, 435, 434, 433, 432, 431, 430, 117, 119, 120, 426, 121, 421, 420, 122, 414, 413, 123, 411, 410, 125, 408, 303, 407, 130, 298, 134, 401, 400, 135, 136, 398, 139, 396, 291, 142, 146, 388, 386, 147, 384, 288, 43, 152, 154, 156, 157, 378, 283, 50, 51, 52, 53, 372, 371, 282, 370, 58, 279, 274, 273, 62, 63]\n",
      "layer4.2.conv2 [58, 248, 151, 206, 343, 149, 333, 330, 144, 334, 133, 138, 136, 251, 371, 3, 252, 214, 396, 250, 154, 350, 406, 384, 10, 200, 195, 340, 6, 26, 402, 90, 419, 304, 376, 285, 37, 56, 317, 351, 221, 426, 216, 344, 242, 299, 354, 43, 147, 143, 364, 77, 276, 199, 287, 300, 445, 2, 243, 256, 34, 253, 246, 5]\n",
      "layer4.2.conv1 [72, 424, 422, 128, 421, 151, 276, 419, 415, 414, 131, 271, 274, 409, 404, 402, 134, 396, 135, 395, 392, 390, 389, 386, 381, 137, 148, 372, 139, 368, 365, 364, 361, 360, 355, 140, 446, 352, 348, 347, 273, 147, 143, 393, 145, 429, 433, 434, 435, 49, 438, 440, 52, 299, 234, 297, 441, 238, 190, 59, 60, 61, 62, 63]\n",
      "Pruning step: 2 multiply–accumulate (macs): 2347233640.0 number of parameters 14771992\n",
      "layer4.0.downsample.0 [16, 547, 424, 1319, 1146, 69, 1393, 986, 1148, 1480, 666, 1410, 1316, 1315, 99, 487, 247, 922, 1086, 1532, 1265, 237, 1175, 519, 840, 55, 412, 1420, 1001, 1405, 307, 1185, 105, 859, 658, 1233, 1279, 748, 1276, 1003, 806, 395, 909, 1133, 1362, 1268, 1114, 91, 990, 151, 388, 594, 722, 415, 1227, 1433, 875, 1382, 896, 753, 1064, 123, 533, 238, 459, 956, 1418, 884, 898, 1375, 695, 1338, 239, 250, 275, 528, 527, 77, 761, 1154, 1473, 2, 860, 302, 1407, 381, 1033, 617, 1340, 1434, 443, 244, 1509, 1437, 1056, 8, 1028, 1165, 1047, 682, 506, 1273, 634, 542, 1283, 37, 561, 287, 503, 173, 789, 1519, 1115, 1504, 414, 466, 549, 921, 1232, 835, 378, 370, 188, 383, 1200, 1361, 824, 417, 491, 1383, 1121, 1400, 429, 458, 897, 1289, 1500, 1000, 729, 945, 694, 987, 1131, 30, 932, 1508, 231, 21, 814, 278, 170, 1042, 1027, 601, 644, 46, 10, 502, 343, 1099, 1300, 325, 960, 888, 686, 1017, 736, 1427, 883, 925, 70, 813, 582, 1465, 1530, 981, 194, 451, 714, 903, 1173, 155, 698, 569, 1364, 1096, 1341, 1286, 36, 839, 518, 684, 266, 1263, 629, 1184, 1084, 1234, 57, 240, 1463, 393, 264, 1090, 484, 219, 554, 735, 558, 1377, 1248, 540, 1511, 1471, 1101, 1526, 42, 467, 490, 1264, 1282, 391, 1444, 965, 1267, 434, 9, 943, 1152, 1277, 214, 1244, 1334, 448, 103, 322, 727, 149, 853, 400, 1318, 409, 1475, 623, 580, 953, 1075, 1347, 907, 1516, 796, 1483, 1260, 376, 834, 755]\n",
      "layer3.0.downsample.0 [665, 284, 662, 371, 13, 63, 140, 241, 449, 112, 358, 287, 259, 574, 48, 707, 393, 113, 683, 464, 19, 401, 42, 411, 312, 125, 189, 82, 243, 384, 607, 69, 653, 734, 234, 545, 309, 747, 446, 264, 727, 229, 145, 9, 523, 690, 536, 657, 492, 244, 202, 191, 47, 381, 716, 498, 361, 275, 751, 320, 557, 452, 363, 130, 88, 196, 261, 245, 722, 414, 445, 511, 568, 470, 376, 280, 255, 600, 226, 159, 8, 528, 75, 766, 677, 650, 174, 278, 332, 746, 442, 227, 194, 385, 136, 413, 427, 577, 616, 540, 59, 686, 618, 360, 109, 517, 692, 534, 216, 57, 29, 257, 441, 508, 38, 154, 507, 170, 669, 199, 17, 106, 420, 703, 658, 173, 732, 754]\n",
      "layer2.0.downsample.0 [20, 31, 208, 257, 89, 133, 23, 316, 299, 321, 11, 304, 349, 332, 220, 215, 265, 300, 34, 359, 270, 363, 289, 372, 69, 242, 146, 243, 35, 95, 313, 8, 47, 357, 218, 187, 145, 134, 160, 73, 287, 238, 3, 92, 210, 111, 77, 383, 286, 240, 344, 149, 147, 236, 330, 56, 118, 42, 200, 376, 209, 33, 165, 212]\n",
      "layer1.0.downsample.0 [155, 3, 146, 159, 185, 135, 167, 179, 31, 170, 138, 49, 78, 137, 47, 68, 25, 173, 168, 40, 46, 39, 124, 44, 117, 33, 9, 34, 50, 16, 122, 64]\n",
      "conv1 [2, 44, 39, 36, 10, 4, 20, 41]\n",
      "layer1.0.conv2 [30, 23, 10, 40, 42, 25, 21, 35]\n",
      "layer1.0.conv1 [36, 16, 42, 4, 8, 25, 21, 1]\n",
      "layer1.1.conv2 [35, 34, 1, 2, 12, 39, 32, 0]\n",
      "layer1.1.conv1 [17, 30, 35, 31, 5, 44, 27, 8]\n",
      "layer1.2.conv2 [42, 1, 5, 44, 0, 22, 14, 31]\n",
      "layer1.2.conv1 [45, 1, 2, 9, 20, 11, 37, 46]\n",
      "layer2.0.conv2 [62, 6, 86, 16, 19, 69, 92, 13, 5, 47, 79, 28, 12, 83, 73, 17]\n",
      "layer2.0.conv1 [79, 89, 78, 85, 47, 1, 77, 40, 19, 10, 45, 7, 81, 91, 48, 17]\n",
      "layer2.1.conv2 [53, 82, 67, 4, 6, 60, 92, 84, 7, 76, 70, 10, 91, 66, 89, 85]\n",
      "layer2.1.conv1 [11, 57, 86, 23, 10, 92, 13, 43, 32, 14, 73, 16, 72, 88, 74, 48]\n",
      "layer2.2.conv2 [29, 92, 39, 16, 34, 51, 40, 15, 71, 65, 64, 19, 18, 90, 82, 49]\n",
      "layer2.2.conv1 [35, 51, 73, 18, 88, 36, 60, 83, 41, 46, 93, 69, 29, 50, 89, 30]\n",
      "layer2.3.conv2 [52, 41, 32, 85, 22, 53, 75, 79, 44, 1, 6, 87, 35, 0, 43, 4]\n",
      "layer2.3.conv1 [72, 14, 48, 87, 43, 77, 71, 31, 10, 20, 16, 17, 11, 2, 5, 18]\n",
      "layer3.0.conv2 [87, 71, 135, 161, 140, 75, 43, 104, 47, 73, 188, 113, 81, 67, 148, 185, 127, 45, 6, 107, 117, 136, 124, 125, 19, 85, 79, 187, 57, 82, 22, 76]\n",
      "layer3.0.conv1 [24, 64, 185, 41, 90, 158, 60, 129, 36, 126, 105, 132, 27, 124, 160, 117, 182, 125, 181, 74, 26, 45, 99, 79, 122, 93, 100, 163, 107, 55, 98, 109]\n",
      "layer3.1.conv2 [29, 98, 143, 83, 6, 15, 36, 120, 81, 183, 41, 175, 76, 71, 102, 109, 136, 43, 64, 141, 25, 115, 39, 54, 150, 104, 103, 93, 164, 70, 114, 99]\n",
      "layer3.1.conv1 [172, 4, 126, 113, 71, 173, 99, 151, 182, 104, 185, 181, 94, 78, 136, 162, 31, 163, 188, 178, 117, 147, 168, 56, 161, 11, 118, 130, 100, 121, 74, 164]\n",
      "layer3.2.conv2 [52, 119, 95, 80, 3, 189, 8, 40, 29, 131, 173, 12, 58, 13, 114, 169, 81, 142, 71, 48, 167, 65, 76, 92, 89, 41, 183, 53, 14, 2, 171, 88]\n",
      "layer3.2.conv1 [110, 122, 50, 177, 98, 36, 22, 17, 101, 172, 109, 72, 4, 11, 38, 141, 140, 42, 55, 29, 73, 18, 13, 158, 134, 52, 111, 75, 129, 119, 118, 169]\n",
      "layer3.3.conv2 [55, 84, 157, 131, 82, 38, 81, 166, 89, 57, 29, 129, 187, 35, 121, 137, 97, 130, 101, 161, 46, 54, 12, 105, 39, 150, 78, 41, 93, 159, 132, 146]\n",
      "layer3.3.conv1 [53, 148, 83, 136, 79, 70, 3, 157, 152, 49, 55, 18, 133, 149, 163, 54, 104, 39, 93, 94, 106, 61, 1, 13, 129, 186, 151, 2, 62, 105, 11, 16]\n",
      "layer3.4.conv2 [180, 135, 148, 90, 161, 62, 184, 122, 137, 31, 39, 101, 25, 179, 115, 133, 19, 160, 4, 165, 48, 95, 46, 57, 131, 51, 142, 183, 92, 140, 185, 188]\n",
      "layer3.4.conv1 [24, 148, 189, 30, 172, 70, 66, 106, 7, 185, 71, 47, 128, 183, 190, 6, 20, 61, 52, 152, 91, 171, 163, 99, 187, 86, 115, 60, 138, 155, 94, 118]\n",
      "layer3.5.conv2 [182, 103, 186, 42, 119, 145, 47, 35, 89, 177, 58, 23, 112, 146, 169, 69, 138, 18, 39, 80, 135, 2, 22, 29, 141, 139, 131, 125, 142, 100, 104, 144]\n",
      "layer3.5.conv1 [123, 9, 5, 27, 26, 162, 31, 64, 186, 153, 101, 109, 119, 144, 168, 6, 96, 25, 169, 2, 18, 57, 62, 65, 114, 135, 112, 185, 158, 172, 32, 104]\n",
      "layer4.0.conv2 [339, 36, 151, 278, 123, 1, 138, 34, 80, 159, 356, 84, 216, 20, 12, 361, 357, 120, 373, 362, 82, 167, 40, 143, 285, 280, 241, 126, 364, 232, 351, 245, 374, 158, 154, 10, 223, 14, 258, 150, 43, 322, 378, 315, 342, 260, 49, 261, 235, 316, 383, 204, 147, 287, 251, 86, 324, 13, 318, 184, 169, 286, 119, 51]\n",
      "layer4.0.conv1 [44, 131, 272, 360, 363, 252, 309, 207, 0, 349, 218, 237, 344, 311, 119, 171, 88, 147, 89, 357, 225, 278, 96, 254, 18, 189, 284, 358, 194, 315, 92, 137, 28, 297, 294, 247, 343, 216, 211, 328, 261, 134, 20, 187, 172, 317, 157, 8, 40, 220, 93, 118, 117, 266, 23, 292, 71, 151, 340, 125, 379, 268, 17, 233]\n",
      "layer4.1.conv2 [93, 139, 24, 286, 150, 281, 12, 226, 158, 63, 290, 76, 292, 217, 142, 206, 75, 272, 231, 103, 44, 279, 9, 367, 43, 7, 362, 26, 36, 350, 192, 21, 83, 379, 182, 69, 128, 54, 136, 265, 162, 210, 184, 264, 194, 48, 173, 25, 218, 16, 355, 149, 80, 198, 100, 47, 118, 31, 289, 168, 180, 181, 190, 301]\n",
      "layer4.1.conv1 [176, 379, 378, 204, 173, 205, 236, 319, 235, 233, 171, 317, 210, 380, 214, 192, 55, 193, 194, 163, 215, 185, 216, 99, 93, 158, 91, 104, 88, 87, 86, 83, 80, 102, 222, 74, 97, 68, 65, 324, 238, 322, 63, 321, 320, 62, 357, 161, 137, 369, 33, 35, 15, 69, 73, 190, 254, 262, 128, 42, 304, 164, 89, 273]\n",
      "layer4.2.conv2 [120, 288, 130, 238, 247, 149, 25, 217, 218, 117, 88, 328, 107, 70, 229, 239, 274, 112, 165, 48, 72, 176, 5, 168, 183, 53, 219, 381, 360, 276, 314, 373, 222, 126, 57, 59, 184, 263, 304, 73, 23, 334, 226, 266, 187, 254, 4, 297, 100, 116, 248, 131, 32, 253, 145, 354, 201, 137, 189, 199, 40, 98, 83, 241]\n",
      "layer4.2.conv1 [218, 158, 221, 95, 223, 61, 63, 380, 64, 232, 225, 65, 150, 146, 66, 256, 229, 101, 67, 116, 115, 70, 114, 118, 235, 161, 133, 156, 129, 216, 168, 259, 252, 253, 254, 269, 93, 89, 87, 85, 84, 268, 80, 78, 261, 77, 75, 262, 265, 58, 73, 379, 49, 292, 276, 137, 79, 248, 376, 272, 83, 5, 353, 6]\n",
      "Pruning step: 3 multiply–accumulate (macs): 1645940520.0 number of parameters 10478480\n",
      "layer4.0.downsample.0 [940, 812, 721, 1110, 621, 482, 258, 547, 923, 1160, 544, 629, 74, 342, 557, 1174, 776, 992, 293, 323, 938, 291, 203, 519, 286, 37, 778, 489, 823, 1017, 102, 985, 288, 1109, 970, 1005, 1205, 1060, 1067, 1272, 111, 565, 1062, 644, 34, 1207, 1195, 879, 171, 651, 1006, 466, 1159, 834, 522, 910, 62, 842, 8, 800, 43, 434, 1085, 1214, 609, 17, 275, 424, 5, 664, 408, 110, 530, 70, 274, 370, 1169, 753, 4, 925, 118, 1097, 364, 297, 91, 529, 243, 872, 1185, 191, 69, 45, 1188, 252, 626, 901, 54, 828, 870, 1262, 863, 389, 86, 882, 605, 524, 190, 1158, 1156, 134, 748, 302, 507, 694, 972, 313, 140, 234, 679, 1187, 1132, 690, 797, 587, 876, 877, 340, 878, 35, 499, 955, 94, 455, 398, 1011, 975, 71, 506, 188, 843, 267, 931, 1255, 660, 327, 257, 858, 654, 803, 1166, 208, 1209, 966, 49, 1012, 1260, 859, 515, 144, 1116, 1038, 927, 183, 1059, 1015, 156, 622, 746, 603, 1068, 33, 130, 80, 1150, 1009, 995, 564, 709, 106, 739, 12, 221, 73, 1231, 330, 484, 847, 256, 540, 1232, 730, 579, 668, 205, 496, 502, 687, 287, 1102, 306, 1204, 186, 543, 123, 649, 1277, 681, 614, 535, 15, 9, 789, 623, 618, 402, 613, 798, 1089, 212, 462, 592, 155, 875, 458, 533, 745, 1271, 48, 559, 817, 276, 829, 332, 639, 266, 900, 211, 461, 1074, 1010, 973, 407, 1239, 497, 862, 278, 444, 920, 926, 1087, 354, 67, 1065, 758, 890, 1081]\n",
      "layer3.0.downsample.0 [137, 101, 320, 587, 512, 498, 441, 581, 373, 291, 241, 615, 621, 139, 225, 113, 51, 248, 549, 403, 503, 524, 546, 335, 99, 431, 619, 336, 491, 153, 519, 493, 338, 551, 327, 346, 233, 140, 567, 477, 151, 612, 353, 289, 152, 363, 528, 501, 464, 573, 294, 110, 300, 379, 364, 437, 308, 306, 258, 146, 618, 541, 105, 449, 438, 275, 374, 561, 515, 34, 18, 455, 479, 194, 318, 468, 141, 539, 94, 416, 26, 203, 411, 70, 470, 371, 29, 586, 76, 197, 191, 334, 255, 215, 324, 389, 523, 20, 290, 461, 502, 331, 362, 601, 208, 545, 21, 277, 149, 174, 401, 91, 299, 594, 396, 47, 4, 390, 199, 478, 433, 578, 135, 568, 606, 187, 342, 77]\n",
      "layer2.0.downsample.0 [301, 67, 16, 241, 283, 62, 66, 247, 234, 81, 106, 158, 68, 2, 165, 122, 56, 226, 176, 280, 212, 107, 137, 259, 4, 153, 205, 111, 57, 273, 128, 217, 131, 8, 143, 251, 219, 34, 194, 18, 225, 94, 244, 178, 294, 164, 282, 80, 300, 29, 313, 64, 159, 271, 148, 296, 264, 1, 253, 75, 112, 98, 71, 179]\n",
      "layer1.0.downsample.0 [137, 141, 21, 154, 98, 93, 51, 146, 111, 82, 92, 132, 52, 138, 157, 20, 153, 113, 66, 43, 53, 15, 23, 0, 149, 106, 85, 84, 24, 155, 13, 73]\n",
      "conv1 [23, 35, 26, 24, 19, 25, 0, 30]\n",
      "layer1.0.conv2 [24, 10, 18, 2, 36, 20, 38, 6]\n",
      "layer1.0.conv1 [22, 23, 34, 38, 37, 19, 35, 21]\n",
      "layer1.1.conv2 [3, 39, 38, 25, 11, 6, 22, 19]\n",
      "layer1.1.conv1 [13, 7, 8, 1, 20, 32, 16, 3]\n",
      "layer1.2.conv2 [17, 39, 31, 19, 9, 38, 36, 21]\n",
      "layer1.2.conv1 [37, 27, 13, 25, 0, 21, 36, 2]\n",
      "layer2.0.conv2 [45, 28, 6, 26, 17, 9, 13, 54, 8, 14, 58, 76, 36, 69, 25, 11]\n",
      "layer2.0.conv1 [42, 40, 32, 38, 56, 77, 8, 59, 46, 7, 67, 10, 39, 61, 52, 4]\n",
      "layer2.1.conv2 [44, 67, 55, 24, 49, 10, 48, 20, 77, 78, 6, 0, 71, 70, 47, 38]\n",
      "layer2.1.conv1 [35, 2, 9, 74, 73, 13, 60, 72, 38, 21, 5, 16, 22, 49, 79, 19]\n",
      "layer2.2.conv2 [55, 13, 21, 41, 0, 40, 69, 70, 50, 51, 43, 24, 78, 3, 23, 61]\n",
      "layer2.2.conv1 [52, 58, 25, 69, 77, 78, 74, 62, 21, 73, 55, 29, 1, 35, 57, 13]\n",
      "layer2.3.conv2 [21, 61, 68, 12, 27, 24, 77, 52, 58, 17, 49, 65, 69, 2, 60, 28]\n",
      "layer2.3.conv1 [37, 23, 22, 0, 31, 56, 12, 69, 36, 75, 28, 55, 13, 63, 26, 51]\n",
      "layer3.0.conv2 [114, 154, 40, 27, 25, 132, 78, 129, 48, 130, 93, 51, 73, 126, 148, 59, 123, 122, 29, 151, 120, 62, 141, 98, 159, 2, 55, 112, 71, 131, 102, 121]\n",
      "layer3.0.conv1 [140, 26, 92, 128, 129, 6, 49, 5, 97, 125, 95, 60, 159, 64, 84, 112, 103, 70, 45, 54, 4, 156, 10, 55, 99, 148, 119, 155, 85, 105, 104, 59]\n",
      "layer3.1.conv2 [9, 124, 88, 28, 101, 68, 79, 13, 119, 108, 114, 12, 36, 147, 81, 16, 67, 125, 131, 150, 91, 64, 107, 92, 66, 76, 62, 44, 72, 43, 30, 134]\n",
      "layer3.1.conv1 [102, 66, 60, 77, 106, 143, 24, 148, 110, 7, 18, 154, 16, 130, 21, 69, 97, 19, 28, 46, 124, 105, 80, 112, 81, 131, 29, 119, 10, 89, 39, 149]\n",
      "layer3.2.conv2 [107, 43, 96, 90, 101, 62, 146, 115, 60, 52, 91, 55, 9, 5, 123, 112, 18, 53, 69, 8, 66, 159, 137, 16, 97, 7, 63, 56, 158, 93, 33, 102]\n",
      "layer3.2.conv1 [65, 13, 67, 106, 100, 146, 95, 91, 57, 64, 84, 44, 126, 113, 51, 4, 139, 10, 150, 74, 155, 159, 104, 3, 0, 11, 69, 121, 122, 96, 7, 60]\n",
      "layer3.3.conv2 [128, 91, 112, 50, 22, 99, 74, 29, 57, 80, 154, 48, 41, 47, 107, 66, 83, 89, 26, 67, 113, 149, 15, 130, 4, 16, 85, 100, 25, 27, 68, 69]\n",
      "layer3.3.conv1 [103, 47, 143, 32, 18, 138, 117, 4, 60, 72, 130, 96, 110, 139, 100, 26, 156, 56, 24, 89, 62, 42, 14, 154, 109, 152, 93, 78, 112, 81, 115, 52]\n",
      "layer3.4.conv2 [80, 83, 102, 155, 126, 138, 30, 98, 107, 69, 133, 93, 82, 84, 40, 13, 149, 10, 7, 34, 47, 9, 50, 20, 135, 104, 110, 74, 117, 28, 72, 142]\n",
      "layer3.4.conv1 [62, 114, 87, 116, 80, 67, 96, 18, 60, 21, 38, 152, 10, 111, 17, 127, 72, 7, 64, 91, 39, 126, 137, 68, 4, 78, 85, 95, 90, 69, 92, 55]\n",
      "layer3.5.conv2 [83, 97, 69, 5, 73, 6, 25, 65, 133, 64, 102, 123, 20, 67, 157, 96, 127, 50, 126, 63, 40, 44, 39, 84, 66, 31, 57, 72, 38, 7, 158, 34]\n",
      "layer3.5.conv1 [142, 127, 62, 46, 60, 41, 147, 130, 150, 16, 7, 121, 118, 4, 156, 114, 56, 92, 107, 157, 68, 50, 17, 14, 80, 6, 131, 8, 93, 0, 90, 143]\n",
      "layer4.0.conv2 [262, 241, 30, 98, 305, 154, 57, 266, 170, 239, 217, 127, 106, 276, 112, 215, 50, 134, 314, 130, 4, 139, 46, 74, 202, 267, 234, 303, 198, 119, 90, 24, 29, 298, 152, 23, 172, 265, 236, 268, 283, 188, 222, 140, 230, 254, 151, 279, 197, 148, 75, 191, 124, 229, 295, 220, 133, 82, 118, 174, 60, 269, 101, 141]\n",
      "layer4.0.conv1 [100, 249, 151, 302, 53, 296, 119, 289, 26, 54, 59, 21, 75, 18, 288, 280, 270, 2, 290, 28, 299, 222, 225, 316, 307, 120, 97, 276, 41, 87, 107, 256, 162, 217, 189, 258, 207, 135, 214, 145, 78, 309, 128, 263, 242, 230, 118, 279, 283, 19, 121, 311, 131, 56, 215, 24, 49, 205, 232, 246, 129, 11, 38, 65]\n",
      "layer4.1.conv2 [159, 212, 52, 68, 131, 70, 94, 124, 196, 287, 184, 39, 120, 167, 183, 310, 171, 149, 272, 22, 192, 119, 88, 225, 172, 208, 73, 269, 302, 309, 262, 300, 232, 95, 168, 162, 102, 107, 126, 48, 101, 176, 163, 99, 313, 142, 259, 288, 188, 246, 285, 254, 191, 5, 145, 165, 93, 79, 69, 143, 229, 190, 224, 57]\n",
      "layer4.1.conv1 [119, 42, 313, 167, 60, 88, 131, 105, 179, 230, 198, 266, 83, 132, 56, 277, 139, 256, 122, 174, 259, 41, 161, 278, 261, 207, 37, 150, 225, 154, 295, 8, 22, 9, 285, 158, 159, 92, 190, 319, 30, 286, 279, 175, 118, 240, 296, 264, 120, 164, 20, 223, 271, 186, 205, 253, 64, 212, 317, 52, 187, 267, 51, 316]\n",
      "layer4.2.conv2 [161, 118, 313, 163, 37, 90, 137, 193, 29, 7, 231, 35, 291, 220, 78, 171, 259, 138, 85, 228, 319, 67, 212, 300, 45, 59, 33, 245, 214, 56, 133, 314, 103, 284, 310, 157, 23, 84, 186, 190, 12, 98, 79, 57, 196, 168, 101, 53, 252, 46, 208, 225, 226, 294, 83, 213, 159, 125, 263, 41, 50, 198, 239, 5]\n",
      "layer4.2.conv1 [245, 257, 131, 138, 208, 175, 3, 183, 82, 95, 154, 46, 113, 150, 273, 111, 300, 9, 200, 77, 72, 274, 70, 79, 205, 110, 254, 281, 28, 58, 262, 226, 66, 157, 318, 115, 68, 265, 24, 295, 86, 319, 220, 169, 297, 168, 229, 276, 231, 69, 233, 215, 147, 206, 308, 83, 25, 148, 98, 21, 203, 33, 219, 35]\n",
      "Pruning step: 4 multiply–accumulate (macs): 1068682472.0 number of parameters 6917640\n",
      "layer4.0.downsample.0 [428, 716, 611, 184, 851, 1011, 646, 569, 175, 35, 861, 653, 871, 541, 590, 253, 554, 334, 231, 477, 375, 431, 289, 343, 324, 383, 167, 70, 506, 421, 11, 835, 36, 474, 849, 845, 697, 406, 952, 500, 524, 128, 802, 412, 470, 327, 1017, 770, 405, 992, 501, 1018, 504, 152, 738, 71, 192, 101, 823, 399, 559, 875, 1013, 530, 29, 486, 642, 5, 543, 668, 328, 889, 229, 709, 761, 432, 867, 591, 695, 30, 749, 739, 783, 704, 367, 479, 385, 830, 355, 837, 690, 461, 164, 622, 90, 363, 143, 508, 388, 961, 465, 472, 62, 846, 525, 735, 672, 899, 918, 963, 31, 301, 788, 901, 168, 916, 932, 498, 627, 487, 453, 947, 17, 4, 1010, 687, 965, 2, 269, 547, 429, 445, 156, 587, 881, 816, 553, 580, 400, 178, 225, 518, 1021, 84, 292, 366, 402, 378, 685, 981, 624, 244, 645, 760, 131, 595, 629, 634, 766, 732, 677, 230, 997, 252, 829, 911, 307, 890, 592, 145, 256, 254, 288, 637, 626, 895, 688, 370, 505, 1022, 78, 790, 305, 607, 123, 332, 27, 718, 537, 866, 144, 420, 102, 669, 597, 746, 654, 241, 494, 812, 161, 410, 720, 946, 854, 3, 964, 203, 838, 938, 195, 419, 243, 745, 264, 181, 232, 236, 491, 674, 640, 281, 166, 684, 879, 882, 1002, 517, 603, 456, 339, 921, 526, 601, 934, 107, 896, 114, 261, 81, 394, 349, 497, 503, 199, 148, 220, 950, 380, 377, 985, 490, 943, 95, 641, 555]\n",
      "layer3.0.downsample.0 [277, 71, 161, 354, 136, 490, 500, 156, 471, 245, 189, 13, 400, 464, 132, 426, 98, 456, 268, 4, 50, 148, 220, 296, 505, 138, 445, 288, 273, 40, 20, 14, 508, 469, 389, 253, 198, 197, 112, 328, 452, 85, 481, 244, 219, 396, 434, 21, 297, 65, 183, 49, 246, 107, 83, 76, 229, 218, 141, 15, 398, 241, 178, 1, 232, 455, 237, 235, 511, 243, 24, 154, 395, 323, 39, 19, 159, 248, 357, 316, 482, 433, 267, 200, 95, 249, 102, 149, 386, 485, 8, 301, 502, 393, 202, 470, 476, 451, 365, 378, 221, 56, 111, 358, 168, 123, 94, 339, 211, 191, 494, 499, 3, 270, 413, 503, 309, 135, 139, 160, 59, 327, 57, 369, 480, 106, 146, 274]\n",
      "layer2.0.downsample.0 [158, 196, 59, 201, 81, 20, 193, 67, 50, 195, 203, 116, 148, 137, 172, 247, 213, 118, 126, 145, 109, 227, 0, 124, 62, 33, 80, 129, 188, 181, 212, 169, 88, 215, 68, 140, 86, 69, 12, 143, 244, 52, 27, 242, 44, 231, 8, 47, 176, 63, 61, 79, 149, 241, 98, 121, 207, 36, 206, 182, 165, 219, 65, 78]\n",
      "layer1.0.downsample.0 [40, 81, 41, 99, 31, 53, 89, 79, 48, 56, 49, 17, 101, 52, 69, 100, 127, 19, 54, 59, 28, 20, 25, 85, 111, 42, 9, 107, 78, 64, 37, 112]\n",
      "conv1 [17, 20, 6, 29, 10, 2, 27, 1]\n",
      "layer1.0.conv2 [1, 29, 12, 22, 23, 8, 14, 6]\n",
      "layer1.0.conv1 [28, 24, 23, 17, 4, 14, 22, 8]\n",
      "layer1.1.conv2 [27, 3, 0, 24, 5, 21, 1, 8]\n",
      "layer1.1.conv1 [10, 27, 13, 25, 18, 24, 2, 7]\n",
      "layer1.2.conv2 [29, 0, 28, 7, 12, 27, 31, 14]\n",
      "layer1.2.conv1 [8, 0, 22, 23, 16, 17, 30, 26]\n",
      "layer2.0.conv2 [35, 38, 43, 4, 25, 37, 17, 44, 51, 13, 54, 57, 3, 42, 2, 12]\n",
      "layer2.0.conv1 [33, 41, 8, 28, 11, 6, 12, 49, 35, 36, 55, 13, 50, 4, 63, 34]\n",
      "layer2.1.conv2 [24, 11, 63, 38, 32, 35, 60, 28, 39, 13, 52, 21, 47, 45, 62, 34]\n",
      "layer2.1.conv1 [23, 46, 61, 3, 31, 1, 10, 17, 37, 57, 34, 0, 12, 16, 9, 60]\n",
      "layer2.2.conv2 [57, 62, 1, 50, 44, 39, 12, 31, 46, 9, 15, 20, 2, 26, 37, 49]\n",
      "layer2.2.conv1 [51, 32, 33, 7, 46, 30, 43, 9, 45, 48, 31, 23, 19, 61, 16, 50]\n",
      "layer2.3.conv2 [33, 7, 9, 63, 27, 12, 1, 25, 45, 4, 56, 18, 38, 16, 36, 0]\n",
      "layer2.3.conv1 [16, 59, 25, 10, 57, 53, 46, 7, 40, 60, 27, 31, 15, 56, 0, 24]\n",
      "layer3.0.conv2 [25, 50, 38, 63, 78, 104, 27, 86, 117, 98, 18, 8, 54, 115, 37, 95, 74, 100, 36, 79, 53, 84, 85, 60, 14, 43, 10, 1, 67, 124, 29, 75]\n",
      "layer3.0.conv1 [19, 54, 70, 77, 121, 65, 63, 32, 2, 117, 123, 7, 21, 118, 31, 0, 104, 127, 112, 92, 102, 56, 83, 45, 115, 6, 24, 64, 37, 5, 125, 71]\n",
      "layer3.1.conv2 [56, 87, 4, 95, 44, 118, 108, 110, 100, 119, 82, 61, 96, 101, 62, 21, 37, 90, 38, 30, 0, 69, 31, 103, 99, 6, 13, 40, 89, 24, 25, 123]\n",
      "layer3.1.conv1 [8, 47, 91, 0, 117, 4, 85, 118, 127, 111, 114, 46, 21, 62, 50, 25, 24, 23, 10, 55, 86, 94, 51, 39, 115, 99, 79, 102, 116, 1, 42, 123]\n",
      "layer3.2.conv2 [104, 112, 81, 5, 21, 72, 8, 84, 36, 28, 11, 24, 96, 70, 48, 68, 121, 52, 12, 15, 6, 9, 56, 71, 13, 63, 17, 92, 20, 123, 67, 113]\n",
      "layer3.2.conv1 [120, 124, 121, 127, 101, 7, 103, 53, 15, 38, 80, 66, 102, 76, 43, 100, 48, 5, 31, 116, 18, 65, 115, 2, 69, 118, 34, 26, 97, 60, 21, 71]\n",
      "layer3.3.conv2 [27, 19, 24, 107, 124, 92, 14, 110, 126, 16, 86, 97, 45, 28, 58, 57, 118, 108, 90, 11, 100, 33, 5, 6, 10, 15, 49, 89, 106, 78, 8, 21]\n",
      "layer3.3.conv1 [41, 2, 99, 0, 22, 83, 29, 92, 25, 61, 8, 46, 86, 96, 39, 13, 47, 59, 82, 5, 91, 127, 49, 122, 118, 14, 79, 27, 98, 16, 50, 109]\n",
      "layer3.4.conv2 [6, 20, 16, 86, 4, 117, 13, 33, 40, 14, 66, 106, 53, 72, 82, 112, 123, 59, 9, 98, 83, 104, 35, 89, 60, 61, 41, 1, 110, 19, 28, 108]\n",
      "layer3.4.conv1 [64, 116, 80, 35, 98, 71, 52, 124, 5, 29, 53, 70, 3, 114, 117, 24, 59, 120, 12, 127, 6, 107, 86, 40, 33, 22, 85, 90, 68, 73, 7, 105]\n",
      "layer3.5.conv2 [3, 4, 57, 81, 93, 28, 21, 87, 51, 100, 2, 94, 43, 63, 66, 64, 44, 79, 78, 67, 62, 6, 53, 119, 35, 40, 123, 65, 83, 20, 90, 105]\n",
      "layer3.5.conv1 [118, 53, 99, 27, 125, 29, 95, 89, 58, 105, 77, 62, 5, 93, 44, 113, 117, 47, 124, 24, 61, 14, 69, 70, 23, 64, 111, 13, 0, 59, 75, 85]\n",
      "layer4.0.conv2 [83, 120, 241, 160, 111, 40, 112, 47, 182, 19, 10, 223, 135, 132, 252, 220, 168, 166, 143, 64, 4, 98, 231, 23, 193, 234, 110, 140, 44, 205, 52, 35, 206, 117, 159, 100, 89, 93, 161, 24, 114, 107, 201, 248, 75, 134, 105, 69, 145, 170, 5, 59, 177, 217, 133, 219, 240, 30, 8, 192, 189, 149, 212, 66]\n",
      "layer4.0.conv1 [190, 29, 191, 163, 18, 199, 153, 89, 6, 20, 3, 244, 8, 130, 132, 106, 161, 112, 134, 108, 115, 206, 99, 79, 109, 181, 167, 28, 211, 235, 32, 150, 208, 247, 85, 175, 131, 185, 97, 92, 214, 152, 43, 198, 203, 93, 229, 212, 122, 223, 221, 218, 228, 52, 239, 241, 196, 207, 176, 156, 192, 178, 174, 233]\n",
      "layer4.1.conv2 [104, 64, 2, 208, 216, 168, 111, 0, 229, 185, 102, 186, 123, 54, 45, 88, 94, 164, 223, 74, 189, 226, 141, 154, 112, 244, 174, 48, 245, 236, 40, 225, 138, 230, 184, 96, 132, 137, 23, 67, 140, 126, 176, 159, 50, 242, 187, 4, 153, 39, 171, 12, 68, 107, 177, 207, 130, 106, 215, 178, 251, 190, 49, 14]\n",
      "layer4.1.conv1 [213, 62, 58, 153, 245, 118, 72, 45, 86, 157, 177, 75, 94, 44, 235, 233, 92, 255, 201, 112, 180, 106, 222, 164, 189, 0, 54, 46, 71, 218, 84, 194, 80, 14, 176, 254, 113, 20, 107, 53, 8, 121, 91, 231, 105, 150, 123, 179, 192, 234, 10, 26, 178, 172, 210, 15, 73, 147, 243, 225, 244, 90, 38, 65]\n",
      "layer4.2.conv2 [242, 149, 220, 211, 124, 110, 200, 208, 114, 44, 232, 127, 15, 207, 78, 204, 146, 125, 175, 182, 194, 17, 190, 43, 106, 249, 82, 21, 159, 154, 33, 77, 238, 213, 128, 58, 250, 150, 156, 201, 245, 95, 50, 76, 107, 141, 205, 218, 87, 75, 13, 74, 23, 172, 68, 147, 48, 196, 29, 37, 145, 93, 41, 99]\n",
      "layer4.2.conv1 [90, 143, 54, 197, 205, 142, 120, 33, 128, 247, 212, 89, 139, 44, 154, 129, 83, 234, 16, 184, 68, 61, 147, 127, 71, 225, 15, 159, 122, 123, 111, 130, 245, 138, 213, 137, 10, 182, 166, 162, 112, 110, 163, 66, 217, 240, 175, 48, 233, 186, 119, 133, 29, 98, 43, 180, 113, 6, 12, 252, 26, 249, 132, 88]\n",
      "Pruning step: 5 multiply–accumulate (macs): 615459496.0 number of parameters 4089472\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 24, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(192, 384, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n",
      "Pruning sparsity: 0.6875\n",
      "layer4.0.downsample.0 [1929, 93, 1993, 1058, 338, 1144, 275, 80, 1748, 892, 1925, 61, 605, 468, 675, 100, 565, 112, 745, 1258, 351, 309, 1326, 311, 1288, 1880, 1477, 1449, 653, 437, 167, 751, 1827, 1349, 1292, 955, 2046, 1980, 1077, 1906, 1253, 1257, 663, 1743, 416, 1201, 1193, 456, 1850, 695, 1462, 1344, 560, 478, 455, 108, 898, 1154, 327, 395, 1192, 1492, 1561, 1888, 296, 1427, 1051, 1568, 1014, 619, 968, 449, 1592, 1055, 558, 583, 839, 2020, 1578, 362, 728, 204, 1843, 1570, 563, 1940, 303, 833, 975, 1941, 1819, 1496, 854, 660, 1726, 305, 143, 1156, 241, 301, 801, 1211, 1221, 1595, 623, 1262, 54, 617, 307, 1974, 1508, 15, 899, 1126, 1375, 195, 1817, 1625, 1099, 1318, 743, 610, 427, 1444, 1510, 1600, 1702, 2042, 706, 1973, 447, 144, 1286, 382, 861, 415, 51, 580, 1428, 218, 1371, 66, 1093, 1794, 794, 1994, 1087, 32, 2003, 1898, 1769, 2040, 1613, 1932, 1139, 734, 526, 377, 1604, 472, 1429, 1070, 1120, 1608, 868, 688, 128, 1692, 1961, 16, 1414, 1953, 77, 622, 1718, 1191, 1441, 353, 1393, 919, 1685, 480, 331, 140, 737, 771, 1270, 521, 1770, 1437, 1693, 194, 1658, 343, 1681, 939, 220, 705, 685, 1357, 1301, 691, 1347, 782, 1889, 247, 1003, 448, 1036, 909, 1802, 500, 1676, 895, 1598, 207, 119, 1046, 721, 755, 1760, 319, 474, 910, 1125, 1820, 687, 1412, 1614, 1448, 936, 1338, 763, 1970, 1967, 1757, 803, 479, 1920, 1167, 302, 683, 863, 453, 1537, 809, 1554, 1930, 676, 1803, 1106, 1006, 1893, 1212, 843, 293, 121, 1172, 986, 1032, 122, 420, 1683, 1829, 867, 712, 285, 1800, 1314, 592, 1369, 1711, 1699, 649, 1334, 1637, 425, 290, 1229, 1832, 83, 1659]\n",
      "layer3.0.downsample.0 [962, 853, 486, 1018, 1023, 491, 657, 501, 544, 303, 170, 412, 803, 18, 644, 759, 906, 729, 500, 91, 60, 197, 966, 96, 123, 444, 595, 980, 1011, 685, 923, 741, 16, 45, 51, 83, 709, 92, 928, 38, 778, 105, 194, 662, 656, 927, 579, 419, 494, 297, 352, 873, 701, 388, 487, 747, 340, 590, 728, 536, 310, 151, 192, 825, 511, 311, 514, 390, 744, 478, 678, 801, 541, 417, 149, 748, 647, 619, 468, 819, 933, 620, 772, 589, 900, 543, 972, 786, 971, 909, 99, 716, 706, 609, 407, 956, 665, 767, 118, 732, 610, 817, 371, 776, 924, 71, 556, 72, 534, 601, 881, 433, 582, 331, 937, 457, 922, 576, 766, 1022, 553, 325, 482, 836, 985, 47, 800, 376, 86, 202, 132, 87, 919, 826, 1017, 29, 467, 370, 114, 852, 683]\n",
      "layer2.0.downsample.0 [387, 246, 412, 176, 404, 243, 34, 347, 100, 163, 11, 53, 24, 98, 114, 66, 43, 371, 184, 361, 33, 495, 424, 207, 166, 0, 188, 85, 411, 363, 149, 311, 438, 96, 81, 60, 509, 326, 379, 372, 353, 58, 102, 147, 309, 485, 442, 381, 192, 285, 339, 139, 279, 382, 345, 269, 328, 487, 229, 307, 473, 10, 133, 504, 180, 265, 254, 245, 483, 204, 465]\n",
      "layer1.0.downsample.0 [144, 77, 108, 214, 150, 112, 58, 103, 131, 92, 235, 29, 0, 10, 31, 156, 225, 36, 245, 68, 97, 26, 231, 63, 135, 69, 233, 196, 14, 218, 60, 113, 21, 120, 168, 148]\n",
      "conv1 [13, 44, 42, 52, 57, 31, 11, 59, 58]\n",
      "layer1.0.conv2 [0, 1, 19, 61, 22, 60, 9, 59, 14]\n",
      "layer1.0.conv1 [23, 1, 33, 38, 7, 27, 60, 58, 56]\n",
      "layer1.1.conv2 [25, 6, 41, 44, 17, 38, 45, 40, 10]\n",
      "layer1.1.conv1 [2, 56, 4, 55, 9, 47, 13, 15, 45]\n",
      "layer1.2.conv2 [11, 57, 7, 51, 5, 4, 39, 24, 35]\n",
      "layer1.2.conv1 [2, 39, 49, 45, 19, 63, 52, 33, 59]\n",
      "layer2.0.conv2 [35, 90, 119, 69, 3, 4, 29, 51, 120, 110, 53, 54, 101, 99, 61, 72, 38, 25]\n",
      "layer2.0.conv1 [89, 112, 92, 8, 63, 68, 104, 2, 61, 14, 66, 12, 122, 121, 62, 86, 1, 110]\n",
      "layer2.1.conv2 [10, 29, 46, 26, 94, 93, 9, 121, 120, 109, 54, 112, 77, 38, 126, 100, 30, 96]\n",
      "layer2.1.conv1 [83, 1, 58, 3, 118, 5, 108, 102, 63, 76, 111, 69, 14, 28, 29, 79, 56, 62]\n",
      "layer2.2.conv2 [56, 29, 18, 39, 34, 101, 75, 2, 12, 47, 86, 32, 22, 35, 53, 43, 87, 97]\n",
      "layer2.2.conv1 [38, 63, 75, 120, 117, 112, 102, 6, 76, 12, 88, 40, 123, 107, 110, 83, 23, 17]\n",
      "layer2.3.conv2 [127, 36, 17, 0, 124, 76, 19, 106, 8, 111, 57, 42, 95, 37, 77, 113, 67, 116]\n",
      "layer2.3.conv1 [74, 120, 79, 114, 9, 23, 6, 30, 4, 52, 37, 33, 49, 68, 119, 44, 127, 105]\n",
      "layer3.0.conv2 [2, 248, 4, 54, 141, 250, 13, 106, 116, 151, 152, 221, 133, 207, 247, 222, 157, 35, 199, 160, 115, 194, 254, 192, 127, 111, 232, 219, 136, 122, 226, 240, 95, 126, 44, 211]\n",
      "layer3.0.conv1 [139, 18, 4, 254, 220, 136, 245, 148, 48, 89, 110, 90, 236, 92, 86, 196, 103, 44, 70, 194, 135, 212, 178, 42, 39, 238, 73, 197, 244, 50, 29, 160, 55, 125, 225, 19]\n",
      "layer3.1.conv2 [9, 123, 130, 111, 155, 108, 100, 7, 8, 213, 127, 254, 250, 191, 188, 133, 16, 246, 56, 132, 88, 23, 24, 85, 209, 72, 235, 82, 229, 42, 228, 221, 146, 238, 186, 164]\n",
      "layer3.1.conv1 [32, 92, 162, 95, 50, 211, 201, 97, 54, 103, 235, 11, 152, 150, 149, 144, 142, 231, 137, 194, 229, 122, 227, 244, 225, 65, 188, 249, 187, 222, 221, 181, 73, 217, 75, 76]\n",
      "layer3.2.conv2 [196, 35, 79, 117, 149, 17, 108, 43, 166, 156, 82, 47, 157, 56, 131, 233, 190, 3, 73, 106, 99, 14, 34, 250, 109, 30, 37, 76, 176, 87, 241, 202, 112, 228, 234, 240]\n",
      "layer3.2.conv1 [167, 23, 24, 210, 216, 29, 153, 30, 51, 47, 105, 155, 181, 134, 56, 164, 99, 95, 243, 242, 20, 100, 161, 148, 191, 83, 97, 59, 212, 119, 192, 8, 1, 127, 156, 84]\n",
      "layer3.3.conv2 [35, 131, 190, 148, 146, 127, 124, 157, 37, 100, 247, 82, 76, 218, 161, 71, 26, 204, 34, 43, 211, 38, 52, 112, 183, 221, 46, 132, 171, 210, 145, 197, 220, 57, 207, 20]\n",
      "layer3.3.conv1 [219, 217, 58, 181, 79, 59, 214, 124, 9, 240, 195, 114, 189, 100, 254, 31, 213, 207, 99, 128, 144, 19, 252, 209, 41, 75, 227, 24, 188, 211, 40, 3, 71, 138, 81, 33]\n",
      "layer3.4.conv2 [41, 105, 242, 244, 42, 126, 169, 144, 19, 53, 79, 116, 210, 50, 252, 186, 35, 164, 150, 202, 21, 241, 165, 38, 193, 174, 84, 212, 222, 96, 179, 213, 138, 123, 149, 16]\n",
      "layer3.4.conv1 [21, 1, 168, 55, 100, 19, 6, 26, 164, 73, 10, 190, 192, 48, 153, 242, 204, 71, 99, 14, 20, 60, 199, 108, 183, 111, 101, 87, 110, 95, 165, 208, 43, 9, 193, 121]\n",
      "layer3.5.conv2 [203, 91, 143, 38, 94, 142, 221, 77, 215, 186, 183, 206, 239, 59, 137, 135, 82, 222, 219, 127, 0, 249, 3, 114, 8, 224, 105, 141, 81, 52, 16, 115, 29, 178, 163, 252]\n",
      "layer3.5.conv1 [16, 1, 3, 81, 203, 200, 190, 10, 249, 70, 95, 204, 126, 246, 29, 166, 164, 105, 112, 114, 251, 38, 48, 84, 199, 5, 133, 205, 197, 220, 33, 77, 100, 132, 153, 236]\n",
      "layer4.0.conv2 [160, 61, 284, 386, 371, 286, 365, 492, 65, 388, 383, 340, 12, 405, 111, 268, 78, 290, 409, 381, 231, 84, 269, 143, 192, 461, 326, 91, 238, 236, 244, 48, 245, 178, 177, 253, 272, 511, 60, 306, 230, 499, 319, 419, 17, 211, 400, 203, 50, 452, 163, 25, 204, 126, 274, 142, 453, 80, 156, 335, 379, 188, 127, 130, 354, 375, 157, 421, 38, 484, 22]\n",
      "layer4.0.conv1 [254, 316, 457, 467, 471, 268, 426, 143, 53, 314, 10, 383, 312, 124, 479, 15, 16, 34, 483, 309, 510, 189, 485, 487, 406, 410, 416, 501, 488, 132, 429, 326, 230, 238, 436, 349, 425, 500, 259, 12, 304, 241, 336, 508, 225, 329, 338, 203, 280, 227, 182, 31, 7, 8, 432, 55, 179, 219, 112, 253, 388, 128, 351, 232, 476, 431, 113, 220, 231, 300, 318]\n",
      "layer4.1.conv2 [280, 470, 2, 469, 126, 465, 464, 351, 355, 131, 228, 352, 134, 267, 459, 224, 223, 457, 18, 454, 448, 217, 214, 291, 249, 442, 205, 204, 251, 439, 30, 258, 202, 237, 475, 35, 36, 437, 196, 476, 40, 194, 428, 426, 480, 422, 46, 256, 48, 421, 299, 51, 185, 308, 54, 183, 310, 57, 58, 59, 60, 61, 179, 63, 178, 177, 172, 67, 493, 505, 170]\n",
      "layer4.1.conv1 [64, 192, 193, 194, 421, 422, 424, 7, 198, 9, 10, 426, 200, 427, 202, 203, 204, 17, 434, 206, 207, 435, 22, 436, 210, 25, 211, 27, 442, 29, 30, 31, 213, 214, 215, 35, 444, 217, 448, 450, 220, 41, 452, 43, 222, 45, 46, 47, 460, 49, 462, 51, 464, 465, 54, 470, 471, 229, 58, 472, 60, 231, 474, 233, 128, 65, 234, 475, 236, 477, 478]\n",
      "layer4.2.conv2 [0, 277, 275, 309, 367, 201, 315, 7, 8, 426, 243, 11, 425, 99, 419, 15, 417, 245, 381, 384, 270, 266, 328, 331, 188, 385, 26, 403, 187, 333, 125, 336, 394, 33, 183, 308, 508, 37, 295, 507, 294, 337, 302, 43, 502, 178, 213, 47, 219, 494, 176, 173, 440, 53, 54, 224, 285, 228, 284, 344, 169, 283, 62, 281, 235, 166, 469, 464, 348, 307, 70]\n",
      "layer4.2.conv1 [64, 257, 251, 447, 382, 5, 6, 7, 254, 255, 392, 380, 379, 394, 14, 15, 16, 396, 18, 19, 398, 376, 375, 407, 24, 410, 411, 415, 370, 29, 417, 367, 366, 418, 34, 35, 364, 423, 38, 424, 361, 82, 360, 359, 358, 357, 46, 427, 48, 49, 50, 428, 356, 431, 434, 355, 436, 440, 354, 59, 353, 61, 443, 445, 450, 65, 66, 67, 453, 69, 456]\n",
      "Pruning step: 1 multiply–accumulate (macs): 3068644758.0 number of parameters 19205218\n",
      "layer4.0.downsample.0 [829, 66, 906, 917, 1609, 601, 797, 7, 1006, 786, 608, 1037, 838, 1038, 840, 1210, 226, 1118, 492, 62, 597, 445, 1295, 1629, 1421, 228, 1557, 1461, 762, 411, 1540, 623, 45, 254, 336, 220, 20, 366, 1066, 37, 816, 596, 1031, 1356, 340, 1247, 260, 1722, 988, 459, 970, 70, 215, 853, 533, 1618, 1266, 122, 1242, 1462, 169, 1422, 1692, 1025, 1499, 1324, 308, 2, 1453, 1613, 804, 27, 107, 426, 1594, 1322, 1258, 1561, 83, 1397, 1184, 1595, 1449, 785, 396, 692, 1333, 132, 1056, 727, 118, 1010, 1743, 998, 1022, 288, 1490, 1697, 1648, 827, 739, 1141, 423, 1503, 1448, 1529, 1581, 85, 887, 1345, 581, 179, 415, 1315, 1683, 613, 359, 1055, 832, 103, 1642, 1624, 207, 1576, 1563, 1109, 1709, 405, 955, 639, 242, 63, 932, 1552, 40, 1658, 1238, 1689, 199, 106, 284, 1730, 766, 619, 1676, 1300, 1021, 1538, 1136, 82, 1097, 731, 1681, 1023, 1605, 875, 1539, 11, 1756, 539, 458, 80, 1194, 502, 980, 714, 1504, 1261, 1488, 645, 542, 94, 1623, 1531, 158, 10, 243, 281, 1519, 481, 1128, 111, 1759, 845, 127, 92, 377, 1214, 401, 441, 1606, 150, 90, 1471, 326, 1133, 1447, 1628, 453, 146, 472, 947, 248, 658, 1758, 188, 1699, 670, 1323, 1614, 1071, 1456, 835, 1076, 565, 884, 633, 523, 1190, 484, 1649, 1245, 1049, 95, 1039, 1219, 1587, 1705, 265, 264, 680, 1445, 1079, 948, 1054, 943, 1694, 1403, 920, 1502, 1703, 833, 1358, 198, 1186, 1657, 293, 1585, 820, 682, 414, 1679, 1459, 1157, 1746, 500, 1051, 182, 702, 1150, 1719, 1213, 615, 1704, 1061, 730, 1158, 1009, 1674, 869, 1532, 803, 1057, 457, 756, 1001, 1684, 677, 953, 599, 818, 1101]\n",
      "layer3.0.downsample.0 [199, 295, 768, 96, 176, 529, 83, 747, 324, 249, 808, 515, 424, 534, 55, 471, 328, 21, 40, 85, 78, 677, 132, 256, 614, 129, 628, 179, 19, 812, 142, 296, 34, 50, 603, 106, 68, 530, 4, 220, 292, 602, 444, 613, 860, 227, 146, 829, 79, 245, 453, 378, 377, 82, 406, 418, 838, 670, 24, 728, 398, 713, 472, 846, 59, 875, 84, 816, 538, 226, 535, 290, 593, 339, 454, 92, 137, 466, 430, 703, 413, 770, 194, 122, 684, 310, 695, 824, 524, 357, 157, 364, 468, 489, 449, 239, 585, 386, 286, 421, 862, 380, 419, 427, 751, 734, 422, 526, 152, 580, 207, 767, 107, 522, 802, 596, 494, 130, 124, 759, 798, 306, 14, 843, 408, 268, 23, 291, 273, 167, 190, 629, 658, 208, 228, 512, 52, 793, 625, 833, 288]\n",
      "layer2.0.downsample.0 [224, 34, 152, 99, 22, 198, 55, 290, 113, 122, 399, 191, 7, 431, 384, 355, 270, 61, 35, 383, 328, 357, 70, 386, 117, 426, 307, 236, 146, 94, 391, 395, 59, 427, 73, 102, 360, 159, 379, 154, 199, 25, 344, 172, 119, 404, 334, 170, 309, 370, 12, 302, 436, 62, 39, 308, 240, 250, 416, 269, 194, 93, 253, 206, 63, 52, 324, 365, 412, 136]\n",
      "layer1.0.downsample.0 [88, 167, 144, 7, 185, 25, 117, 165, 126, 119, 86, 64, 46, 175, 47, 154, 145, 50, 207, 26, 95, 174, 67, 4, 57, 213, 194, 162, 177, 148, 89, 21, 152, 212, 211]\n",
      "conv1 [43, 2, 26, 31, 27, 17, 28, 3, 51]\n",
      "layer1.0.conv2 [22, 28, 38, 43, 13, 6, 37, 26, 34]\n",
      "layer1.0.conv1 [42, 40, 39, 36, 19, 18, 43, 49, 30]\n",
      "layer1.1.conv2 [26, 48, 23, 49, 16, 10, 18, 1, 40]\n",
      "layer1.1.conv1 [36, 25, 28, 32, 14, 33, 38, 18, 5]\n",
      "layer1.2.conv2 [36, 49, 43, 25, 5, 17, 51, 14, 52]\n",
      "layer1.2.conv1 [10, 2, 50, 54, 49, 46, 36, 1, 9]\n",
      "layer2.0.conv2 [0, 99, 95, 94, 11, 10, 97, 76, 83, 41, 63, 20, 101, 109, 34, 88, 54, 27]\n",
      "layer2.0.conv1 [95, 48, 104, 85, 88, 89, 67, 3, 100, 17, 86, 19, 98, 49, 106, 45, 94, 40]\n",
      "layer2.1.conv2 [75, 105, 72, 82, 87, 92, 25, 89, 76, 5, 1, 41, 66, 95, 38, 68, 7, 74]\n",
      "layer2.1.conv1 [95, 51, 24, 28, 39, 20, 99, 11, 66, 88, 48, 61, 75, 100, 25, 14, 13, 85]\n",
      "layer2.2.conv2 [68, 42, 38, 74, 31, 36, 80, 4, 104, 47, 102, 16, 107, 85, 14, 57, 101, 93]\n",
      "layer2.2.conv1 [2, 106, 47, 40, 9, 93, 21, 101, 43, 54, 60, 52, 84, 95, 67, 100, 39, 12]\n",
      "layer2.3.conv2 [17, 93, 36, 50, 94, 48, 0, 92, 6, 5, 95, 39, 55, 109, 38, 43, 80, 60]\n",
      "layer2.3.conv1 [48, 15, 100, 0, 2, 10, 84, 37, 52, 61, 12, 34, 90, 82, 89, 21, 19, 32]\n",
      "layer3.0.conv2 [133, 76, 185, 39, 54, 91, 146, 19, 165, 104, 29, 213, 194, 63, 132, 157, 216, 11, 47, 184, 7, 52, 218, 114, 85, 83, 122, 99, 81, 35, 87, 100, 56, 102, 110]\n",
      "layer3.0.conv1 [107, 133, 46, 28, 129, 71, 79, 179, 218, 1, 115, 93, 213, 212, 125, 104, 165, 149, 5, 111, 67, 141, 112, 100, 148, 192, 204, 216, 164, 29, 8, 128, 145, 174, 73]\n",
      "layer3.1.conv2 [49, 200, 190, 41, 144, 20, 141, 65, 78, 112, 111, 129, 46, 32, 47, 132, 98, 177, 163, 84, 179, 193, 31, 14, 138, 76, 88, 152, 186, 63, 187, 93, 39, 40, 6]\n",
      "layer3.1.conv1 [69, 80, 190, 71, 77, 145, 153, 41, 39, 152, 151, 144, 118, 12, 147, 26, 187, 175, 168, 212, 20, 38, 120, 27, 14, 207, 35, 136, 116, 32, 34, 95, 211, 198, 124]\n",
      "layer3.2.conv2 [130, 68, 109, 128, 16, 86, 159, 34, 98, 26, 39, 155, 9, 117, 168, 210, 56, 76, 153, 143, 6, 74, 10, 144, 33, 7, 82, 75, 110, 88, 166, 48, 35, 102, 96]\n",
      "layer3.2.conv1 [165, 24, 122, 43, 51, 159, 202, 177, 96, 153, 83, 124, 147, 6, 172, 211, 197, 0, 7, 184, 146, 136, 175, 151, 110, 160, 21, 123, 60, 35, 173, 16, 121, 84, 81]\n",
      "layer3.3.conv2 [104, 160, 72, 128, 196, 144, 184, 92, 181, 17, 185, 148, 127, 167, 24, 14, 77, 201, 35, 106, 58, 130, 143, 156, 173, 171, 61, 145, 86, 166, 89, 96, 97, 191, 214]\n",
      "layer3.3.conv1 [105, 137, 94, 146, 50, 169, 18, 63, 129, 210, 36, 134, 175, 203, 100, 13, 174, 178, 53, 173, 80, 92, 159, 14, 170, 106, 153, 60, 182, 194, 43, 70, 171, 62, 8]\n",
      "layer3.4.conv2 [102, 75, 48, 153, 12, 17, 126, 199, 186, 61, 171, 38, 170, 168, 160, 30, 103, 179, 210, 45, 33, 80, 155, 207, 89, 46, 212, 36, 157, 188, 119, 169, 211, 203, 25]\n",
      "layer3.4.conv1 [52, 6, 19, 192, 98, 117, 205, 38, 189, 176, 99, 35, 164, 196, 163, 84, 5, 218, 167, 169, 43, 10, 58, 31, 199, 61, 120, 64, 30, 24, 217, 170, 12, 93, 27]\n",
      "layer3.5.conv2 [81, 39, 67, 110, 126, 25, 46, 42, 180, 129, 111, 35, 78, 205, 119, 103, 15, 45, 210, 133, 194, 130, 134, 143, 50, 139, 74, 112, 47, 191, 214, 161, 55, 131, 170]\n",
      "layer3.5.conv1 [215, 114, 64, 218, 185, 58, 22, 46, 49, 150, 78, 17, 32, 164, 178, 212, 77, 2, 190, 6, 48, 93, 133, 12, 170, 106, 31, 193, 8, 92, 9, 151, 186, 119, 5]\n",
      "layer4.0.conv2 [292, 31, 41, 101, 285, 89, 183, 74, 362, 258, 324, 156, 377, 261, 180, 56, 95, 388, 126, 417, 142, 242, 81, 124, 63, 392, 321, 228, 416, 135, 196, 256, 147, 79, 14, 358, 174, 249, 413, 229, 13, 425, 298, 221, 91, 203, 273, 166, 341, 331, 353, 303, 415, 185, 404, 37, 160, 219, 165, 302, 62, 195, 283, 233, 138, 410, 12, 144, 141, 46]\n",
      "layer4.0.conv1 [12, 84, 411, 40, 356, 110, 158, 345, 102, 205, 95, 90, 387, 199, 368, 369, 222, 97, 248, 140, 18, 389, 191, 157, 27, 129, 143, 207, 223, 0, 255, 293, 286, 208, 250, 408, 277, 407, 259, 412, 415, 100, 168, 263, 257, 170, 162, 172, 103, 397, 264, 402, 32, 10, 74, 228, 358, 49, 131, 1, 73, 147, 429, 22, 343, 314, 305, 149, 179, 9]\n",
      "layer4.1.conv2 [319, 340, 302, 105, 300, 299, 103, 285, 343, 348, 135, 102, 352, 326, 325, 133, 324, 281, 99, 128, 318, 56, 317, 279, 124, 58, 59, 87, 273, 265, 101, 71, 79, 74, 142, 149, 436, 143, 338, 147, 69, 269, 399, 192, 3, 118, 167, 413, 219, 26, 97, 221, 66, 226, 335, 94, 81, 234, 418, 247, 283, 28, 11, 306, 7, 329, 400, 225, 189, 166]\n",
      "layer4.1.conv1 [55, 261, 259, 327, 258, 256, 328, 134, 133, 132, 194, 329, 196, 128, 127, 334, 199, 335, 286, 245, 121, 241, 239, 163, 238, 208, 343, 237, 119, 233, 118, 283, 117, 228, 115, 345, 216, 278, 217, 227, 277, 222, 274, 437, 436, 347, 112, 435, 111, 49, 50, 51, 52, 353, 428, 273, 427, 57, 426, 272, 424, 61, 62, 63, 267, 165, 423, 420, 419, 70]\n",
      "layer4.2.conv2 [134, 140, 66, 70, 388, 78, 299, 305, 308, 312, 144, 142, 3, 153, 37, 57, 85, 296, 398, 26, 94, 248, 228, 376, 350, 342, 86, 249, 79, 336, 333, 313, 419, 253, 173, 222, 243, 139, 200, 412, 224, 378, 73, 294, 300, 82, 9, 269, 14, 30, 135, 343, 136, 115, 407, 356, 438, 246, 90, 6, 55, 10, 87, 291, 218, 62, 437, 169, 247, 240]\n",
      "layer4.2.conv1 [55, 265, 304, 303, 180, 181, 182, 301, 256, 300, 299, 186, 250, 188, 189, 249, 248, 192, 193, 247, 298, 196, 245, 158, 244, 297, 199, 200, 293, 162, 202, 291, 204, 290, 275, 289, 208, 209, 210, 211, 212, 288, 229, 168, 282, 280, 224, 272, 221, 439, 173, 435, 52, 53, 54, 269, 56, 434, 433, 431, 60, 428, 62, 63, 64, 65, 66, 67, 68, 427]\n",
      "Pruning step: 2 multiply–accumulate (macs): 2180119276.0 number of parameters 13817385\n",
      "layer4.0.downsample.0 [185, 1030, 498, 208, 1362, 852, 956, 1167, 1082, 1283, 1115, 449, 966, 997, 286, 1323, 423, 864, 961, 972, 116, 97, 683, 403, 1132, 1336, 924, 1116, 909, 1394, 1424, 774, 1066, 495, 732, 946, 34, 952, 913, 473, 487, 448, 433, 300, 377, 726, 516, 1358, 827, 529, 1212, 35, 840, 439, 1110, 1200, 508, 1322, 301, 386, 1320, 996, 85, 320, 1244, 1142, 1232, 652, 1345, 257, 2, 1015, 54, 680, 231, 1062, 413, 571, 1307, 551, 1366, 143, 1227, 697, 1177, 1042, 190, 225, 786, 633, 30, 835, 214, 728, 418, 1474, 165, 740, 734, 417, 315, 1023, 699, 1262, 1453, 1265, 202, 669, 623, 829, 1457, 1103, 679, 655, 883, 146, 592, 238, 317, 890, 932, 805, 1380, 42, 611, 842, 1083, 1377, 870, 485, 1013, 476, 52, 836, 862, 604, 582, 400, 1063, 1325, 541, 578, 1364, 552, 9, 221, 1064, 1050, 160, 1287, 1196, 232, 1245, 1168, 279, 288, 918, 230, 1233, 268, 768, 333, 1057, 1280, 1312, 1346, 986, 294, 390, 617, 666, 589, 20, 1388, 371, 1026, 933, 450, 204, 1199, 1471, 1162, 591, 40, 207, 242, 391, 959, 1121, 1100, 366, 971, 405, 10, 793, 1229, 628, 213, 526, 605, 1069, 228, 74, 91, 1151, 295, 1279, 336, 747, 426, 141, 1172, 1355, 316, 150, 1216, 815, 1378, 1014, 1313, 1089, 849, 1479, 479, 6, 1202, 714, 1226, 530, 636, 1140, 1257, 456, 28, 43, 1123, 889, 1297, 162, 282, 945, 878, 335, 816, 1385, 1068, 1117, 749, 1237, 1218, 1417, 81, 686, 355, 460, 1240, 735, 654, 1146, 84, 856, 723, 1460, 305, 1459, 1065, 616, 1034, 517, 1096, 256, 1047, 314, 41, 798, 858, 364, 813, 1465, 1426, 283]\n",
      "layer3.0.downsample.0 [347, 227, 690, 716, 69, 109, 87, 557, 571, 663, 118, 425, 554, 642, 137, 85, 230, 130, 605, 740, 58, 378, 474, 238, 637, 255, 586, 186, 669, 299, 271, 451, 476, 277, 116, 455, 581, 639, 47, 210, 445, 374, 394, 27, 436, 498, 721, 541, 481, 515, 409, 310, 699, 682, 608, 252, 161, 728, 548, 396, 325, 520, 416, 231, 31, 79, 38, 426, 370, 681, 666, 324, 437, 167, 707, 429, 237, 220, 152, 358, 638, 662, 648, 504, 177, 725, 188, 322, 106, 715, 266, 390, 537, 9, 360, 612, 162, 442, 221, 397, 279, 182, 357, 339, 514, 510, 131, 737, 509, 302, 164, 249, 148, 629, 163, 574, 340, 658, 228, 268, 194, 159, 349, 392, 287, 490, 625, 28, 8, 597, 306, 313, 127, 402, 423, 469, 420, 125, 556, 680, 595]\n",
      "layer2.0.downsample.0 [251, 32, 346, 361, 134, 321, 192, 278, 296, 328, 254, 364, 70, 213, 280, 338, 66, 231, 25, 236, 359, 349, 235, 233, 128, 175, 8, 281, 312, 292, 180, 2, 279, 140, 73, 181, 209, 40, 74, 31, 203, 106, 139, 65, 18, 162, 206, 263, 138, 160, 221, 122, 271, 244, 205, 148, 370, 158, 333, 78, 3, 187, 293, 188, 86, 302, 363, 33, 316, 93, 204]\n",
      "layer1.0.downsample.0 [3, 25, 152, 162, 56, 34, 47, 16, 163, 161, 112, 35, 40, 46, 67, 170, 121, 133, 65, 167, 32, 17, 173, 156, 49, 26, 115, 96, 9, 19, 160, 80, 24, 132, 114]\n",
      "conv1 [3, 9, 38, 29, 26, 22, 35, 19, 8]\n",
      "layer1.0.conv2 [10, 38, 24, 40, 19, 11, 21, 33, 44]\n",
      "layer1.0.conv1 [16, 8, 1, 4, 25, 41, 40, 28, 24]\n",
      "layer1.1.conv2 [33, 31, 1, 0, 37, 11, 44, 5, 45]\n",
      "layer1.1.conv1 [42, 14, 25, 29, 33, 28, 8, 9, 7]\n",
      "layer1.2.conv2 [1, 2, 24, 6, 0, 15, 44, 31, 39]\n",
      "layer1.2.conv1 [8, 34, 25, 17, 36, 28, 42, 44, 14]\n",
      "layer2.0.conv2 [62, 29, 8, 6, 18, 79, 14, 22, 70, 21, 87, 9, 13, 12, 20, 54, 25]\n",
      "layer2.0.conv1 [6, 75, 64, 9, 74, 76, 65, 87, 34, 41, 89, 12, 86, 78, 67, 40, 46]\n",
      "layer2.1.conv2 [53, 47, 48, 73, 3, 85, 5, 6, 50, 80, 37, 74, 61, 87, 40, 90, 78]\n",
      "layer2.1.conv1 [54, 10, 88, 28, 40, 29, 69, 71, 84, 39, 85, 15, 2, 70, 45, 9, 13]\n",
      "layer2.2.conv2 [14, 88, 27, 36, 58, 68, 61, 17, 79, 64, 48, 63, 80, 46, 47, 90, 40]\n",
      "layer2.2.conv1 [85, 17, 58, 71, 49, 34, 28, 44, 89, 66, 88, 60, 48, 35, 29, 25, 67]\n",
      "layer2.3.conv2 [82, 25, 32, 36, 79, 5, 1, 80, 75, 15, 66, 28, 10, 57, 76, 0, 69]\n",
      "layer2.3.conv1 [83, 15, 43, 46, 10, 2, 69, 16, 29, 31, 19, 80, 39, 5, 30, 11, 87]\n",
      "layer3.0.conv2 [121, 77, 43, 176, 119, 80, 107, 22, 142, 129, 178, 75, 111, 181, 180, 151, 53, 145, 45, 32, 90, 6, 28, 19, 148, 133, 118, 65, 152, 57, 72, 66, 154, 85, 134]\n",
      "layer3.0.conv1 [95, 27, 164, 120, 152, 1, 26, 62, 184, 63, 55, 119, 6, 72, 21, 89, 155, 183, 44, 36, 28, 137, 96, 112, 67, 117, 50, 73, 107, 161, 59, 111, 179, 5, 103]\n",
      "layer3.1.conv2 [142, 135, 167, 175, 102, 162, 95, 179, 14, 133, 139, 9, 107, 67, 24, 77, 96, 128, 66, 89, 92, 106, 132, 39, 124, 50, 13, 97, 170, 171, 155, 60, 30, 118, 27]\n",
      "layer3.1.conv1 [172, 167, 132, 16, 147, 41, 163, 159, 175, 86, 58, 180, 4, 85, 76, 73, 96, 44, 66, 116, 113, 183, 125, 158, 11, 143, 27, 123, 72, 108, 32, 119, 19, 162, 22]\n",
      "layer3.2.conv2 [51, 107, 3, 71, 11, 125, 97, 113, 84, 179, 48, 154, 10, 57, 73, 67, 6, 150, 62, 20, 16, 124, 2, 72, 119, 81, 182, 118, 38, 112, 162, 166, 54, 22, 28]\n",
      "layer3.2.conv1 [169, 117, 21, 11, 12, 79, 98, 151, 37, 119, 114, 106, 4, 170, 126, 56, 13, 22, 49, 71, 73, 162, 17, 51, 107, 88, 54, 134, 123, 182, 124, 29, 133, 111, 113]\n",
      "layer3.3.conv2 [56, 184, 139, 123, 128, 37, 133, 124, 115, 40, 79, 145, 80, 94, 14, 97, 9, 137, 31, 112, 60, 47, 131, 161, 156, 104, 22, 88, 154, 33, 4, 28, 121, 165, 76]\n",
      "layer3.3.conv1 [140, 146, 135, 50, 25, 128, 127, 14, 42, 76, 156, 58, 63, 142, 52, 16, 59, 100, 2, 98, 179, 123, 23, 167, 68, 6, 99, 137, 48, 171, 153, 109, 119, 162, 131]\n",
      "layer3.4.conv2 [66, 63, 13, 175, 84, 44, 97, 16, 48, 161, 49, 181, 132, 134, 35, 140, 119, 98, 52, 41, 21, 94, 4, 162, 8, 153, 116, 146, 123, 81, 152, 15, 144, 60, 46]\n",
      "layer3.4.conv1 [7, 94, 53, 146, 28, 129, 180, 5, 101, 158, 86, 159, 71, 23, 110, 66, 131, 75, 133, 57, 178, 69, 148, 19, 4, 182, 104, 89, 90, 67, 58, 81, 143, 150, 144]\n",
      "layer3.5.conv2 [141, 122, 133, 165, 140, 150, 57, 52, 136, 36, 2, 23, 149, 126, 84, 139, 75, 46, 146, 81, 24, 80, 130, 135, 45, 3, 66, 74, 51, 85, 114, 79, 151, 125, 30]\n",
      "layer3.5.conv1 [103, 60, 148, 115, 35, 139, 15, 33, 27, 16, 106, 2, 163, 72, 18, 162, 26, 55, 165, 179, 62, 140, 146, 8, 174, 49, 54, 9, 149, 5, 100, 28, 19, 182, 108]\n",
      "layer4.0.conv2 [83, 223, 271, 152, 366, 306, 1, 57, 345, 23, 207, 303, 34, 276, 81, 79, 226, 212, 18, 249, 30, 145, 229, 36, 26, 176, 351, 28, 360, 247, 144, 37, 214, 243, 364, 121, 225, 253, 233, 252, 305, 113, 155, 268, 312, 12, 321, 299, 122, 160, 264, 278, 10, 42, 370, 318, 162, 348, 332, 85, 149, 359, 195, 147, 62, 302, 254, 173, 58, 350, 117]\n",
      "layer4.0.conv1 [227, 279, 160, 181, 292, 86, 132, 348, 257, 201, 334, 304, 281, 163, 255, 109, 82, 28, 272, 124, 243, 297, 345, 184, 195, 284, 85, 79, 341, 4, 187, 237, 321, 56, 330, 20, 318, 30, 87, 125, 40, 367, 180, 326, 258, 151, 44, 105, 336, 121, 166, 128, 70, 147, 366, 266, 325, 244, 338, 171, 194, 333, 23, 253, 131, 313, 359, 250, 110, 287, 116]\n",
      "layer4.1.conv2 [265, 272, 293, 191, 280, 344, 122, 72, 175, 136, 9, 53, 119, 207, 358, 24, 269, 261, 195, 216, 25, 208, 254, 124, 289, 16, 342, 21, 66, 197, 152, 132, 285, 144, 7, 364, 246, 91, 114, 206, 253, 170, 81, 173, 354, 30, 182, 89, 29, 151, 97, 50, 35, 200, 12, 202, 174, 166, 235, 320, 98, 250, 45, 115, 317, 180, 334, 140, 310, 107, 65]\n",
      "layer4.1.conv1 [128, 66, 78, 118, 271, 270, 84, 122, 267, 123, 87, 89, 312, 266, 72, 264, 262, 130, 260, 132, 133, 309, 91, 135, 136, 307, 138, 96, 253, 252, 354, 353, 299, 250, 115, 61, 243, 63, 242, 257, 298, 99, 31, 361, 68, 56, 190, 302, 368, 219, 40, 106, 140, 37, 71, 224, 334, 103, 15, 313, 85, 179, 150, 171, 181, 208, 55, 215, 187, 81, 259]\n",
      "layer4.2.conv2 [102, 119, 157, 307, 107, 32, 234, 260, 274, 4, 348, 43, 321, 231, 174, 25, 345, 306, 167, 188, 215, 364, 258, 118, 88, 159, 330, 287, 326, 2, 83, 130, 370, 38, 361, 124, 27, 65, 262, 339, 6, 206, 178, 61, 224, 14, 51, 40, 222, 117, 252, 156, 78, 175, 99, 183, 300, 57, 41, 89, 249, 144, 268, 21, 68, 266, 137, 241, 251, 240, 291]\n",
      "layer4.2.conv1 [251, 351, 62, 352, 64, 65, 66, 67, 68, 354, 70, 71, 72, 359, 74, 363, 332, 77, 79, 76, 80, 82, 87, 88, 89, 91, 130, 94, 98, 253, 60, 101, 102, 250, 103, 249, 105, 221, 107, 125, 110, 246, 113, 114, 243, 115, 124, 315, 242, 323, 325, 326, 330, 334, 337, 339, 344, 57, 345, 349, 141, 240, 25, 199, 119, 208, 192, 28, 126, 302, 358]\n",
      "Pruning step: 3 multiply–accumulate (macs): 1447383287.0 number of parameters 9298230\n",
      "layer4.0.downsample.0 [77, 1110, 734, 178, 726, 930, 526, 239, 878, 872, 497, 694, 463, 1085, 1138, 880, 649, 638, 33, 502, 751, 1113, 220, 909, 572, 196, 1100, 621, 202, 144, 776, 943, 43, 806, 44, 64, 102, 9, 1143, 697, 946, 279, 1176, 1185, 698, 1019, 266, 36, 50, 950, 495, 274, 870, 998, 82, 94, 657, 992, 598, 387, 103, 215, 546, 1135, 863, 1013, 578, 825, 475, 458, 1196, 1084, 843, 301, 474, 643, 357, 585, 1007, 65, 429, 40, 646, 110, 810, 515, 824, 1133, 399, 576, 738, 1095, 993, 1195, 1131, 501, 265, 344, 1039, 805, 380, 329, 381, 588, 564, 752, 85, 554, 174, 907, 817, 211, 87, 921, 176, 1178, 684, 941, 316, 664, 803, 1078, 580, 291, 444, 996, 1129, 277, 1032, 1151, 661, 719, 981, 818, 1187, 197, 460, 302, 1027, 766, 911, 611, 866, 599, 206, 397, 431, 459, 1021, 453, 2, 1037, 1107, 790, 823, 1055, 472, 735, 1199, 561, 600, 513, 584, 1087, 820, 727, 417, 418, 46, 1076, 300, 1128, 222, 490, 15, 1154, 613, 8, 62, 437, 145, 812, 183, 278, 1156, 901, 979, 595, 765, 45, 844, 832, 440, 945, 745, 935, 267, 574, 436, 984, 716, 1161, 699, 306, 1194, 432, 592, 1012, 977, 130, 1025, 711, 944, 1030, 583, 896, 514, 187, 620, 626, 192, 217, 254, 345, 612, 920, 483, 807, 926, 342, 240, 398, 1179, 1093, 658, 777, 689, 499, 991, 750, 528, 159, 193, 391, 672, 821, 223, 757, 257, 16, 869, 1079, 983, 846, 386, 1193, 1003, 156, 622, 640, 98, 229, 479, 700, 12, 997, 614, 1020, 895, 631, 447, 1189, 489, 404, 1048, 332, 126, 1035, 90, 308, 617, 133]\n",
      "layer3.0.downsample.0 [54, 147, 14, 423, 34, 473, 547, 513, 582, 118, 30, 544, 344, 479, 309, 533, 407, 346, 256, 378, 19, 36, 146, 482, 21, 343, 334, 304, 175, 465, 392, 319, 507, 50, 589, 16, 584, 469, 485, 430, 29, 176, 97, 141, 324, 565, 452, 412, 512, 517, 18, 174, 267, 351, 327, 155, 91, 442, 558, 62, 79, 578, 286, 242, 224, 281, 590, 318, 577, 134, 204, 548, 282, 5, 413, 169, 188, 278, 528, 444, 15, 120, 51, 538, 115, 130, 221, 575, 489, 211, 509, 555, 86, 463, 316, 158, 240, 186, 472, 160, 493, 524, 61, 78, 373, 451, 199, 195, 385, 345, 235, 184, 94, 537, 73, 532, 183, 315, 595, 24, 193, 233, 382, 25, 202, 454, 409, 500, 229, 450, 436, 190, 333, 535, 265, 322, 102, 22, 17, 566, 196]\n",
      "layer2.0.downsample.0 [237, 202, 129, 233, 73, 59, 264, 283, 119, 126, 188, 169, 167, 15, 56, 107, 108, 117, 25, 3, 183, 137, 7, 277, 161, 230, 70, 155, 195, 251, 208, 44, 33, 259, 83, 133, 62, 239, 177, 76, 81, 94, 255, 71, 292, 140, 252, 227, 90, 249, 287, 40, 17, 214, 28, 1, 103, 98, 49, 47, 258, 130, 99, 164, 0, 178, 289, 75, 151, 273]\n",
      "layer1.0.downsample.0 [147, 143, 86, 96, 47, 87, 99, 49, 60, 124, 144, 45, 20, 139, 66, 68, 102, 91, 72, 126, 115, 21, 105, 145, 113, 13, 23, 78, 79, 50, 46, 77, 0, 129, 18]\n",
      "conv1 [20, 3, 31, 34, 22, 32, 17, 0, 27]\n",
      "layer1.0.conv2 [30, 22, 33, 17, 34, 27, 18, 2, 12]\n",
      "layer1.0.conv1 [22, 18, 35, 31, 14, 21, 17, 27, 26]\n",
      "layer1.1.conv2 [24, 0, 18, 26, 3, 1, 4, 29, 5]\n",
      "layer1.1.conv1 [17, 13, 1, 12, 32, 16, 3, 29, 9]\n",
      "layer1.2.conv2 [8, 31, 29, 20, 19, 0, 9, 36, 1]\n",
      "layer1.2.conv1 [34, 25, 20, 2, 0, 10, 18, 35, 1]\n",
      "layer2.0.conv2 [11, 5, 71, 47, 12, 63, 13, 32, 56, 64, 21, 8, 3, 67, 50, 52, 1, 31]\n",
      "layer2.0.conv1 [53, 8, 38, 7, 56, 39, 49, 66, 14, 4, 36, 37, 41, 63, 9, 15, 59, 43]\n",
      "layer2.1.conv2 [65, 72, 6, 39, 44, 53, 71, 59, 67, 0, 45, 36, 5, 51, 73, 24, 20, 57]\n",
      "layer2.1.conv1 [45, 19, 18, 34, 13, 74, 68, 56, 4, 53, 69, 28, 16, 37, 11, 3, 71, 65]\n",
      "layer2.2.conv2 [38, 0, 66, 26, 42, 3, 73, 70, 15, 49, 58, 2, 32, 24, 53, 59, 18, 14]\n",
      "layer2.2.conv1 [20, 12, 33, 69, 73, 27, 70, 37, 65, 47, 36, 25, 1, 58, 52, 50, 57, 13]\n",
      "layer2.3.conv2 [15, 25, 59, 9, 72, 23, 50, 7, 16, 37, 68, 20, 74, 41, 30, 1, 56, 39]\n",
      "layer2.3.conv1 [34, 24, 33, 26, 48, 60, 53, 67, 0, 32, 13, 52, 12, 56, 64, 11, 47, 35]\n",
      "layer3.0.conv2 [84, 9, 64, 68, 132, 38, 26, 89, 55, 52, 58, 40, 142, 116, 2, 115, 98, 97, 139, 71, 117, 94, 87, 19, 149, 15, 118, 27, 39, 41, 48, 107, 82, 85, 83]\n",
      "layer3.0.conv1 [20, 90, 111, 49, 77, 119, 81, 122, 103, 7, 87, 44, 63, 22, 0, 84, 33, 147, 96, 69, 145, 32, 53, 94, 140, 116, 95, 76, 71, 143, 25, 2, 133, 138, 120]\n",
      "layer3.1.conv2 [73, 33, 65, 117, 92, 103, 61, 0, 124, 59, 14, 11, 121, 69, 85, 67, 145, 132, 4, 40, 63, 114, 20, 6, 76, 64, 26, 34, 106, 45, 120, 27, 141, 101, 122]\n",
      "layer3.1.conv1 [63, 74, 99, 98, 131, 138, 109, 7, 120, 129, 17, 121, 139, 114, 42, 82, 144, 136, 97, 19, 5, 0, 9, 26, 73, 25, 30, 91, 54, 57, 149, 62, 105, 10, 100]\n",
      "layer3.2.conv2 [141, 125, 149, 53, 143, 112, 113, 60, 47, 83, 129, 29, 38, 61, 132, 26, 49, 101, 8, 98, 148, 11, 15, 86, 13, 95, 76, 84, 64, 82, 67, 136, 6, 130, 59]\n",
      "layer3.2.conv1 [117, 65, 13, 81, 149, 140, 64, 0, 32, 63, 141, 21, 12, 130, 4, 144, 67, 9, 50, 91, 45, 56, 95, 113, 59, 145, 118, 10, 112, 121, 38, 7, 139, 51, 119]\n",
      "layer3.3.conv2 [64, 120, 39, 11, 45, 32, 117, 21, 129, 75, 121, 26, 6, 55, 84, 78, 101, 93, 42, 22, 81, 122, 29, 146, 16, 144, 15, 25, 17, 47, 148, 46, 131, 71, 112]\n",
      "layer3.3.conv1 [146, 102, 8, 58, 115, 15, 70, 48, 79, 97, 32, 131, 93, 118, 105, 60, 110, 46, 142, 24, 10, 144, 26, 111, 30, 76, 35, 1, 106, 54, 72, 27, 3, 87, 0]\n",
      "layer3.4.conv2 [97, 45, 100, 8, 78, 96, 110, 87, 68, 60, 124, 138, 25, 36, 43, 136, 67, 127, 75, 145, 27, 131, 19, 6, 77, 144, 102, 69, 9, 111, 15, 128, 98, 40, 113]\n",
      "layer3.4.conv1 [36, 104, 87, 62, 82, 5, 65, 79, 118, 142, 137, 85, 91, 74, 126, 61, 40, 50, 83, 3, 146, 84, 35, 9, 101, 125, 141, 32, 97, 86, 103, 6, 71, 25, 135]\n",
      "layer3.5.conv2 [61, 100, 48, 4, 26, 17, 63, 79, 76, 123, 27, 3, 82, 32, 83, 139, 62, 21, 71, 6, 56, 65, 147, 7, 84, 36, 45, 125, 105, 35, 54, 128, 77, 132, 89]\n",
      "layer3.5.conv1 [55, 43, 86, 61, 14, 124, 115, 106, 72, 122, 83, 108, 100, 121, 5, 134, 135, 53, 30, 73, 147, 51, 112, 48, 0, 49, 138, 87, 60, 70, 17, 131, 145, 85, 76]\n",
      "layer4.0.conv2 [294, 225, 36, 220, 4, 86, 248, 197, 195, 189, 238, 117, 251, 280, 250, 203, 296, 211, 184, 153, 118, 132, 126, 73, 185, 144, 23, 163, 179, 139, 111, 161, 256, 142, 208, 156, 105, 138, 20, 27, 128, 92, 215, 51, 155, 38, 56, 112, 249, 98, 223, 226, 162, 102, 259, 71, 31, 108, 172, 32, 277, 240, 237, 78, 8, 127, 239, 192, 183, 109]\n",
      "layer4.0.conv1 [178, 266, 172, 117, 245, 271, 260, 135, 25, 292, 232, 229, 175, 125, 49, 281, 19, 250, 35, 10, 251, 110, 284, 118, 45, 72, 289, 286, 207, 34, 119, 234, 217, 273, 2, 109, 171, 239, 195, 15, 99, 22, 16, 241, 213, 27, 5, 197, 136, 187, 92, 220, 98, 224, 219, 209, 36, 272, 243, 112, 14, 191, 153, 204, 6, 162, 30, 8, 121, 275]\n",
      "layer4.1.conv2 [158, 128, 172, 185, 222, 220, 97, 69, 136, 291, 101, 96, 255, 118, 173, 68, 56, 113, 211, 129, 245, 283, 124, 138, 114, 130, 73, 165, 153, 196, 180, 2, 281, 232, 203, 156, 167, 60, 179, 210, 48, 15, 152, 200, 102, 218, 166, 161, 240, 290, 42, 276, 107, 287, 90, 177, 206, 154, 47, 76, 109, 5, 209, 122, 270, 199, 268, 265, 247, 120]\n",
      "layer4.1.conv1 [276, 32, 261, 102, 219, 100, 58, 190, 74, 29, 163, 277, 189, 54, 42, 146, 254, 70, 41, 294, 223, 69, 149, 62, 125, 144, 297, 98, 132, 21, 213, 85, 260, 299, 253, 173, 192, 216, 156, 8, 171, 258, 120, 200, 105, 129, 60, 53, 250, 244, 286, 298, 65, 236, 179, 241, 267, 197, 137, 77, 153, 296, 198, 90, 38, 115, 121, 64, 247, 248]\n",
      "layer4.2.conv2 [157, 243, 215, 149, 58, 80, 142, 89, 211, 169, 144, 75, 188, 49, 88, 125, 121, 72, 171, 292, 185, 230, 51, 189, 223, 26, 190, 175, 96, 247, 93, 91, 236, 242, 253, 92, 226, 183, 174, 177, 258, 147, 173, 251, 271, 197, 227, 284, 260, 276, 115, 132, 44, 109, 16, 295, 263, 123, 143, 39, 154, 246, 36, 279, 81, 244, 232, 201, 238, 18]\n",
      "layer4.2.conv1 [163, 73, 135, 175, 242, 147, 97, 62, 84, 10, 177, 204, 243, 217, 64, 149, 173, 275, 272, 130, 160, 23, 194, 170, 219, 214, 60, 285, 25, 38, 141, 104, 152, 17, 96, 258, 139, 239, 231, 203, 93, 5, 206, 75, 71, 267, 220, 298, 145, 142, 196, 279, 190, 86, 107, 138, 89, 103, 35, 34, 106, 123, 158, 293, 81, 288, 169, 254, 249, 20]\n",
      "Pruning step: 4 multiply–accumulate (macs): 860418456.0 number of parameters 5678189\n",
      "layer4.0.downsample.0 [536, 367, 17, 287, 504, 87, 68, 463, 359, 557, 440, 62, 919, 552, 485, 396, 239, 544, 11, 78, 30, 299, 501, 414, 917, 169, 875, 423, 469, 653, 841, 533, 75, 776, 179, 574, 756, 770, 354, 568, 492, 261, 35, 272, 210, 143, 717, 445, 435, 334, 270, 546, 480, 237, 4, 401, 898, 694, 826, 829, 579, 767, 345, 364, 110, 375, 304, 747, 625, 390, 853, 807, 632, 858, 235, 216, 576, 220, 754, 6, 159, 899, 821, 31, 48, 378, 46, 434, 152, 556, 215, 5, 918, 70, 418, 225, 439, 398, 49, 300, 204, 726, 604, 218, 422, 781, 66, 133, 339, 890, 247, 680, 863, 44, 874, 871, 753, 458, 812, 381, 909, 869, 553, 497, 177, 326, 575, 455, 305, 187, 761, 252, 676, 227, 606, 736, 605, 856, 460, 547, 503, 893, 138, 399, 665, 426, 733, 184, 425, 697, 715, 158, 903, 232, 238, 651, 344, 263, 309, 582, 172, 660, 810, 67, 507, 194, 615, 477, 18, 101, 775, 383, 545, 39, 467, 81, 808, 53, 3, 248, 565, 845, 147, 578, 156, 136, 783, 870, 887, 29, 603, 465, 206, 752, 60, 301, 737, 540, 211, 868, 640, 351, 780, 710, 908, 590, 652, 145, 0, 851, 16, 728, 198, 555, 43, 196, 409, 162, 525, 377, 188, 831, 368, 622, 317, 862, 26, 657, 860, 166, 595, 888, 683, 452, 13, 740, 677, 678, 372, 92, 119, 494, 190, 464, 815, 86, 358, 488, 905, 751, 562, 664, 259, 719, 734, 38, 285, 373, 236, 170, 347, 907, 308, 793, 161, 804, 571, 564, 850, 45, 298, 142, 670, 217, 174, 286, 27, 795, 548, 760, 649]\n",
      "layer3.0.downsample.0 [335, 436, 219, 215, 344, 424, 142, 239, 4, 439, 452, 290, 157, 193, 323, 110, 94, 362, 353, 8, 83, 418, 393, 9, 410, 459, 357, 238, 282, 343, 445, 359, 187, 210, 101, 121, 126, 15, 1, 305, 430, 248, 103, 6, 320, 399, 26, 115, 10, 348, 289, 174, 447, 341, 194, 133, 18, 98, 351, 109, 148, 329, 176, 441, 189, 51, 438, 123, 124, 206, 128, 208, 302, 283, 179, 113, 100, 48, 132, 39, 446, 266, 255, 82, 453, 177, 263, 106, 172, 218, 185, 84, 428, 363, 49, 138, 401, 457, 141, 223, 414, 276, 332, 225, 228, 294, 298, 214, 33, 226, 355, 389, 166, 241, 308, 227, 404, 183, 192, 280, 322, 181, 217, 337, 86, 71, 364, 260, 137, 434, 158, 297, 244, 43, 371, 3, 310, 433, 384, 233]\n",
      "layer2.0.downsample.0 [88, 105, 202, 140, 46, 219, 108, 106, 31, 104, 128, 177, 154, 37, 62, 79, 70, 145, 33, 151, 71, 7, 147, 41, 184, 134, 125, 136, 77, 170, 25, 93, 166, 130, 58, 111, 158, 113, 103, 187, 197, 11, 150, 188, 122, 194, 42, 21, 110, 1, 114, 85, 221, 60, 132, 15, 92, 13, 48, 107, 66, 47, 182, 153, 220, 176, 69, 169, 218, 157]\n",
      "layer1.0.downsample.0 [98, 16, 45, 48, 26, 23, 79, 68, 51, 94, 114, 39, 42, 30, 4, 103, 49, 53, 100, 75, 108, 36, 67, 20, 18, 111, 101, 27, 85, 110, 107, 66, 33, 81, 91]\n",
      "conv1 [1, 4, 12, 6, 23, 21, 17, 24]\n",
      "layer1.0.conv2 [1, 9, 21, 5, 12, 23, 2, 14]\n",
      "layer1.0.conv1 [26, 8, 4, 0, 15, 20, 22, 13]\n",
      "layer1.1.conv2 [23, 15, 5, 3, 27, 1, 21, 4]\n",
      "layer1.1.conv1 [2, 15, 22, 21, 6, 24, 7, 12]\n",
      "layer1.2.conv2 [7, 9, 25, 10, 19, 5, 13, 11]\n",
      "layer1.2.conv1 [20, 14, 23, 19, 17, 24, 27, 5]\n",
      "layer2.0.conv2 [16, 6, 2, 33, 34, 19, 3, 11, 10, 39, 48, 7, 42, 21, 13, 32, 41]\n",
      "layer2.0.conv1 [25, 56, 7, 36, 31, 53, 52, 40, 38, 34, 10, 44, 51, 20, 32, 48, 50]\n",
      "layer2.1.conv2 [56, 13, 33, 32, 24, 7, 44, 36, 37, 9, 2, 21, 10, 34, 46, 41, 53]\n",
      "layer2.1.conv1 [0, 1, 10, 15, 33, 30, 32, 54, 16, 2, 8, 21, 18, 44, 27, 19, 49]\n",
      "layer2.2.conv2 [0, 20, 17, 42, 28, 45, 52, 40, 36, 16, 21, 10, 34, 37, 25, 1, 8]\n",
      "layer2.2.conv1 [7, 17, 41, 27, 4, 28, 42, 15, 53, 48, 51, 54, 46, 25, 38, 24, 39]\n",
      "layer2.3.conv2 [17, 21, 48, 26, 18, 31, 24, 51, 50, 45, 22, 25, 0, 4, 32, 9, 5]\n",
      "layer2.3.conv1 [28, 24, 53, 46, 52, 6, 14, 23, 15, 7, 49, 13, 0, 47, 4, 10, 5]\n",
      "layer3.0.conv2 [102, 36, 92, 90, 58, 104, 70, 72, 81, 84, 113, 71, 48, 111, 46, 1, 68, 86, 26, 45, 6, 88, 12, 52, 100, 25, 108, 69, 0, 31, 56, 105, 54, 66, 101]\n",
      "layer3.0.conv1 [33, 93, 110, 3, 23, 82, 5, 66, 112, 106, 47, 26, 62, 25, 114, 73, 92, 101, 61, 40, 103, 18, 31, 104, 30, 24, 49, 4, 90, 20, 91, 57, 45, 76, 113]\n",
      "layer3.1.conv2 [45, 33, 93, 5, 8, 57, 10, 77, 36, 38, 90, 49, 16, 19, 92, 89, 60, 71, 88, 98, 39, 106, 113, 9, 58, 86, 74, 32, 105, 82, 54, 66, 30, 47, 20]\n",
      "layer3.1.conv1 [21, 42, 55, 104, 112, 111, 89, 92, 29, 103, 91, 38, 0, 106, 20, 35, 63, 3, 34, 105, 84, 71, 16, 66, 50, 107, 45, 58, 102, 87, 5, 80, 7, 9, 26]\n",
      "layer3.2.conv2 [24, 6, 88, 80, 15, 72, 43, 10, 61, 63, 5, 32, 20, 84, 71, 68, 77, 14, 106, 49, 108, 50, 4, 40, 56, 99, 62, 33, 30, 60, 39, 29, 64, 107, 12]\n",
      "layer3.2.conv1 [19, 3, 70, 65, 114, 60, 29, 43, 93, 108, 110, 63, 75, 90, 47, 85, 59, 41, 105, 34, 54, 24, 83, 1, 31, 20, 2, 109, 33, 17, 91, 64, 55, 16, 73]\n",
      "layer3.3.conv2 [47, 81, 106, 61, 80, 85, 9, 66, 84, 8, 23, 39, 107, 17, 71, 21, 72, 57, 3, 22, 59, 111, 43, 7, 28, 5, 108, 33, 0, 44, 25, 104, 56, 52, 87]\n",
      "layer3.3.conv1 [10, 71, 87, 22, 49, 67, 37, 52, 89, 96, 114, 16, 72, 13, 28, 40, 76, 97, 110, 29, 42, 109, 43, 75, 63, 59, 17, 30, 103, 82, 70, 90, 56, 3, 101]\n",
      "layer3.4.conv2 [94, 25, 73, 30, 89, 93, 36, 12, 55, 22, 21, 98, 4, 8, 90, 79, 1, 82, 64, 110, 50, 60, 41, 113, 6, 17, 34, 66, 49, 99, 100, 29, 14, 7, 76]\n",
      "layer3.4.conv1 [66, 97, 82, 104, 55, 62, 67, 78, 22, 27, 10, 48, 100, 106, 89, 5, 51, 87, 36, 61, 75, 4, 96, 58, 59, 76, 30, 7, 77, 64, 83, 8, 38, 1, 114]\n",
      "layer3.5.conv2 [48, 33, 42, 37, 84, 3, 54, 32, 79, 63, 103, 70, 83, 40, 19, 18, 109, 56, 4, 1, 74, 69, 6, 113, 44, 0, 66, 72, 90, 5, 67, 13, 10, 28, 68]\n",
      "layer3.5.conv1 [53, 5, 68, 84, 23, 106, 105, 63, 86, 3, 92, 80, 112, 65, 36, 56, 61, 41, 76, 89, 13, 100, 54, 18, 27, 64, 45, 22, 0, 38, 59, 71, 60, 110, 8]\n",
      "layer4.0.conv2 [187, 35, 178, 226, 7, 148, 223, 206, 84, 216, 51, 99, 190, 5, 59, 63, 170, 58, 82, 75, 4, 69, 15, 23, 45, 39, 140, 9, 192, 184, 175, 158, 88, 19, 157, 33, 30, 26, 96, 229, 89, 87, 139, 102, 108, 126, 156, 209, 110, 127, 83, 183, 199, 173, 161, 106, 166, 151, 100, 1, 214, 221, 65, 122, 129, 28, 197, 193, 168, 167]\n",
      "layer4.0.conv1 [214, 206, 172, 148, 121, 96, 201, 186, 10, 22, 4, 158, 62, 141, 98, 163, 89, 207, 147, 189, 123, 44, 190, 219, 145, 74, 17, 138, 196, 42, 193, 146, 143, 179, 199, 34, 92, 55, 178, 83, 216, 45, 36, 222, 102, 192, 47, 0, 33, 46, 128, 51, 211, 226, 149, 134, 113, 78, 73, 87, 221, 13, 183, 26, 159, 173, 35, 227, 165, 5]\n",
      "layer4.1.conv2 [101, 176, 21, 206, 54, 116, 201, 212, 146, 96, 170, 60, 31, 217, 11, 65, 166, 127, 97, 78, 141, 16, 219, 112, 46, 0, 158, 181, 120, 55, 58, 52, 178, 9, 113, 205, 194, 7, 38, 161, 71, 43, 162, 167, 47, 192, 145, 203, 168, 108, 114, 124, 99, 48, 131, 223, 81, 61, 195, 153, 134, 126, 184, 222, 157, 30, 34, 111, 86, 56]\n",
      "layer4.1.conv1 [95, 192, 170, 146, 210, 136, 64, 8, 191, 45, 208, 157, 179, 172, 150, 9, 203, 159, 46, 211, 151, 44, 16, 160, 69, 4, 84, 85, 177, 79, 186, 21, 40, 147, 188, 137, 98, 221, 67, 195, 30, 174, 202, 35, 2, 212, 28, 220, 39, 105, 82, 27, 106, 108, 93, 15, 119, 74, 201, 70, 117, 91, 11, 131, 155, 156, 161, 216, 193, 59]\n",
      "layer4.2.conv2 [224, 64, 14, 20, 92, 101, 199, 41, 43, 143, 145, 203, 131, 207, 163, 47, 79, 28, 57, 215, 91, 37, 181, 63, 99, 106, 49, 36, 118, 11, 182, 39, 22, 170, 221, 174, 50, 189, 5, 137, 219, 119, 160, 74, 193, 34, 185, 84, 72, 95, 62, 129, 13, 124, 56, 177, 104, 158, 48, 94, 25, 27, 141, 146, 51, 190, 24, 132, 3, 59]\n",
      "layer4.2.conv1 [29, 44, 229, 116, 190, 145, 220, 147, 162, 208, 3, 184, 119, 63, 111, 167, 95, 139, 81, 36, 164, 69, 118, 40, 11, 16, 80, 227, 175, 129, 128, 23, 5, 103, 182, 72, 59, 120, 55, 123, 150, 39, 214, 125, 7, 131, 43, 124, 109, 13, 8, 90, 177, 146, 224, 115, 199, 28, 24, 97, 50, 102, 34, 140, 176, 222, 4, 98, 213, 107]\n",
      "Pruning step: 5 multiply–accumulate (macs): 435361160.0 number of parameters 2950140\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 20, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(80, 160, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=640, out_features=1000, bias=True)\n",
      ")\n",
      "Pruning sparsity: 0.75\n",
      "layer4.0.downsample.0 [955, 1880, 2, 675, 1158, 275, 1292, 991, 100, 898, 1288, 167, 12, 80, 1542, 619, 1993, 831, 968, 1592, 1510, 854, 1748, 468, 327, 108, 1530, 1126, 286, 1099, 617, 1427, 93, 1645, 1201, 1193, 338, 653, 143, 605, 112, 1810, 2046, 1492, 61, 2035, 616, 1143, 351, 1464, 751, 16, 1344, 1144, 892, 153, 794, 1568, 828, 1555, 218, 950, 1850, 715, 560, 1999, 1051, 305, 833, 1743, 861, 1477, 1262, 757, 1888, 1496, 309, 1257, 362, 1156, 1056, 533, 158, 1819, 1906, 416, 456, 220, 1349, 1619, 1941, 307, 1326, 1532, 1980, 585, 2003, 204, 839, 449, 301, 195, 1749, 1154, 1932, 526, 975, 1718, 1441, 2020, 685, 1406, 415, 1221, 1898, 32, 1958, 695, 1055, 2040, 382, 1595, 1843, 563, 1077, 1253, 1929, 1460, 663, 296, 497, 447, 427, 207, 48, 1444, 273, 929, 583, 77, 241, 660, 570, 1829, 1125, 1817, 1219, 1312, 1093, 194, 1139, 581, 622, 1428, 1014, 1341, 7, 478, 706, 331, 1691, 107, 1412, 1070, 801, 743, 1608, 734, 1192, 1270, 1211, 771, 863, 1600, 1973, 1598, 610, 1318, 1820, 472, 94, 1974, 11, 66, 895, 486, 448, 1770, 272, 1692, 474, 83, 1036, 479, 1839, 910, 1301, 1357, 1802, 1693, 1889, 1887, 1676, 293, 119, 1670, 1437, 279, 709, 1167, 1347, 1804, 1673, 809, 128, 1537, 937, 687, 1338, 1953, 54, 1429, 121, 1685, 1554, 868, 247, 202, 96, 1081, 73, 2042, 144, 294, 461, 683, 140, 974, 319, 412, 453, 1879, 763, 357, 500, 722, 694, 1658, 353, 1832, 916, 1996, 302, 1223, 721, 1229, 70, 1448, 1172, 1106, 1032, 1711, 1930, 1699, 1314, 1369, 1757, 285, 1046, 227, 290, 712, 1003, 1864, 1646, 673, 1848, 1883, 592, 1659, 1637, 1426, 1050, 1064, 1800, 1803, 1146, 1602, 1863, 1705, 1925, 726, 226, 1736, 1469, 287, 1366, 1203, 1625, 437, 1474, 1968, 482, 1775, 1269, 168, 2041, 325]\n",
      "layer3.0.downsample.0 [962, 1018, 853, 486, 1023, 197, 170, 657, 759, 544, 491, 412, 303, 803, 500, 96, 501, 91, 1017, 18, 644, 980, 778, 923, 595, 51, 60, 729, 748, 388, 38, 83, 741, 685, 390, 311, 444, 514, 511, 487, 609, 728, 590, 123, 194, 906, 966, 662, 151, 105, 45, 928, 149, 927, 656, 482, 716, 352, 1011, 419, 744, 825, 329, 767, 468, 873, 709, 536, 475, 800, 365, 836, 589, 325, 407, 786, 747, 772, 619, 556, 683, 92, 701, 604, 16, 371, 541, 1022, 202, 732, 494, 706, 166, 776, 766, 205, 647, 956, 610, 972, 801, 417, 919, 576, 297, 132, 298, 426, 826, 985, 86, 93, 534, 37, 192, 620, 579, 99, 223, 543, 824, 908, 331, 78, 424, 533, 478, 14, 553, 72, 457, 936, 118, 114, 900, 924, 433, 863, 106, 340, 274, 156, 886, 941, 63, 977, 678, 199, 665, 937, 933, 4, 376, 909]\n",
      "layer2.0.downsample.0 [246, 387, 176, 404, 243, 34, 412, 347, 163, 53, 100, 424, 11, 24, 0, 114, 495, 326, 43, 98, 33, 363, 438, 207, 371, 166, 372, 85, 149, 509, 184, 311, 65, 328, 188, 361, 379, 487, 353, 192, 309, 147, 133, 81, 442, 66, 465, 382, 102, 10, 307, 96, 339, 483, 58, 473, 485, 285, 40, 335, 260, 269, 279, 229, 72, 504, 139, 60, 86, 151, 446, 381, 350, 82, 222, 494, 312]\n",
      "layer1.0.downsample.0 [144, 77, 108, 214, 150, 112, 58, 103, 131, 233, 156, 29, 235, 0, 31, 225, 10, 196, 231, 36, 245, 92, 63, 78, 97, 69, 68, 168, 60, 218, 21, 26, 105, 135, 148, 113, 54, 195, 204]\n",
      "conv1 [13, 44, 42, 52, 57, 31, 11, 59, 48, 58]\n",
      "layer1.0.conv2 [0, 1, 19, 22, 61, 9, 60, 59, 14, 28]\n",
      "layer1.0.conv1 [33, 1, 27, 60, 38, 7, 58, 35, 56, 49]\n",
      "layer1.1.conv2 [45, 6, 17, 25, 44, 41, 38, 10, 30, 40]\n",
      "layer1.1.conv1 [47, 56, 2, 45, 4, 19, 43, 38, 55, 9]\n",
      "layer1.2.conv2 [11, 7, 57, 51, 4, 8, 24, 18, 43, 50]\n",
      "layer1.2.conv1 [2, 39, 49, 52, 45, 57, 63, 53, 19, 33]\n",
      "layer2.0.conv2 [35, 90, 119, 69, 29, 110, 51, 4, 101, 12, 61, 53, 113, 0, 54, 115, 99, 120, 32, 111]\n",
      "layer2.0.conv1 [92, 112, 63, 89, 104, 68, 8, 66, 110, 61, 2, 14, 121, 122, 77, 86, 12, 5, 102, 101]\n",
      "layer2.1.conv2 [9, 93, 109, 26, 46, 29, 54, 10, 77, 100, 121, 120, 38, 126, 30, 94, 122, 112, 96, 84]\n",
      "layer2.1.conv1 [1, 69, 3, 83, 5, 111, 76, 63, 29, 58, 28, 14, 102, 108, 112, 118, 56, 59, 79, 62]\n",
      "layer2.2.conv2 [29, 56, 39, 18, 101, 34, 12, 54, 86, 125, 22, 75, 43, 2, 82, 60, 32, 47, 35, 70]\n",
      "layer2.2.conv1 [63, 38, 120, 117, 112, 75, 6, 102, 88, 76, 40, 12, 46, 105, 107, 124, 74, 67, 123, 17]\n",
      "layer2.3.conv2 [127, 124, 36, 0, 17, 113, 67, 76, 57, 21, 77, 95, 8, 105, 106, 37, 19, 114, 3, 42]\n",
      "layer2.3.conv1 [74, 6, 114, 52, 9, 120, 79, 23, 49, 58, 105, 37, 30, 4, 13, 2, 68, 119, 127, 33]\n",
      "layer3.0.conv2 [141, 2, 35, 4, 207, 116, 248, 250, 157, 54, 222, 232, 133, 106, 152, 13, 247, 151, 221, 194, 150, 160, 211, 115, 60, 113, 254, 127, 219, 192, 199, 136, 240, 43, 111, 95, 126, 226, 149]\n",
      "layer3.0.conv1 [148, 4, 48, 139, 220, 90, 245, 254, 110, 134, 136, 18, 196, 194, 103, 70, 44, 1, 236, 86, 55, 89, 39, 225, 197, 92, 125, 152, 42, 19, 135, 244, 27, 126, 50, 29, 95, 83, 238]\n",
      "layer3.1.conv2 [100, 228, 146, 72, 254, 108, 155, 7, 8, 191, 111, 221, 24, 133, 132, 123, 16, 42, 127, 85, 229, 235, 246, 23, 250, 130, 188, 88, 209, 56, 82, 164, 74, 57, 238, 213, 186, 218, 231]\n",
      "layer3.1.conv1 [32, 97, 95, 92, 150, 56, 188, 165, 54, 201, 152, 11, 85, 13, 172, 173, 79, 103, 231, 77, 76, 75, 229, 194, 227, 65, 73, 181, 187, 225, 249, 222, 244, 221, 131, 142, 144, 149, 217]\n",
      "layer3.2.conv2 [196, 79, 149, 117, 35, 108, 43, 156, 157, 233, 47, 166, 56, 99, 30, 190, 87, 228, 34, 240, 17, 186, 250, 109, 14, 182, 73, 106, 3, 131, 82, 81, 241, 130, 37, 29, 45, 8, 234]\n",
      "layer3.2.conv1 [56, 1, 164, 181, 29, 210, 30, 51, 47, 167, 105, 134, 192, 99, 100, 242, 20, 148, 23, 24, 59, 155, 119, 196, 8, 153, 161, 243, 62, 97, 83, 127, 84, 95, 216, 0, 162, 236, 31]\n",
      "layer3.3.conv2 [131, 190, 35, 127, 148, 146, 100, 247, 37, 161, 46, 218, 34, 82, 169, 236, 197, 186, 112, 43, 157, 152, 71, 14, 217, 255, 221, 171, 38, 119, 132, 231, 210, 199, 181, 168, 145, 26, 76]\n",
      "layer3.3.conv1 [195, 181, 75, 19, 79, 214, 58, 41, 219, 59, 100, 240, 24, 124, 31, 254, 189, 213, 209, 44, 217, 180, 199, 33, 9, 193, 128, 200, 99, 227, 170, 81, 21, 114, 89, 84, 71, 144, 122]\n",
      "layer3.4.conv2 [144, 53, 41, 116, 244, 169, 242, 19, 165, 35, 126, 252, 50, 79, 186, 164, 105, 212, 150, 179, 20, 42, 213, 241, 16, 38, 149, 177, 117, 84, 195, 210, 138, 217, 207, 174, 86, 143, 21]\n",
      "layer3.4.conv1 [73, 26, 71, 55, 204, 10, 48, 99, 100, 108, 122, 199, 8, 87, 19, 21, 190, 111, 20, 164, 49, 1, 242, 76, 168, 6, 240, 60, 110, 104, 227, 193, 208, 28, 14, 65, 165, 39, 183]\n",
      "layer3.5.conv2 [186, 77, 91, 203, 94, 219, 221, 38, 59, 142, 143, 137, 105, 52, 206, 135, 127, 8, 222, 183, 82, 224, 163, 115, 239, 249, 93, 223, 126, 0, 114, 252, 215, 178, 48, 29, 248, 141, 119]\n",
      "layer3.5.conv1 [16, 1, 200, 3, 5, 203, 249, 166, 10, 153, 112, 190, 246, 251, 126, 204, 199, 70, 174, 84, 205, 114, 29, 220, 236, 77, 67, 132, 95, 250, 48, 222, 100, 33, 4, 91, 12, 81, 188]\n",
      "layer4.0.conv2 [335, 84, 238, 388, 61, 386, 383, 284, 492, 381, 163, 91, 12, 178, 231, 46, 48, 160, 378, 157, 192, 326, 272, 461, 268, 477, 269, 371, 365, 143, 78, 244, 35, 216, 65, 511, 111, 453, 286, 130, 126, 142, 17, 230, 422, 306, 60, 452, 203, 419, 25, 274, 290, 484, 319, 204, 506, 80, 499, 253, 188, 236, 285, 409, 267, 155, 109, 405, 22, 400, 50, 227, 165, 103, 454, 482, 494]\n",
      "layer4.0.conv1 [34, 485, 189, 488, 227, 230, 326, 487, 8, 426, 10, 314, 12, 457, 510, 15, 16, 55, 304, 309, 53, 416, 383, 338, 132, 467, 410, 471, 406, 405, 143, 268, 479, 316, 259, 219, 349, 18, 421, 312, 107, 124, 128, 229, 394, 182, 203, 328, 429, 351, 115, 251, 156, 445, 483, 284, 276, 388, 505, 413, 253, 215, 113, 500, 220, 235, 114, 432, 231, 436, 7, 252, 238, 100, 352, 420, 318]\n",
      "layer4.1.conv2 [40, 389, 223, 331, 183, 480, 217, 277, 482, 497, 505, 426, 12, 327, 214, 179, 118, 119, 18, 120, 122, 178, 177, 317, 131, 134, 172, 313, 169, 377, 280, 170, 32, 291, 376, 35, 36, 375, 144, 308, 162, 148, 299, 153, 202, 155, 46, 294, 163, 224, 370, 51, 369, 368, 54, 228, 229, 57, 58, 268, 60, 267, 237, 63, 248, 249, 251, 67, 258, 391, 403, 409, 421, 422, 355, 75, 76]\n",
      "layer4.1.conv1 [64, 189, 409, 412, 192, 193, 194, 7, 414, 9, 10, 11, 416, 418, 198, 421, 200, 17, 422, 19, 202, 203, 204, 424, 426, 25, 207, 27, 434, 29, 435, 31, 210, 211, 436, 35, 213, 442, 215, 444, 217, 448, 450, 452, 44, 45, 46, 47, 48, 49, 462, 51, 52, 222, 54, 463, 56, 464, 58, 465, 60, 467, 471, 228, 128, 65, 229, 472, 231, 69, 474, 233, 72, 73, 74, 75, 234]\n",
      "layer4.2.conv2 [0, 336, 333, 463, 281, 331, 469, 277, 8, 507, 425, 11, 80, 486, 502, 15, 99, 494, 105, 426, 201, 440, 213, 348, 125, 337, 26, 353, 188, 187, 219, 309, 32, 33, 270, 308, 307, 37, 359, 362, 266, 87, 367, 508, 92, 302, 46, 47, 294, 176, 173, 171, 54, 169, 166, 381, 160, 158, 62, 156, 178, 394, 285, 284, 70, 417, 243, 245, 441, 453, 283, 7, 384, 84, 295, 150, 4]\n",
      "layer4.2.conv1 [64, 267, 266, 3, 261, 5, 6, 238, 245, 246, 259, 248, 249, 239, 14, 15, 16, 258, 18, 19, 251, 257, 253, 254, 24, 255, 26, 507, 506, 29, 505, 504, 502, 33, 34, 499, 498, 37, 38, 497, 493, 492, 488, 486, 485, 483, 46, 479, 48, 49, 50, 478, 473, 471, 468, 466, 464, 57, 463, 460, 459, 61, 62, 457, 511, 269, 66, 67, 456, 69, 453, 450, 445, 444, 443, 440, 76]\n",
      "Pruning step: 1 multiply–accumulate (macs): 2977856940.0 number of parameters 18690753\n",
      "layer4.0.downsample.0 [854, 194, 567, 293, 768, 923, 586, 1433, 1695, 1449, 428, 1059, 1039, 1330, 1232, 120, 353, 579, 630, 1168, 522, 1102, 77, 906, 83, 1226, 591, 709, 326, 1495, 1297, 395, 1442, 1062, 252, 1633, 1508, 34, 1432, 1512, 1023, 1435, 348, 1660, 1510, 994, 104, 484, 725, 1498, 1583, 1006, 207, 1667, 472, 159, 1112, 806, 100, 1135, 957, 1614, 432, 1094, 1248, 643, 1008, 1186, 875, 519, 817, 1222, 246, 1590, 59, 1346, 140, 94, 808, 1084, 245, 1425, 350, 1013, 1034, 1499, 11, 1556, 328, 1659, 17, 857, 465, 1468, 836, 426, 1471, 1049, 1205, 95, 1088, 1706, 1016, 467, 974, 525, 1483, 749, 1673, 604, 1652, 769, 1705, 1605, 1541, 215, 624, 416, 1185, 75, 1521, 1466, 541, 898, 872, 1561, 679, 1649, 1584, 1625, 232, 98, 576, 1726, 1616, 1573, 636, 1618, 48, 1022, 1586, 941, 758, 1398, 1608, 1470, 1682, 666, 1110, 951, 1164, 929, 582, 681, 1562, 279, 8, 549, 1589, 607, 1183, 1009, 1376, 102, 563, 791, 1261, 655, 653, 309, 37, 486, 1141, 1195, 622, 399, 1375, 1733, 1105, 1427, 169, 1128, 569, 148, 708, 1277, 631, 1089, 1680, 1536, 1392, 261, 561, 1225, 213, 1675, 1437, 1054, 1693, 752, 1303, 1603, 1298, 674, 713, 557, 614, 716, 1124, 852, 437, 247, 1621, 386, 237, 1122, 743, 1092, 271, 1198, 1326, 1339, 1632, 1580, 434, 689, 407, 794, 481, 390, 1231, 1133, 584, 820, 1613, 1027, 1606, 993, 917, 10, 462, 202, 377, 1553, 264, 1044, 545, 615, 455, 672, 177, 464, 442, 323, 928, 1090, 498, 117, 1119, 111, 860, 846, 1410, 831, 427, 850, 1526, 1300, 337, 1275, 343, 18, 1665, 468, 1493, 124, 1519, 1116, 1438, 1681, 1730, 1539, 1404, 1719, 703, 1204, 99, 1246, 1161, 967, 422, 1284, 1338, 945, 275, 581, 497, 1734, 1448, 1701, 663, 1007, 1482, 776, 1373, 667, 939]\n",
      "layer3.0.downsample.0 [698, 277, 61, 83, 503, 816, 40, 82, 441, 753, 665, 103, 141, 231, 522, 515, 133, 616, 499, 426, 199, 73, 354, 411, 245, 712, 811, 410, 696, 862, 212, 833, 49, 413, 121, 757, 788, 543, 80, 512, 803, 727, 322, 286, 22, 126, 432, 723, 329, 93, 42, 568, 285, 21, 456, 442, 717, 573, 144, 283, 440, 317, 269, 755, 533, 300, 500, 591, 314, 270, 394, 107, 564, 218, 17, 279, 777, 759, 674, 302, 809, 654, 646, 191, 25, 281, 347, 691, 192, 481, 38, 407, 672, 401, 406, 81, 104, 786, 454, 386, 260, 849, 105, 119, 51, 367, 381, 469, 459, 32, 216, 219, 542, 77, 601, 658, 763, 831, 177, 250, 263, 617, 36, 240, 225, 771, 526, 514, 247, 181, 590, 172, 845, 510, 826, 524, 249, 613, 330, 47, 147, 450, 592, 268, 657, 223, 152, 353, 69, 232, 415, 765, 843, 404]\n",
      "layer2.0.downsample.0 [167, 201, 170, 215, 34, 57, 94, 394, 353, 379, 193, 386, 88, 323, 149, 339, 60, 381, 189, 7, 207, 165, 304, 117, 22, 108, 112, 366, 59, 140, 157, 423, 425, 282, 399, 375, 63, 351, 25, 303, 146, 363, 289, 97, 133, 114, 348, 407, 294, 319, 302, 336, 390, 337, 150, 51, 12, 21, 100, 29, 233, 148, 241, 120, 244, 130, 266, 247, 212, 427, 99, 396, 211, 421, 38, 75, 9]\n",
      "layer1.0.downsample.0 [164, 7, 204, 12, 93, 98, 116, 118, 144, 182, 153, 17, 26, 161, 208, 27, 66, 143, 19, 172, 57, 174, 50, 178, 85, 22, 65, 193, 3, 191, 209, 32, 125, 4, 38, 155, 55, 151]\n",
      "conv1 [2, 26, 31, 27, 3, 17, 28, 50, 45, 11]\n",
      "layer1.0.conv2 [27, 37, 36, 42, 13, 6, 33, 11, 25, 46]\n",
      "layer1.0.conv1 [19, 42, 40, 39, 36, 21, 18, 48, 4, 8]\n",
      "layer1.1.conv2 [16, 23, 47, 10, 38, 18, 48, 1, 2, 43]\n",
      "layer1.1.conv1 [12, 10, 37, 36, 35, 26, 29, 33, 19, 5]\n",
      "layer1.2.conv2 [29, 48, 33, 0, 2, 16, 17, 24, 4, 39]\n",
      "layer1.2.conv1 [10, 48, 50, 53, 36, 2, 9, 1, 12, 34]\n",
      "layer2.0.conv2 [2, 64, 19, 10, 7, 41, 15, 9, 34, 77, 54, 82, 61, 84, 26, 13, 95, 72, 23]\n",
      "layer2.0.conv1 [56, 85, 84, 104, 96, 48, 92, 73, 82, 86, 93, 83, 102, 50, 49, 51, 72, 7, 45]\n",
      "layer2.1.conv2 [25, 88, 54, 38, 86, 72, 41, 81, 91, 4, 1, 8, 59, 75, 101, 68, 66, 94, 56]\n",
      "layer2.1.conv1 [97, 20, 28, 39, 24, 74, 14, 11, 65, 48, 104, 87, 64, 84, 98, 35, 16, 25, 60]\n",
      "layer2.2.conv2 [42, 38, 36, 31, 92, 0, 103, 78, 4, 101, 50, 84, 16, 17, 77, 20, 14, 30, 94]\n",
      "layer2.2.conv1 [22, 20, 43, 47, 100, 52, 83, 95, 54, 72, 53, 93, 2, 99, 9, 12, 40, 59, 39]\n",
      "layer2.3.conv2 [5, 46, 94, 92, 80, 41, 98, 4, 82, 95, 87, 78, 90, 57, 7, 58, 35, 23, 0]\n",
      "layer2.3.conv1 [13, 35, 32, 98, 99, 10, 17, 59, 82, 53, 0, 80, 88, 30, 103, 50, 87, 81, 3]\n",
      "layer3.0.conv2 [182, 191, 39, 109, 162, 19, 143, 90, 84, 181, 52, 215, 29, 101, 80, 47, 210, 82, 75, 62, 98, 113, 7, 11, 86, 213, 96, 142, 99, 121, 55, 134, 63, 93, 53, 154, 130, 25]\n",
      "layer3.0.conv1 [149, 160, 66, 215, 131, 26, 161, 1, 209, 175, 71, 191, 127, 180, 135, 201, 120, 210, 143, 4, 98, 216, 189, 170, 90, 101, 60, 144, 85, 136, 123, 58, 205, 162, 79, 8, 7, 69]\n",
      "layer3.1.conv2 [7, 143, 97, 83, 21, 77, 131, 33, 162, 111, 140, 63, 42, 6, 186, 169, 176, 110, 15, 47, 75, 40, 194, 32, 48, 211, 87, 191, 41, 92, 137, 115, 154, 61, 199, 90, 94, 128]\n",
      "layer3.1.conv1 [186, 40, 38, 37, 47, 106, 142, 198, 181, 19, 76, 121, 116, 170, 140, 120, 31, 33, 204, 13, 133, 25, 98, 26, 195, 208, 144, 183, 154, 209, 182, 148, 163, 130, 115, 34, 212, 91]\n",
      "layer3.2.conv2 [8, 127, 169, 152, 164, 140, 73, 36, 3, 32, 153, 72, 9, 211, 13, 15, 90, 79, 83, 125, 45, 57, 58, 60, 151, 62, 14, 101, 33, 214, 195, 107, 2, 104, 96, 131, 31, 172]\n",
      "layer3.2.conv1 [121, 41, 143, 172, 119, 169, 200, 177, 195, 159, 129, 93, 14, 182, 174, 25, 20, 107, 141, 26, 156, 15, 134, 6, 150, 157, 55, 5, 43, 170, 79, 21, 180, 131, 80, 110, 61, 78]\n",
      "layer3.3.conv2 [74, 144, 129, 173, 170, 130, 63, 110, 45, 179, 79, 19, 176, 156, 9, 149, 152, 16, 35, 147, 186, 49, 187, 24, 161, 159, 184, 64, 151, 62, 53, 154, 7, 90, 169, 134, 165, 92]\n",
      "layer3.3.conv1 [206, 127, 62, 9, 116, 15, 199, 179, 172, 150, 214, 155, 142, 78, 162, 53, 90, 92, 1, 176, 147, 160, 144, 115, 3, 103, 29, 190, 135, 163, 18, 14, 170, 177, 34, 63, 196, 69]\n",
      "layer3.4.conv2 [60, 168, 47, 83, 57, 24, 164, 88, 172, 204, 12, 196, 101, 187, 17, 157, 166, 50, 207, 14, 29, 53, 97, 152, 150, 154, 118, 209, 32, 184, 182, 200, 76, 208, 68, 107, 167, 45]\n",
      "layer3.4.conv1 [34, 95, 96, 117, 37, 126, 160, 163, 5, 197, 194, 114, 79, 12, 186, 6, 65, 55, 166, 41, 143, 162, 29, 32, 168, 10, 23, 188, 7, 215, 210, 174, 172, 75, 90, 212, 120, 185]\n",
      "layer3.5.conv2 [73, 41, 129, 76, 178, 46, 80, 192, 168, 132, 27, 17, 125, 160, 110, 166, 162, 159, 56, 22, 68, 37, 48, 148, 128, 179, 57, 133, 42, 152, 2, 111, 208, 63, 130, 167, 169, 47]\n",
      "layer3.5.conv1 [170, 29, 113, 86, 48, 215, 184, 73, 87, 192, 75, 210, 5, 191, 47, 150, 31, 90, 62, 111, 104, 91, 44, 42, 182, 177, 4, 21, 15, 127, 196, 137, 201, 174, 45, 168, 163, 193]\n",
      "layer4.0.conv2 [108, 96, 281, 61, 352, 200, 254, 407, 257, 33, 295, 55, 26, 89, 144, 320, 222, 21, 410, 245, 78, 178, 98, 39, 150, 365, 319, 323, 287, 226, 45, 94, 300, 252, 412, 272, 124, 206, 340, 331, 361, 73, 217, 122, 154, 289, 357, 382, 301, 364, 1, 413, 164, 402, 66, 294, 133, 179, 172, 12, 135, 29, 141, 276, 183, 246, 92, 112, 219, 230, 158, 247, 42, 325, 191, 171, 13]\n",
      "layer4.0.conv1 [368, 282, 202, 199, 204, 195, 17, 352, 103, 388, 157, 403, 289, 258, 369, 250, 188, 273, 169, 364, 329, 143, 9, 261, 252, 40, 272, 1, 165, 233, 348, 176, 316, 432, 158, 107, 216, 290, 219, 145, 182, 148, 339, 399, 400, 299, 84, 94, 426, 407, 98, 391, 389, 45, 242, 217, 235, 102, 21, 371, 397, 343, 32, 410, 154, 340, 284, 194, 224, 259, 97, 196, 126, 244, 404, 24, 387]\n",
      "layer4.1.conv2 [364, 72, 70, 388, 391, 381, 375, 289, 288, 88, 158, 274, 159, 392, 369, 396, 355, 366, 386, 75, 62, 80, 293, 402, 210, 150, 292, 291, 326, 98, 412, 271, 99, 168, 116, 397, 40, 12, 216, 41, 8, 163, 100, 95, 314, 241, 308, 59, 26, 10, 417, 48, 325, 403, 224, 254, 389, 320, 82, 144, 67, 30, 385, 240, 161, 160, 109, 304, 139, 297, 418, 270, 264, 4, 331, 430, 35]\n",
      "layer4.1.conv1 [54, 340, 125, 338, 126, 127, 263, 330, 269, 130, 329, 268, 327, 151, 325, 133, 138, 137, 324, 116, 432, 431, 430, 429, 422, 318, 317, 421, 420, 148, 145, 418, 313, 312, 310, 417, 143, 414, 413, 305, 408, 407, 401, 400, 398, 120, 121, 62, 48, 299, 50, 354, 273, 298, 348, 272, 342, 215, 212, 211, 262, 222, 77, 63, 64, 223, 66, 228, 296, 69, 232, 194, 75, 191, 233, 189, 234]\n",
      "layer4.2.conv2 [339, 276, 215, 187, 354, 41, 242, 291, 88, 338, 33, 293, 25, 5, 80, 151, 234, 307, 198, 306, 240, 328, 365, 288, 275, 243, 30, 128, 432, 337, 99, 192, 54, 352, 364, 402, 263, 211, 296, 120, 74, 81, 287, 193, 4, 2, 406, 159, 143, 407, 393, 431, 374, 150, 124, 244, 132, 8, 299, 129, 331, 309, 311, 221, 163, 38, 324, 182, 56, 346, 202, 254, 82, 241, 410, 322, 207]\n",
      "layer4.2.conv1 [108, 206, 367, 366, 207, 208, 161, 160, 209, 365, 210, 156, 363, 212, 371, 155, 352, 351, 253, 374, 350, 254, 257, 260, 378, 338, 273, 379, 143, 335, 60, 334, 332, 331, 141, 381, 326, 323, 322, 275, 320, 383, 384, 316, 387, 137, 136, 313, 312, 311, 50, 51, 52, 53, 380, 55, 310, 309, 58, 135, 276, 61, 62, 63, 64, 65, 66, 278, 68, 130, 304, 71, 388, 73, 301, 75, 76]\n",
      "Pruning step: 2 multiply–accumulate (macs): 2033869720.0 number of parameters 12935549\n",
      "layer4.0.downsample.0 [1203, 843, 32, 641, 1094, 512, 1376, 968, 112, 1237, 328, 554, 1369, 940, 1219, 593, 73, 224, 1199, 8, 1030, 1366, 39, 142, 305, 249, 219, 432, 433, 26, 225, 1328, 1227, 802, 692, 835, 588, 380, 425, 1251, 983, 733, 1367, 263, 1046, 138, 606, 1129, 37, 1300, 507, 1419, 259, 539, 1320, 724, 375, 52, 1187, 938, 901, 59, 362, 440, 187, 366, 1416, 1175, 868, 251, 679, 1124, 1214, 312, 956, 800, 1297, 1029, 1032, 1024, 1277, 273, 656, 140, 144, 929, 760, 561, 514, 717, 1102, 309, 1236, 495, 409, 1410, 1279, 260, 837, 890, 40, 153, 1202, 1347, 16, 1317, 863, 500, 1079, 292, 1063, 1158, 1382, 95, 1112, 693, 809, 761, 653, 434, 1339, 628, 1083, 609, 998, 625, 509, 865, 583, 808, 296, 1074, 923, 272, 589, 898, 1389, 829, 876, 325, 1306, 1192, 1009, 289, 701, 652, 961, 519, 851, 704, 1330, 1379, 578, 1136, 727, 743, 155, 1190, 461, 785, 880, 680, 533, 223, 510, 327, 827, 508, 918, 1240, 162, 1228, 207, 97, 1131, 755, 603, 1267, 1161, 939, 1113, 147, 1099, 643, 361, 363, 1378, 44, 1019, 1047, 595, 33, 1409, 42, 894, 1315, 552, 954, 1082, 410, 448, 322, 795, 677, 871, 605, 494, 619, 209, 50, 534, 357, 159, 41, 150, 748, 953, 1411, 587, 182, 1262, 1284, 462, 1242, 1234, 523, 937, 820, 1033, 1195, 1128, 287, 113, 11, 1346, 1156, 581, 771, 1107, 558, 516, 1408, 1130, 202, 60, 270, 741, 644, 839, 1065, 787, 891, 566, 5, 1008, 823, 235, 945, 81, 2, 555, 567, 1291, 1377, 10, 332, 877, 737, 673, 84, 311, 822, 134, 1140, 389, 604, 686, 379, 757, 349, 866, 1035, 404, 1356, 957, 321, 541, 831, 1352, 1185, 307, 1085, 459, 104, 994, 1425, 1349, 832, 246, 528, 1141, 1142, 660, 281, 974, 1049, 1248]\n",
      "layer3.0.downsample.0 [105, 376, 453, 406, 483, 517, 702, 147, 691, 392, 648, 112, 657, 129, 678, 255, 486, 76, 356, 253, 640, 643, 215, 495, 557, 36, 99, 8, 18, 468, 345, 233, 171, 156, 240, 432, 350, 331, 573, 342, 222, 633, 459, 694, 157, 618, 405, 102, 153, 616, 650, 568, 699, 627, 3, 397, 674, 419, 44, 307, 221, 270, 177, 407, 59, 161, 16, 373, 472, 125, 333, 711, 695, 323, 690, 160, 28, 639, 19, 606, 390, 415, 134, 9, 45, 371, 294, 489, 383, 377, 714, 69, 564, 505, 321, 418, 252, 305, 262, 575, 673, 494, 609, 500, 22, 521, 126, 608, 292, 401, 548, 528, 288, 656, 235, 327, 80, 607, 404, 155, 686, 687, 122, 537, 295, 164, 223, 216, 585, 64, 410, 580, 561, 481, 589, 332, 277, 525, 559, 655, 684, 535, 340, 484, 4, 39, 183, 527, 198, 551, 466, 208, 284]\n",
      "layer2.0.downsample.0 [333, 309, 182, 193, 156, 214, 203, 319, 299, 269, 61, 74, 29, 268, 129, 221, 225, 294, 347, 316, 68, 202, 133, 251, 149, 181, 2, 191, 321, 73, 336, 130, 17, 338, 37, 223, 122, 144, 283, 65, 357, 77, 3, 83, 273, 9, 197, 69, 353, 28, 276, 70, 185, 1, 250, 172, 62, 87, 226, 5, 330, 176, 304, 350, 267, 177, 219, 117, 66, 195, 242, 19, 131, 213, 302, 313, 104]\n",
      "layer1.0.downsample.0 [156, 123, 21, 163, 172, 61, 157, 166, 107, 70, 35, 14, 116, 154, 8, 30, 160, 109, 128, 173, 176, 29, 155, 44, 75, 145, 73, 59, 101, 106, 36, 57, 22, 174, 13, 24, 0, 16, 60]\n",
      "conv1 [25, 34, 18, 26, 39, 38, 3, 7, 21]\n",
      "layer1.0.conv2 [23, 20, 18, 10, 32, 38, 26, 42, 1]\n",
      "layer1.0.conv1 [23, 14, 26, 1, 42, 20, 39, 38, 36]\n",
      "layer1.1.conv2 [32, 30, 0, 10, 43, 27, 13, 4, 42]\n",
      "layer1.1.conv1 [40, 14, 25, 31, 7, 17, 8, 21, 1]\n",
      "layer1.2.conv2 [0, 21, 1, 28, 34, 35, 13, 42, 40]\n",
      "layer1.2.conv1 [13, 16, 24, 32, 34, 42, 27, 0, 40]\n",
      "layer2.0.conv2 [14, 56, 7, 71, 16, 25, 74, 23, 65, 84, 13, 9, 17, 10, 15, 80, 88, 75, 30]\n",
      "layer2.0.conv1 [1, 9, 84, 81, 61, 36, 18, 44, 16, 83, 74, 12, 64, 39, 86, 47, 43, 50, 45]\n",
      "layer2.1.conv2 [3, 62, 37, 5, 78, 85, 9, 47, 79, 65, 87, 49, 48, 50, 67, 63, 27, 68, 44]\n",
      "layer2.1.conv1 [10, 68, 39, 12, 28, 2, 82, 69, 83, 54, 38, 44, 67, 9, 42, 65, 18, 81, 88]\n",
      "layer2.2.conv2 [85, 56, 83, 14, 60, 57, 77, 59, 76, 32, 61, 65, 87, 42, 43, 2, 36, 52, 37]\n",
      "layer2.2.conv1 [17, 82, 55, 68, 86, 34, 64, 28, 85, 29, 63, 57, 81, 76, 31, 46, 25, 53, 1]\n",
      "layer2.3.conv2 [73, 18, 30, 32, 40, 27, 0, 9, 22, 11, 25, 8, 81, 45, 70, 76, 88, 77, 66]\n",
      "layer2.3.conv1 [28, 9, 15, 46, 14, 30, 4, 32, 16, 79, 40, 47, 31, 10, 18, 19, 0, 61, 20]\n",
      "layer3.0.conv2 [115, 136, 123, 73, 172, 43, 30, 175, 55, 19, 6, 32, 87, 79, 174, 127, 113, 64, 170, 128, 85, 146, 148, 70, 63, 75, 145, 27, 54, 101, 142, 98, 44, 108, 178, 47, 137, 81, 167]\n",
      "layer3.0.conv1 [151, 60, 39, 22, 167, 177, 104, 91, 34, 57, 84, 90, 148, 92, 25, 64, 108, 24, 116, 75, 178, 43, 100, 4, 169, 143, 98, 93, 53, 146, 27, 102, 49, 106, 119, 127, 59, 162, 157]\n",
      "layer3.1.conv2 [170, 122, 66, 103, 145, 9, 92, 121, 59, 131, 152, 98, 13, 40, 102, 135, 165, 151, 86, 93, 148, 114, 24, 141, 128, 12, 118, 88, 140, 51, 84, 158, 71, 99, 65, 4, 39, 119, 104]\n",
      "layer3.1.conv1 [167, 162, 16, 75, 170, 143, 98, 94, 158, 57, 122, 32, 177, 43, 153, 71, 27, 113, 154, 84, 120, 4, 31, 115, 157, 11, 164, 139, 50, 65, 21, 76, 106, 88, 72, 165, 8, 19, 22]\n",
      "layer3.2.conv2 [108, 130, 118, 102, 35, 17, 171, 77, 78, 57, 172, 89, 94, 150, 95, 158, 56, 129, 20, 131, 112, 161, 73, 34, 163, 76, 5, 67, 123, 64, 117, 169, 48, 109, 4, 69, 157, 178, 10]\n",
      "layer3.2.conv1 [12, 25, 120, 123, 113, 3, 107, 74, 103, 76, 100, 26, 37, 156, 46, 5, 101, 170, 163, 11, 93, 176, 58, 109, 68, 51, 119, 15, 128, 117, 48, 129, 83, 66, 161, 4, 21, 173, 137]\n",
      "layer3.3.conv2 [51, 29, 94, 38, 73, 83, 153, 82, 122, 99, 175, 20, 155, 145, 78, 31, 12, 112, 135, 23, 91, 97, 172, 46, 90, 128, 148, 34, 124, 120, 4, 72, 17, 16, 95, 87, 113, 25, 123]\n",
      "layer3.3.conv1 [74, 40, 138, 51, 52, 66, 113, 83, 141, 97, 9, 5, 93, 103, 173, 58, 115, 35, 151, 116, 148, 14, 21, 165, 98, 170, 139, 118, 110, 29, 121, 70, 158, 130, 49, 47, 175, 11, 131]\n",
      "layer3.4.conv2 [64, 47, 169, 31, 119, 10, 29, 175, 60, 93, 8, 156, 172, 135, 148, 120, 112, 116, 155, 44, 54, 45, 19, 141, 94, 38, 114, 150, 128, 78, 89, 95, 14, 81, 173, 20, 4, 35, 139]\n",
      "layer3.4.conv1 [126, 147, 177, 56, 141, 6, 106, 123, 18, 80, 48, 20, 4, 162, 57, 130, 88, 68, 128, 153, 142, 154, 140, 11, 65, 66, 97, 108, 40, 70, 164, 78, 82, 111, 7, 117, 93, 75, 89]\n",
      "layer3.5.conv2 [78, 2, 117, 41, 55, 99, 13, 158, 133, 72, 3, 23, 129, 30, 166, 40, 134, 82, 50, 113, 73, 79, 83, 144, 120, 63, 42, 24, 140, 31, 77, 114, 155, 25, 57, 150, 68, 136, 8]\n",
      "layer3.5.conv1 [25, 103, 10, 147, 110, 118, 161, 17, 8, 30, 56, 2, 154, 151, 21, 31, 55, 62, 24, 168, 50, 97, 67, 20, 29, 149, 108, 73, 9, 173, 104, 79, 124, 100, 78, 136, 132, 6, 145]\n",
      "layer4.0.conv2 [116, 141, 226, 38, 221, 266, 11, 348, 239, 300, 113, 110, 25, 132, 234, 167, 33, 244, 243, 347, 136, 79, 139, 305, 145, 28, 135, 50, 98, 12, 321, 205, 146, 199, 357, 149, 296, 352, 115, 4, 339, 155, 54, 46, 350, 241, 65, 188, 156, 331, 294, 9, 104, 23, 164, 268, 58, 129, 170, 190, 308, 214, 213, 261, 120, 106, 44, 293, 218, 318, 187, 281, 154, 307, 237, 203, 292]\n",
      "layer4.0.conv1 [43, 75, 144, 33, 279, 88, 222, 253, 59, 90, 276, 188, 282, 108, 8, 185, 257, 297, 120, 296, 66, 132, 326, 291, 129, 148, 134, 251, 240, 23, 186, 41, 160, 211, 173, 136, 325, 268, 3, 339, 121, 114, 26, 113, 277, 31, 295, 289, 84, 0, 254, 354, 5, 347, 317, 55, 87, 13, 147, 176, 22, 313, 219, 151, 143, 98, 318, 210, 17, 207, 168, 270, 112, 310, 344, 249, 159]\n",
      "layer4.1.conv2 [57, 333, 246, 11, 139, 263, 170, 63, 39, 260, 20, 210, 119, 179, 24, 135, 43, 94, 151, 191, 62, 184, 127, 193, 198, 83, 147, 157, 138, 146, 196, 215, 103, 140, 69, 23, 202, 15, 177, 247, 243, 87, 331, 239, 310, 115, 158, 269, 162, 144, 110, 309, 351, 108, 224, 323, 153, 279, 48, 222, 81, 117, 169, 228, 306, 250, 66, 166, 258, 203, 338, 264, 65, 137, 340, 18, 175]\n",
      "layer4.1.conv1 [204, 215, 94, 77, 95, 246, 131, 84, 220, 82, 101, 129, 236, 247, 218, 102, 78, 89, 74, 104, 217, 71, 92, 163, 183, 30, 229, 66, 293, 79, 150, 62, 168, 349, 316, 80, 143, 335, 330, 239, 262, 146, 242, 53, 200, 301, 317, 260, 21, 125, 352, 98, 127, 185, 298, 38, 181, 52, 213, 277, 16, 310, 221, 31, 267, 132, 193, 99, 270, 100, 58, 302, 201, 22, 144, 43, 238]\n",
      "layer4.2.conv2 [278, 229, 38, 219, 348, 246, 9, 315, 23, 117, 65, 172, 121, 49, 54, 152, 220, 181, 4, 102, 116, 217, 319, 68, 26, 78, 5, 169, 94, 263, 291, 227, 50, 56, 244, 235, 328, 41, 118, 133, 154, 39, 140, 153, 286, 222, 75, 36, 32, 331, 252, 183, 274, 211, 196, 258, 162, 275, 28, 337, 95, 304, 87, 63, 260, 123, 347, 92, 351, 321, 60, 223, 204, 294, 182, 148, 93]\n",
      "layer4.2.conv1 [73, 157, 158, 81, 75, 80, 313, 195, 155, 161, 198, 162, 163, 194, 165, 193, 152, 168, 151, 197, 169, 149, 171, 199, 173, 174, 200, 146, 72, 206, 142, 208, 139, 211, 213, 215, 216, 236, 239, 240, 241, 242, 110, 107, 105, 322, 245, 246, 314, 102, 247, 248, 99, 251, 254, 95, 94, 93, 255, 97, 60, 61, 90, 63, 64, 65, 87, 67, 84, 69, 82, 202, 272, 59, 298, 66, 10]\n",
      "Pruning step: 3 multiply–accumulate (macs): 1274471478.0 number of parameters 8217318\n",
      "layer4.0.downsample.0 [203, 839, 990, 220, 798, 1109, 418, 693, 998, 1018, 570, 39, 11, 325, 640, 21, 132, 869, 613, 827, 162, 102, 336, 957, 1051, 384, 811, 261, 853, 542, 682, 433, 768, 855, 789, 1029, 604, 704, 61, 537, 237, 241, 873, 476, 689, 1045, 1079, 380, 697, 209, 752, 628, 878, 769, 192, 808, 121, 703, 665, 585, 527, 164, 160, 966, 1034, 227, 287, 467, 286, 618, 243, 106, 623, 562, 256, 161, 884, 708, 653, 166, 412, 525, 455, 367, 415, 1111, 906, 196, 364, 361, 1117, 935, 766, 559, 32, 911, 187, 1020, 133, 612, 285, 1062, 1063, 83, 228, 556, 601, 0, 817, 1044, 116, 85, 960, 36, 253, 449, 94, 968, 274, 726, 761, 650, 788, 40, 669, 1013, 378, 679, 120, 68, 473, 1122, 362, 472, 95, 381, 522, 411, 518, 600, 54, 936, 373, 1038, 765, 41, 763, 794, 180, 993, 338, 181, 45, 514, 649, 536, 751, 74, 1088, 759, 715, 13, 186, 265, 398, 778, 932, 397, 661, 344, 791, 210, 930, 864, 200, 273, 43, 454, 951, 609, 790, 921, 942, 529, 488, 760, 310, 1043, 82, 754, 914, 545, 147, 931, 171, 320, 189, 1123, 477, 929, 1021, 66, 410, 546, 733, 812, 288, 493, 886, 264, 874, 776, 235, 487, 549, 1061, 368, 958, 172, 1118, 1010, 779, 963, 841, 980, 1012, 707, 371, 205, 574, 1059, 1067, 824, 922, 176, 823, 6, 670, 144, 244, 328, 816, 163, 555, 890, 767, 426, 101, 925, 463, 118, 263, 575, 4, 802, 14, 686, 937, 913, 448, 91, 314, 519, 660, 716, 897, 1124, 195, 616, 646, 231, 442, 948, 581, 903, 317, 294, 508, 1070, 732, 561, 1014, 105, 182, 303, 1113, 698, 840, 420, 887, 552, 512, 917, 738, 543, 582, 832, 1049, 764, 513, 20, 515, 108, 750, 5, 284, 389]\n",
      "layer3.0.downsample.0 [489, 479, 288, 86, 260, 179, 486, 298, 156, 375, 358, 80, 503, 512, 272, 187, 525, 477, 135, 438, 12, 407, 41, 248, 413, 301, 470, 445, 134, 305, 42, 453, 391, 3, 335, 389, 356, 557, 263, 303, 371, 241, 19, 123, 440, 131, 515, 14, 25, 194, 105, 401, 297, 172, 425, 442, 283, 52, 237, 160, 324, 532, 143, 24, 214, 13, 345, 182, 314, 506, 295, 329, 206, 426, 522, 152, 536, 390, 7, 264, 436, 323, 68, 43, 168, 322, 83, 221, 361, 58, 195, 215, 228, 418, 521, 173, 247, 17, 501, 422, 491, 498, 132, 480, 246, 185, 98, 307, 59, 513, 164, 351, 91, 541, 291, 75, 211, 167, 528, 217, 67, 508, 95, 114, 287, 456, 463, 294, 171, 313, 267, 404, 69, 51, 174, 118, 149, 137, 533, 430, 268, 146, 256, 5, 552, 147, 33, 16, 102, 21, 196, 66, 478, 177]\n",
      "layer2.0.downsample.0 [118, 186, 249, 24, 212, 134, 155, 103, 243, 229, 211, 215, 29, 36, 267, 160, 109, 71, 119, 205, 172, 264, 216, 234, 20, 70, 198, 94, 89, 105, 39, 21, 150, 273, 78, 142, 128, 64, 72, 2, 121, 236, 61, 124, 188, 112, 270, 179, 192, 153, 225, 254, 63, 66, 167, 158, 92, 136, 137, 130, 40, 54, 47, 56, 259, 129, 140, 68, 221, 127, 45, 0, 82, 30, 258, 238, 90]\n",
      "layer1.0.downsample.0 [99, 71, 107, 93, 136, 30, 73, 43, 62, 122, 28, 81, 90, 42, 60, 96, 20, 115, 51, 16, 19, 57, 33, 139, 109, 17, 72, 132, 66, 54, 45, 29, 74, 86, 120, 123, 15, 97]\n",
      "conv1 [20, 22, 0, 21, 32, 10, 2, 17, 6, 3]\n",
      "layer1.0.conv2 [16, 13, 31, 1, 25, 5, 24, 32, 17, 9]\n",
      "layer1.0.conv1 [17, 22, 27, 33, 19, 14, 4, 13, 25, 21]\n",
      "layer1.1.conv2 [30, 5, 0, 1, 3, 6, 24, 17, 12, 22]\n",
      "layer1.1.conv1 [6, 2, 27, 9, 30, 20, 11, 12, 28, 15]\n",
      "layer1.2.conv2 [33, 9, 2, 27, 7, 34, 8, 6, 5, 30]\n",
      "layer1.2.conv1 [1, 19, 32, 9, 0, 18, 25, 24, 17, 28]\n",
      "layer2.0.conv2 [39, 24, 29, 5, 21, 19, 9, 66, 41, 47, 10, 12, 13, 49, 62, 59, 40, 50, 1]\n",
      "layer2.0.conv1 [44, 39, 8, 61, 11, 31, 4, 7, 36, 45, 14, 52, 56, 54, 15, 38, 63, 58, 49]\n",
      "layer2.1.conv2 [47, 68, 41, 25, 13, 56, 4, 60, 11, 10, 0, 28, 20, 7, 67, 57, 61, 50, 36]\n",
      "layer2.1.conv1 [12, 65, 18, 19, 11, 62, 28, 51, 67, 16, 4, 36, 66, 3, 14, 41, 0, 22, 1]\n",
      "layer2.2.conv2 [38, 18, 20, 68, 42, 12, 29, 45, 23, 9, 33, 51, 56, 63, 54, 21, 36, 0, 65]\n",
      "layer2.2.conv1 [24, 19, 31, 65, 11, 35, 68, 54, 32, 20, 64, 7, 51, 40, 12, 33, 49, 53, 17]\n",
      "layer2.3.conv2 [67, 35, 37, 20, 63, 45, 55, 25, 27, 38, 1, 32, 48, 18, 62, 65, 5, 21, 59]\n",
      "layer2.3.conv1 [55, 21, 47, 30, 23, 48, 10, 27, 62, 31, 29, 6, 63, 57, 59, 51, 16, 26, 4]\n",
      "layer3.0.conv2 [27, 26, 107, 66, 110, 49, 2, 55, 90, 86, 89, 39, 7, 52, 108, 15, 109, 124, 19, 29, 9, 113, 103, 99, 77, 81, 70, 57, 82, 138, 105, 44, 136, 132, 128, 100, 1, 126]\n",
      "layer3.0.conv1 [136, 91, 20, 137, 83, 7, 90, 31, 51, 59, 68, 128, 111, 105, 92, 73, 88, 74, 66, 55, 5, 123, 85, 133, 130, 37, 22, 8, 32, 81, 33, 110, 23, 115, 34, 2, 127, 135]\n",
      "layer3.1.conv2 [25, 101, 62, 111, 64, 86, 13, 107, 0, 27, 40, 113, 72, 11, 56, 61, 95, 98, 34, 115, 18, 112, 92, 63, 58, 49, 135, 14, 131, 22, 10, 5, 130, 94, 41, 74, 44, 121]\n",
      "layer3.1.conv1 [23, 134, 122, 91, 17, 128, 76, 92, 114, 50, 9, 90, 8, 113, 107, 49, 27, 129, 102, 98, 4, 68, 26, 53, 111, 5, 0, 110, 93, 130, 58, 45, 108, 42, 1, 139, 136, 84]\n",
      "layer3.2.conv2 [129, 125, 30, 91, 6, 43, 121, 87, 64, 82, 116, 19, 4, 76, 13, 55, 92, 7, 50, 10, 77, 8, 74, 132, 94, 34, 26, 65, 14, 98, 17, 108, 63, 99, 61, 56, 84, 81]\n",
      "layer3.2.conv1 [10, 57, 84, 8, 131, 122, 139, 80, 36, 50, 0, 60, 135, 130, 58, 110, 109, 40, 33, 113, 132, 98, 39, 7, 17, 126, 20, 75, 105, 23, 128, 111, 100, 24, 138, 3, 5, 66]\n",
      "layer3.3.conv2 [112, 77, 50, 79, 59, 61, 40, 10, 41, 20, 21, 25, 121, 60, 119, 18, 28, 136, 14, 27, 9, 129, 67, 138, 107, 80, 71, 43, 44, 45, 19, 22, 100, 37, 110, 29, 24, 83]\n",
      "layer3.3.conv1 [22, 67, 29, 97, 103, 34, 1, 46, 24, 57, 100, 110, 27, 86, 13, 135, 73, 0, 3, 30, 32, 89, 52, 9, 98, 49, 14, 44, 69, 63, 123, 139, 133, 55, 66, 92, 84, 127]\n",
      "layer3.4.conv2 [73, 71, 37, 43, 17, 96, 87, 6, 92, 123, 109, 57, 25, 65, 135, 14, 82, 35, 103, 64, 130, 27, 30, 16, 113, 23, 38, 4, 128, 7, 8, 116, 10, 91, 122, 66, 90, 44]\n",
      "layer3.4.conv1 [67, 78, 17, 81, 3, 59, 71, 60, 84, 83, 48, 24, 34, 80, 110, 130, 131, 43, 79, 74, 38, 9, 97, 93, 31, 128, 112, 127, 5, 68, 96, 12, 106, 7, 101, 135, 26, 36]\n",
      "layer3.5.conv2 [5, 64, 98, 137, 90, 6, 69, 22, 85, 48, 83, 72, 104, 56, 28, 109, 50, 23, 75, 76, 4, 60, 73, 70, 55, 124, 101, 66, 7, 3, 44, 54, 121, 138, 58, 39, 52, 71]\n",
      "layer3.5.conv1 [53, 136, 101, 81, 63, 109, 6, 12, 66, 44, 0, 108, 31, 115, 33, 70, 52, 97, 128, 83, 125, 67, 137, 1, 28, 104, 8, 122, 82, 72, 102, 85, 64, 77, 49, 17, 127, 134]\n",
      "layer4.0.conv2 [127, 233, 277, 143, 168, 113, 175, 162, 132, 21, 48, 258, 199, 267, 70, 116, 242, 178, 207, 130, 238, 115, 118, 169, 244, 188, 104, 66, 273, 145, 20, 31, 167, 198, 26, 210, 191, 253, 68, 229, 157, 53, 265, 237, 5, 203, 23, 117, 96, 177, 209, 98, 120, 30, 41, 264, 139, 180, 246, 163, 170, 73, 10, 223, 111, 222, 54, 189, 232, 218, 95, 7, 36, 92, 146, 1, 109]\n",
      "layer4.0.conv1 [119, 206, 116, 45, 146, 107, 173, 273, 253, 237, 249, 161, 190, 19, 7, 95, 12, 16, 263, 31, 148, 183, 163, 208, 177, 271, 181, 98, 166, 50, 202, 47, 191, 228, 57, 120, 87, 35, 196, 105, 93, 5, 127, 238, 60, 109, 176, 30, 219, 204, 187, 143, 58, 167, 255, 246, 24, 224, 4, 26, 48, 171, 113, 32, 124, 101, 240, 223, 247, 22, 106, 245, 186, 188, 102, 260, 13]\n",
      "layer4.1.conv2 [58, 129, 272, 3, 149, 215, 2, 144, 94, 157, 271, 208, 239, 162, 70, 166, 145, 98, 89, 108, 107, 252, 35, 22, 231, 114, 127, 0, 43, 54, 75, 100, 155, 66, 52, 5, 245, 49, 260, 116, 106, 25, 205, 228, 99, 143, 216, 221, 247, 182, 104, 168, 172, 121, 195, 248, 17, 88, 196, 223, 42, 186, 14, 201, 156, 152, 194, 251, 76, 134, 273, 112, 253, 204, 274, 203, 259]\n",
      "layer4.1.conv1 [146, 224, 183, 158, 197, 171, 138, 112, 181, 250, 231, 34, 117, 229, 239, 259, 256, 268, 126, 143, 94, 58, 120, 178, 217, 190, 113, 235, 66, 107, 254, 135, 48, 90, 193, 207, 77, 195, 92, 49, 130, 114, 236, 133, 52, 8, 186, 98, 46, 136, 210, 280, 9, 167, 11, 172, 196, 278, 163, 187, 225, 279, 277, 21, 97, 78, 227, 15, 82, 86, 121, 108, 57, 69, 267, 179, 128]\n",
      "layer4.2.conv2 [70, 176, 147, 232, 38, 218, 144, 49, 235, 215, 135, 73, 11, 199, 115, 140, 83, 185, 88, 173, 23, 104, 55, 162, 189, 265, 137, 242, 164, 42, 241, 181, 138, 230, 63, 134, 208, 86, 228, 123, 82, 76, 280, 244, 217, 133, 273, 128, 223, 47, 268, 210, 167, 165, 177, 87, 19, 66, 231, 116, 35, 159, 96, 5, 54, 139, 224, 48, 95, 45, 119, 275, 40, 108, 227, 34, 160]\n",
      "layer4.2.conv1 [4, 194, 239, 187, 41, 100, 80, 73, 257, 261, 205, 63, 227, 103, 147, 118, 61, 5, 38, 171, 87, 172, 137, 134, 218, 60, 29, 104, 231, 8, 139, 17, 226, 224, 102, 99, 269, 93, 275, 192, 193, 241, 174, 142, 6, 25, 148, 157, 18, 184, 109, 279, 267, 168, 146, 204, 189, 207, 270, 70, 178, 201, 152, 177, 52, 262, 163, 179, 84, 274, 131, 215, 276, 119, 199, 280, 12]\n",
      "Pruning step: 4 multiply–accumulate (macs): 687397367.0 number of parameters 4572522\n",
      "layer4.0.downsample.0 [701, 478, 40, 480, 691, 187, 66, 754, 154, 23, 283, 333, 662, 817, 369, 208, 803, 512, 491, 777, 666, 678, 24, 509, 584, 597, 513, 131, 312, 211, 805, 157, 402, 381, 212, 669, 575, 713, 632, 399, 372, 728, 291, 495, 240, 768, 772, 268, 435, 441, 406, 122, 510, 627, 714, 800, 1, 347, 186, 42, 644, 115, 265, 247, 489, 44, 144, 472, 589, 798, 394, 136, 459, 190, 253, 532, 292, 233, 538, 356, 671, 747, 600, 745, 700, 477, 31, 332, 797, 699, 804, 21, 39, 69, 140, 53, 101, 320, 262, 464, 306, 261, 340, 590, 785, 508, 683, 410, 610, 483, 368, 606, 759, 308, 257, 501, 494, 156, 708, 353, 149, 417, 422, 650, 58, 581, 232, 405, 345, 22, 426, 572, 396, 250, 319, 451, 32, 741, 133, 392, 124, 176, 580, 769, 331, 13, 139, 78, 371, 695, 324, 64, 118, 614, 445, 652, 377, 299, 328, 178, 757, 196, 789, 25, 525, 780, 228, 269, 591, 792, 296, 152, 583, 326, 298, 615, 436, 717, 779, 364, 442, 602, 404, 811, 201, 301, 97, 278, 661, 117, 439, 121, 688, 493, 137, 506, 33, 56, 657, 799, 668, 163, 110, 783, 433, 781, 175, 318, 675, 685, 359, 134, 366, 638, 434, 92, 81, 778, 229, 55, 736, 468, 83, 429, 38, 170, 36, 807, 87, 563, 751, 689, 729, 409, 813, 263, 684, 649, 522, 486, 336, 808, 734, 801, 498, 401, 315, 408, 225, 548, 595, 173, 107, 573, 766, 59, 698, 91, 284, 549, 704, 346, 7, 113, 547, 551, 746, 199, 141, 687, 20, 446, 715, 793, 367, 344, 796, 213, 322, 503, 72, 782, 188, 546, 317, 9, 227, 234, 145, 360, 786, 112, 237, 773, 564, 363, 309, 721, 485, 182, 703, 656, 380, 132, 126, 167, 197]\n",
      "layer3.0.downsample.0 [69, 387, 281, 394, 90, 5, 177, 250, 376, 358, 204, 116, 27, 6, 302, 98, 269, 105, 166, 108, 111, 1, 314, 76, 87, 74, 316, 133, 373, 35, 270, 251, 3, 41, 404, 384, 318, 140, 147, 160, 199, 155, 184, 59, 182, 223, 363, 70, 112, 149, 283, 84, 255, 284, 260, 309, 202, 310, 392, 193, 191, 399, 275, 89, 402, 86, 10, 312, 125, 141, 229, 379, 331, 244, 296, 99, 153, 393, 150, 187, 19, 395, 208, 359, 179, 237, 264, 353, 9, 92, 295, 119, 308, 144, 183, 203, 42, 100, 401, 68, 139, 388, 276, 403, 355, 61, 151, 109, 253, 262, 297, 189, 287, 194, 215, 209, 344, 0, 162, 335, 330, 130, 319, 383, 299, 212, 339, 49, 258, 271, 66, 52, 158, 243, 273, 7, 128, 185, 2, 126, 278, 174, 294, 11, 291, 300, 164, 406, 377, 29, 77, 232, 171]\n",
      "layer2.0.downsample.0 [61, 67, 164, 174, 12, 114, 136, 113, 93, 194, 148, 73, 59, 104, 137, 133, 92, 37, 193, 60, 146, 170, 6, 160, 96, 184, 171, 106, 14, 10, 29, 38, 74, 165, 185, 159, 130, 192, 131, 83, 125, 132, 201, 35, 154, 135, 199, 175, 47, 127, 161, 91, 20, 4, 142, 188, 202, 77, 134, 140, 8, 48, 95, 88, 80, 195, 82, 198, 58, 18, 141, 173, 144, 42, 34, 46]\n",
      "layer1.0.downsample.0 [90, 59, 44, 95, 57, 4, 33, 66, 78, 36, 25, 76, 75, 61, 47, 18, 87, 9, 17, 20, 30, 5, 77, 81, 93, 27, 96, 41, 37, 72, 60, 56, 98, 52, 26, 11, 71, 54]\n",
      "conv1 [20, 10, 18, 1, 9, 17, 21, 11, 2]\n",
      "layer1.0.conv2 [6, 19, 24, 5, 11, 1, 8, 18, 12]\n",
      "layer1.0.conv1 [20, 18, 7, 13, 9, 10, 21, 1, 6]\n",
      "layer1.1.conv2 [18, 24, 4, 19, 3, 13, 15, 23, 5]\n",
      "layer1.1.conv1 [19, 11, 2, 6, 21, 7, 23, 18, 24]\n",
      "layer1.2.conv2 [22, 19, 10, 13, 8, 18, 0, 7, 11]\n",
      "layer1.2.conv1 [23, 5, 20, 21, 18, 14, 13, 16, 24]\n",
      "layer2.0.conv2 [19, 2, 9, 35, 29, 12, 34, 48, 13, 42, 43, 28, 4, 7, 10, 50, 31, 17, 3]\n",
      "layer2.0.conv1 [6, 28, 14, 32, 50, 31, 5, 48, 10, 37, 30, 43, 35, 40, 9, 18, 46, 7, 4]\n",
      "layer2.1.conv2 [17, 47, 2, 4, 28, 49, 50, 0, 16, 7, 21, 29, 46, 43, 10, 34, 9, 5, 33]\n",
      "layer2.1.conv1 [17, 28, 26, 44, 12, 6, 0, 39, 14, 11, 46, 15, 31, 32, 20, 23, 21, 25, 33]\n",
      "layer2.2.conv2 [23, 21, 36, 10, 29, 12, 43, 40, 28, 35, 15, 19, 6, 47, 1, 31, 32, 18, 11]\n",
      "layer2.2.conv1 [4, 37, 26, 48, 24, 46, 39, 22, 41, 20, 16, 21, 34, 49, 13, 14, 35, 43, 44]\n",
      "layer2.3.conv2 [22, 6, 7, 29, 17, 4, 42, 34, 9, 50, 26, 33, 24, 3, 18, 23, 0, 46, 45]\n",
      "layer2.3.conv1 [47, 5, 46, 12, 42, 50, 0, 11, 32, 49, 4, 31, 1, 23, 39, 7, 27, 38, 15]\n",
      "layer3.0.conv2 [60, 48, 42, 96, 10, 29, 77, 80, 67, 65, 83, 22, 23, 7, 66, 52, 50, 27, 92, 91, 58, 44, 94, 47, 64, 45, 86, 1, 0, 30, 16, 88, 36, 28, 25, 69, 68, 100]\n",
      "layer3.0.conv1 [22, 97, 66, 95, 0, 26, 101, 34, 69, 29, 88, 85, 23, 75, 60, 36, 84, 41, 83, 43, 100, 31, 82, 18, 58, 4, 61, 51, 32, 17, 55, 19, 94, 56, 80, 2, 71, 16]\n",
      "layer3.1.conv2 [24, 50, 31, 58, 83, 64, 86, 54, 17, 18, 52, 21, 79, 5, 30, 38, 45, 8, 73, 14, 72, 33, 63, 12, 78, 88, 77, 35, 47, 19, 93, 94, 42, 40, 3, 48, 32, 87]\n",
      "layer3.1.conv1 [99, 94, 93, 77, 49, 64, 18, 5, 31, 44, 57, 58, 91, 39, 80, 54, 26, 92, 89, 84, 69, 95, 15, 73, 33, 32, 40, 14, 7, 16, 52, 37, 56, 3, 10, 29, 25, 96]\n",
      "layer3.2.conv2 [4, 27, 36, 16, 40, 88, 8, 28, 15, 47, 24, 11, 86, 14, 38, 87, 57, 45, 90, 13, 69, 25, 34, 9, 63, 70, 6, 97, 44, 72, 80, 55, 101, 76, 77, 68, 1, 73]\n",
      "layer3.2.conv1 [31, 23, 98, 62, 66, 1, 53, 77, 81, 57, 38, 84, 11, 13, 52, 36, 65, 68, 34, 35, 48, 33, 56, 75, 55, 100, 41, 4, 20, 21, 97, 46, 18, 27, 89, 32, 80, 72]\n",
      "layer3.3.conv2 [10, 42, 19, 92, 59, 12, 9, 51, 95, 70, 16, 98, 17, 55, 79, 50, 35, 8, 97, 90, 36, 80, 84, 89, 18, 62, 94, 66, 37, 60, 7, 3, 31, 87, 28, 47, 32, 14]\n",
      "layer3.3.conv1 [14, 86, 75, 79, 3, 77, 11, 26, 87, 15, 4, 57, 63, 25, 62, 27, 30, 21, 65, 93, 94, 32, 38, 91, 10, 49, 58, 1, 68, 36, 56, 0, 43, 90, 71, 53, 64, 45]\n",
      "layer3.4.conv2 [93, 4, 27, 87, 50, 45, 67, 12, 19, 101, 92, 86, 72, 88, 83, 54, 48, 16, 51, 75, 70, 74, 5, 79, 64, 44, 82, 90, 46, 2, 10, 9, 8, 94, 26, 56, 65, 99]\n",
      "layer3.4.conv1 [92, 58, 51, 4, 98, 43, 6, 54, 24, 84, 23, 73, 45, 86, 88, 42, 32, 85, 72, 0, 1, 67, 59, 56, 77, 79, 17, 9, 29, 68, 50, 57, 40, 33, 82, 49, 25, 12]\n",
      "layer3.5.conv2 [30, 93, 91, 60, 2, 25, 87, 82, 50, 55, 62, 94, 39, 1, 59, 49, 61, 65, 58, 4, 101, 0, 7, 11, 38, 32, 78, 97, 64, 40, 57, 41, 37, 72, 23, 22, 3, 16]\n",
      "layer3.5.conv1 [82, 99, 59, 38, 52, 56, 87, 17, 54, 81, 55, 21, 44, 33, 79, 76, 43, 64, 16, 13, 78, 35, 32, 31, 62, 6, 95, 57, 14, 3, 39, 20, 42, 51, 49, 89, 28, 86]\n",
      "layer4.0.conv2 [138, 66, 22, 121, 33, 3, 106, 78, 80, 141, 19, 114, 93, 200, 51, 92, 163, 109, 24, 17, 147, 56, 165, 167, 5, 168, 15, 72, 151, 94, 76, 77, 150, 47, 7, 161, 4, 44, 105, 74, 203, 18, 112, 185, 45, 28, 172, 196, 171, 190, 96, 136, 152, 142, 83, 177, 164, 59, 139, 110, 12, 87, 173, 149, 132, 123, 9, 55, 195, 156, 201, 153, 169, 6, 134, 69]\n",
      "layer4.0.conv1 [13, 106, 127, 112, 144, 186, 78, 99, 148, 195, 39, 189, 198, 125, 137, 25, 160, 138, 165, 154, 116, 163, 181, 33, 170, 71, 4, 132, 41, 155, 196, 83, 118, 174, 162, 73, 188, 167, 82, 34, 32, 159, 192, 147, 110, 128, 149, 179, 121, 49, 5, 193, 141, 58, 50, 123, 151, 21, 156, 119, 59, 30, 89, 90, 10, 201, 81, 109, 194, 67, 65, 139, 185, 183, 140, 93]\n",
      "layer4.1.conv2 [166, 167, 136, 174, 45, 179, 195, 151, 37, 101, 19, 112, 108, 56, 141, 202, 43, 49, 129, 145, 98, 62, 199, 109, 99, 143, 52, 192, 51, 110, 59, 149, 36, 13, 94, 18, 194, 46, 137, 8, 153, 169, 119, 148, 128, 198, 87, 57, 85, 54, 116, 47, 105, 79, 75, 14, 189, 133, 142, 138, 30, 172, 146, 115, 97, 163, 117, 2, 92, 96, 83, 0, 158, 71, 17, 182]\n",
      "layer4.1.conv1 [50, 0, 39, 137, 180, 135, 34, 142, 30, 12, 85, 157, 70, 40, 151, 95, 83, 187, 35, 64, 78, 195, 154, 107, 60, 141, 161, 52, 55, 25, 144, 176, 122, 44, 171, 67, 179, 140, 177, 125, 41, 183, 148, 62, 101, 23, 77, 73, 123, 22, 118, 105, 89, 87, 65, 202, 191, 139, 168, 29, 3, 106, 63, 100, 80, 14, 49, 53, 129, 2, 5, 97, 156, 119, 98, 74]\n",
      "layer4.2.conv2 [123, 34, 116, 189, 111, 196, 126, 121, 182, 105, 10, 175, 131, 112, 148, 88, 15, 13, 183, 122, 77, 89, 97, 108, 136, 12, 138, 159, 51, 185, 84, 19, 20, 61, 31, 41, 124, 115, 25, 174, 128, 49, 40, 21, 62, 168, 181, 141, 26, 191, 158, 79, 11, 99, 103, 80, 95, 154, 23, 47, 52, 160, 6, 39, 42, 3, 65, 186, 81, 176, 36, 17, 171, 63, 87, 1]\n",
      "layer4.2.conv1 [188, 37, 131, 138, 126, 4, 24, 108, 106, 95, 40, 31, 117, 32, 5, 159, 33, 103, 147, 115, 9, 96, 22, 62, 200, 26, 3, 109, 78, 73, 102, 20, 59, 157, 36, 100, 182, 66, 130, 179, 85, 68, 44, 163, 122, 51, 89, 91, 53, 148, 16, 99, 7, 41, 125, 114, 170, 64, 174, 52, 178, 39, 57, 184, 14, 55, 168, 77, 141, 1, 124, 134, 25, 45, 197, 86]\n",
      "Pruning step: 5 multiply–accumulate (macs): 286271592.0 number of parameters 1993976\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18, resnet50\n",
    "import torch_pruning as tp\n",
    "from torchinfo import summary\n",
    "import os\n",
    "\n",
    "sparsities = [0, 0.0625, 0.125, 0.1875, 0.25, 0.3125, 0.375, 0.4375, 0.5, 0.5625, 0.625, 0.6875, 0.75]\n",
    "\n",
    "for sparsity in sparsities:\n",
    "  model = resnet50(pretrained=True)\n",
    "\n",
    "  # Importance criteria\n",
    "  example_inputs = torch.randn(1, 3, 224, 224)\n",
    "  imp = tp.importance.TaylorImportance()\n",
    "\n",
    "  ignored_layers = []\n",
    "  for m in model.modules():\n",
    "      if isinstance(m, torch.nn.Linear) and m.out_features == 1000:\n",
    "          ignored_layers.append(m) # DO NOT prune the final classifier!\n",
    "\n",
    "  iterative_steps = 5 # progressive pruning\n",
    "  current_step = 1\n",
    "  prune_amounts = [x / 64 for x in range(48)]\n",
    "\n",
    "  pruner = tp.pruner.MagnitudePruner(\n",
    "      model,\n",
    "      example_inputs,\n",
    "      importance=imp,\n",
    "      iterative_steps=iterative_steps,\n",
    "      ch_sparsity=sparsity, # remove 50% channels, ResNet18 = {64, 128, 256, 512} => ResNet18_Half = {32, 64, 128, 256}\n",
    "      ignored_layers=ignored_layers,\n",
    "  )\n",
    "\n",
    "  base_macs, base_nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "\n",
    "  print(\"Pruning sparsity:\", sparsity,)\n",
    "  for i in range(iterative_steps):\n",
    "      if isinstance(imp, tp.importance.TaylorImportance):\n",
    "          # Taylor expansion requires gradients for importance estimation\n",
    "          loss = model(example_inputs).sum() # a dummy loss for TaylorImportance\n",
    "          loss.backward() # before pruner.step()\n",
    "      pruner.step()\n",
    "      macs, nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "      print(\"Pruning step:\", current_step, \"multiply–accumulate (macs):\", macs, \"number of parameters\", nparams)\n",
    "      current_step += 1\n",
    "\n",
    "  state_dict = tp.state_dict(model) # the pruned model, e.g., a resnet-18-half\n",
    "  torch.save(state_dict, \"./resnet50/\"+str(sparsity)+\"_\"+'pruned.pth')\n",
    "  model_statistics = summary(model, (1, 3, 224, 224), depth=3, col_names=[\"kernel_size\", \"input_size\",\"output_size\", \"num_params\", \"mult_adds\"],)\n",
    "  model_statistics_str = str(model_statistics)\n",
    "\n",
    "  import pickle\n",
    "  with open(\"./resnet50/\"+str(sparsity)+\"_\"+'statistics.txt', 'wb') as f:\n",
    "      pickle.dump(model_statistics_str,f)  \n",
    "  \n",
    "  print(model)\n",
    "\n",
    "  # validate model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
