{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d222740b",
   "metadata": {},
   "source": [
    "# Customize Your Own Pruners\n",
    "\n",
    "Torch-pruning is a scalable tool that enables you to create your own pruners with customized importance criteria and pruning schemes. For instance, you can use torch-pruning to implement the [Slimming pruner](https://arxiv.org/abs/1708.06519), which utilizes the scaling parameters in Batch Normalization (BN) to identify and remove unimportant channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba962543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "import torch_pruning as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9d8d32",
   "metadata": {},
   "source": [
    "### 1. Pruner Definition\n",
    "\n",
    "Slimming Pruner leverages the scaling factor in Batch Normalization (BN) layers to determine the importance score of different channels. This technique follows a \"training-pruning-fine-tuning\" paradigm, which involves sparse training of the original model. In Torch-Pruning, the base class ``tp.pruner.MetaPruner`` provides a convenient ``.regularize(model)`` method for sparse training. Our first task is to implement such an interface to enable efficient regularization of BN parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ccf46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimplePruner(tp.pruner.MetaPruner):\n",
    "    def regularize(self, model, reg):\n",
    "        print(\"No regularization required.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dcfd75",
   "metadata": {},
   "source": [
    "### 2. Importance function\n",
    "Now, we need a new importance criterion for slimming, which compares the magnitude of the scaling parameter in BN. In this work, importance criterion is a callable function or object which accept a group ``tp.PruningGroup`` as inputs. ``tp.PruningGroup`` records all coupled layers as well as their pruning indices. We can scan the group to design our own importance function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f61c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimplePrunerImportance(tp.importance.Importance):\n",
    "    def __call__(self, group, **kwargs):\n",
    "        #note that we have multiple BNs in a group, \n",
    "        # we store layer-wise scores in a list and then reduce them to get the final results\n",
    "        group_imp = [] # (num_bns, num_channels) \n",
    "        # 1. iterate the group to estimate importance\n",
    "        for dep, idxs in group:\n",
    "            layer = dep.target.module # get the target model\n",
    "            prune_fn = dep.handler    # get the pruning function of target model, unused in this example\n",
    "            if isinstance(layer, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)) and layer.affine:\n",
    "                local_imp = torch.abs(layer.weight.data)\n",
    "                group_imp.append(local_imp)\n",
    "        if len(group_imp)==0: return None # return None if the group contains no BN layer\n",
    "        # 2. reduce your group importance to a 1-D scroe vector. Here we use the average score across layers.\n",
    "        group_imp = torch.stack(group_imp, dim=0).mean(dim=0) \n",
    "        return group_imp # (num_channels, )\n",
    "\n",
    "# You can implement any importance functions, as long as it transforms a group to a 1-D score vector.\n",
    "class MinimumChannelImportance(tp.importance.Importance):\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, group, **kwargs):\n",
    "        _, idxs = group[0]\n",
    "        return torch.rand(len(idxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e1e073",
   "metadata": {},
   "source": [
    "### 3. Pruning\n",
    "Now let's leverage the customized pruner to slim a resnet-18 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "762220da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True)\n",
    "example_inputs = torch.randn(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b68e113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. importance criterion \n",
    "imp = MinimumChannelImportance()\n",
    "\n",
    "# 1. ignore some layers that should not be pruned, e.g., the final classifier layer.\n",
    "ignored_layers = []\n",
    "for m in model.modules():\n",
    "    if isinstance(m, torch.nn.Linear) and m.out_features == 1000:\n",
    "        ignored_layers.append(m) # DO NOT prune the final classifier!\n",
    "\n",
    "# 2. Pruner initialization\n",
    "iterative_steps = 5 # You can prune your model to the target sparsity iteratively.\n",
    "pruner = MySimplePruner(\n",
    "    model, \n",
    "    example_inputs, \n",
    "    global_pruning=False, # If False, a uniform sparsity will be assigned to different layers.\n",
    "    importance=imp, # importance criterion for parameter selection\n",
    "    iterative_steps=iterative_steps, # the number of iterations to achieve target sparsity\n",
    "    ch_sparsity=0.5, # remove 50% channels, ResNet18 = {64, 128, 256, 512} => ResNet18_Half = {32, 64, 128, 256}\n",
    "    ignored_layers=ignored_layers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4b5b2",
   "metadata": {},
   "source": [
    "Sparse training with ``pruner.regularize``. Rember to regularize the model before ``optimizer.step()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fb7344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for _ in range(100):\n",
    "    pass\n",
    "    # optimizer.zero_grad()\n",
    "    # ...\n",
    "    # loss.backward()\n",
    "    # pruner.regularize(model, reg=1e-5)\n",
    "    # optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc447ab6",
   "metadata": {},
   "source": [
    "Pruning and finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab5ee265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer4.0.downsample.0 [445, 19, 340, 341, 370, 181, 86, 358, 329, 60, 46, 27, 170, 476, 208, 115, 167, 142, 446, 299, 395, 101, 281, 463, 70, 52, 293, 259, 401, 229, 74, 265, 116, 66, 280, 16, 76, 107, 219, 39, 197, 279, 286, 367, 73, 190, 133, 160, 450, 248, 489, 251]\n",
      "layer3.0.downsample.0 [228, 109, 164, 243, 22, 149, 147, 205, 170, 218, 61, 183, 2, 220, 223, 86, 181, 4, 16, 38, 95, 136, 80, 56, 72, 192]\n",
      "layer2.0.downsample.0 [16, 43, 7, 118, 37, 31, 28, 15, 88, 123, 47, 61, 11]\n",
      "conv1 [58, 18, 47, 24, 36, 2, 39]\n",
      "layer1.0.conv1 [31, 35, 45, 36, 13, 42, 62]\n",
      "layer1.1.conv1 [15, 55, 34, 12, 61, 27, 41]\n",
      "layer2.0.conv1 [97, 8, 67, 11, 95, 4, 76, 69, 115, 53, 121, 10, 49]\n",
      "layer2.1.conv1 [83, 88, 71, 78, 92, 40, 32, 10, 38, 16, 37, 65, 89]\n",
      "layer3.0.conv1 [112, 81, 61, 224, 116, 59, 93, 43, 31, 42, 180, 14, 151, 0, 107, 186, 119, 7, 77, 148, 252, 73, 167, 36, 235, 214]\n",
      "layer3.1.conv1 [242, 240, 71, 18, 174, 106, 60, 211, 154, 241, 62, 133, 247, 52, 2, 235, 141, 39, 135, 166, 113, 178, 207, 6, 255, 17]\n",
      "layer4.0.conv1 [260, 417, 511, 353, 450, 277, 375, 303, 388, 395, 146, 336, 138, 332, 42, 394, 458, 168, 118, 377, 310, 363, 444, 1, 397, 342, 266, 190, 222, 284, 447, 145, 464, 427, 53, 274, 407, 166, 320, 355, 150, 376, 24, 430, 36, 459, 59, 437, 251, 174, 489, 364]\n",
      "layer4.1.conv1 [457, 331, 369, 373, 115, 341, 404, 351, 261, 409, 438, 216, 230, 313, 416, 275, 149, 100, 446, 212, 87, 227, 278, 131, 353, 165, 501, 172, 477, 143, 226, 288, 348, 117, 127, 455, 379, 306, 42, 394, 45, 368, 235, 407, 354, 239, 181, 388, 71, 184, 222, 247]\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 57, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(57, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(57, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(57, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(57, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(57, 115, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(115, 115, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(57, 115, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(115, 115, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(115, 115, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(115, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(115, 230, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(230, 230, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(115, 230, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(230, 230, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(230, 230, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(230, 460, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(460, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(460, 460, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(460, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(230, 460, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(460, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(460, 460, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(460, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(460, 460, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(460, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=460, out_features=1000, bias=True)\n",
      ")\n",
      "torch.Size([1, 1000])\n",
      "  Iter 1/5, Params: 11.69 M => 9.48 M\n",
      "  Iter 1/5, MACs: 1.82 G => 1.47 G\n",
      "================\n",
      "layer4.0.downsample.0 [145, 419, 213, 79, 368, 11, 161, 319, 346, 246, 406, 20, 404, 83, 66, 207, 160, 296, 33, 218, 436, 441, 200, 423, 412, 107, 255, 302, 181, 300, 75, 452, 93, 370, 53, 194, 243, 435, 129, 256, 242, 282, 397, 119, 63, 206, 447, 14, 138, 306, 280]\n",
      "layer3.0.downsample.0 [41, 26, 132, 189, 223, 200, 91, 222, 31, 76, 107, 118, 121, 38, 72, 176, 103, 220, 192, 71, 68, 36, 214, 144, 74, 208]\n",
      "layer2.0.downsample.0 [93, 72, 114, 96, 70, 67, 44, 84, 104, 37, 45, 50, 18]\n",
      "conv1 [4, 47, 14, 20, 40, 13]\n",
      "layer1.0.conv1 [42, 54, 23, 18, 25, 38]\n",
      "layer1.1.conv1 [53, 25, 5, 51, 23, 18]\n",
      "layer2.0.conv1 [23, 56, 13, 1, 104, 35, 77, 28, 9, 20, 74, 89, 42]\n",
      "layer2.1.conv1 [96, 109, 33, 108, 70, 12, 81, 110, 74, 37, 111, 64, 23]\n",
      "layer3.0.conv1 [185, 161, 134, 41, 181, 6, 9, 65, 186, 99, 152, 28, 111, 7, 31, 169, 213, 220, 197, 180, 39, 151, 222, 27, 158, 50]\n",
      "layer3.1.conv1 [141, 181, 52, 68, 156, 137, 98, 65, 174, 55, 145, 46, 190, 213, 168, 57, 106, 112, 222, 157, 14, 85, 58, 163, 70, 226]\n",
      "layer4.0.conv1 [198, 114, 162, 24, 231, 0, 303, 137, 11, 368, 429, 237, 265, 302, 161, 335, 448, 442, 437, 411, 312, 67, 263, 436, 215, 183, 212, 236, 348, 25, 271, 124, 136, 258, 153, 378, 306, 89, 261, 193, 80, 64, 450, 148, 373, 220, 226, 451, 290, 22, 169]\n",
      "layer4.1.conv1 [374, 361, 455, 45, 116, 183, 19, 441, 392, 168, 288, 149, 82, 155, 245, 446, 396, 395, 450, 189, 55, 195, 0, 266, 124, 147, 218, 384, 110, 16, 198, 265, 191, 328, 1, 23, 88, 315, 152, 4, 84, 230, 193, 369, 242, 66, 351, 448, 216, 81, 382]\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 51, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(51, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(51, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(51, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(51, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(51, 102, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(102, 102, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(51, 102, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(102, 102, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(102, 102, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(102, 204, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(204, 204, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(102, 204, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(204, 204, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(204, 204, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(204, 409, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(409, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(409, 409, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(409, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(204, 409, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(409, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(409, 409, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(409, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(409, 409, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(409, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=409, out_features=1000, bias=True)\n",
      ")\n",
      "torch.Size([1, 1000])\n",
      "  Iter 2/5, Params: 11.69 M => 7.53 M\n",
      "  Iter 2/5, MACs: 1.82 G => 1.18 G\n",
      "================\n",
      "layer4.0.downsample.0 [407, 342, 139, 124, 101, 108, 247, 160, 206, 372, 60, 158, 249, 276, 63, 176, 294, 188, 106, 345, 127, 157, 347, 174, 264, 389, 172, 189, 58, 163, 68, 110, 307, 180, 87, 120, 236, 267, 378, 112, 49, 25, 366, 311, 30, 304, 278, 61, 77, 105, 263]\n",
      "layer3.0.downsample.0 [144, 54, 157, 26, 113, 36, 175, 41, 58, 65, 178, 104, 164, 98, 112, 163, 14, 49, 195, 15, 9, 44, 153, 122, 117]\n",
      "layer2.0.downsample.0 [37, 73, 87, 2, 20, 55, 94, 12, 85, 71, 18, 57, 7]\n",
      "conv1 [36, 31, 32, 38, 35, 46, 42]\n",
      "layer1.0.conv1 [48, 15, 43, 17, 49, 14, 2]\n",
      "layer1.1.conv1 [13, 16, 1, 30, 37, 8, 26]\n",
      "layer2.0.conv1 [54, 99, 66, 67, 36, 62, 32, 41, 35, 23, 55, 96, 70]\n",
      "layer2.1.conv1 [94, 42, 31, 100, 92, 5, 62, 68, 56, 83, 75, 99, 52]\n",
      "layer3.0.conv1 [31, 51, 97, 73, 1, 140, 6, 151, 143, 96, 27, 8, 121, 154, 87, 4, 104, 40, 200, 174, 161, 58, 126, 80, 48]\n",
      "layer3.1.conv1 [202, 2, 151, 96, 33, 54, 161, 32, 145, 41, 187, 108, 179, 9, 95, 137, 30, 147, 47, 128, 140, 155, 150, 157, 11]\n",
      "layer4.0.conv1 [250, 91, 327, 160, 309, 38, 229, 296, 182, 355, 365, 252, 211, 3, 78, 55, 63, 57, 142, 304, 224, 26, 331, 371, 222, 253, 219, 349, 227, 226, 336, 266, 34, 62, 110, 180, 357, 103, 221, 230, 290, 115, 154, 30, 206, 192, 32, 383, 214, 359, 74]\n",
      "layer4.1.conv1 [39, 394, 154, 94, 388, 272, 85, 333, 379, 210, 72, 25, 88, 98, 140, 320, 104, 315, 124, 183, 342, 63, 15, 291, 68, 87, 376, 146, 65, 148, 195, 81, 318, 226, 18, 284, 156, 269, 282, 176, 249, 74, 125, 276, 2, 254, 391, 143, 392, 96, 314]\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 44, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(44, 89, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(89, 89, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(44, 89, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(89, 89, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(89, 89, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(89, 179, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(179, 179, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(89, 179, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(179, 179, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(179, 179, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(179, 358, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(358, 358, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(179, 358, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(358, 358, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(358, 358, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=358, out_features=1000, bias=True)\n",
      ")\n",
      "torch.Size([1, 1000])\n",
      "  Iter 3/5, Params: 11.69 M => 5.82 M\n",
      "  Iter 3/5, MACs: 1.82 G => 0.91 G\n",
      "================\n",
      "layer4.0.downsample.0 [320, 9, 184, 182, 220, 302, 82, 185, 12, 165, 247, 285, 295, 62, 205, 246, 144, 357, 312, 47, 2, 67, 139, 338, 221, 21, 253, 161, 77, 87, 287, 93, 262, 131, 216, 36, 224, 64, 102, 229, 1, 194, 325, 154, 160, 56, 353, 158, 85, 15, 150]\n",
      "layer3.0.downsample.0 [153, 15, 116, 105, 36, 114, 117, 123, 45, 163, 41, 44, 68, 93, 66, 175, 27, 162, 24, 102, 125, 104, 158, 63, 78, 84]\n",
      "layer2.0.downsample.0 [51, 70, 52, 37, 3, 49, 85, 79, 6, 56, 77, 81, 65]\n",
      "conv1 [4, 6, 18, 20, 10, 23]\n",
      "layer1.0.conv1 [17, 11, 5, 35, 34, 13]\n",
      "layer1.1.conv1 [4, 42, 34, 38, 18, 32]\n",
      "layer2.0.conv1 [4, 9, 78, 28, 67, 55, 66, 17, 26, 40, 7, 53, 70]\n",
      "layer2.1.conv1 [60, 48, 38, 27, 18, 47, 58, 9, 88, 14, 26, 32, 82]\n",
      "layer3.0.conv1 [142, 146, 111, 37, 97, 9, 159, 172, 50, 24, 63, 96, 176, 158, 139, 1, 48, 47, 70, 15, 36, 167, 99, 0, 166, 79]\n",
      "layer3.1.conv1 [59, 7, 85, 31, 57, 141, 14, 176, 46, 0, 21, 160, 11, 12, 155, 64, 70, 157, 19, 104, 49, 121, 106, 93, 40, 94]\n",
      "layer4.0.conv1 [263, 183, 98, 136, 247, 198, 167, 287, 4, 47, 215, 12, 271, 97, 113, 46, 301, 133, 48, 224, 155, 129, 9, 312, 145, 200, 306, 251, 189, 285, 245, 267, 262, 17, 69, 27, 74, 344, 316, 223, 102, 193, 199, 54, 87, 29, 328, 148, 89, 42, 300]\n",
      "layer4.1.conv1 [331, 163, 24, 118, 93, 195, 217, 188, 2, 110, 176, 296, 356, 318, 304, 260, 36, 266, 190, 230, 352, 256, 235, 132, 231, 21, 58, 131, 100, 172, 185, 179, 334, 129, 101, 153, 70, 52, 257, 120, 233, 35, 92, 86, 344, 42, 155, 198, 8, 351, 99]\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 38, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(38, 76, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(76, 76, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(38, 76, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(76, 76, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(76, 76, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(76, 153, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(153, 153, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(76, 153, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(153, 153, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(153, 153, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(153, 307, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(307, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(307, 307, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(307, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(153, 307, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(307, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(307, 307, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(307, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(307, 307, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(307, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=307, out_features=1000, bias=True)\n",
      ")\n",
      "torch.Size([1, 1000])\n",
      "  Iter 4/5, Params: 11.69 M => 4.32 M\n",
      "  Iter 4/5, MACs: 1.82 G => 0.68 G\n",
      "================\n",
      "layer4.0.downsample.0 [144, 188, 293, 282, 103, 193, 233, 133, 247, 251, 236, 70, 143, 172, 286, 287, 278, 296, 86, 15, 190, 91, 125, 155, 110, 292, 22, 81, 116, 205, 211, 128, 160, 189, 174, 178, 11, 77, 229, 25, 197, 14, 291, 196, 163, 300, 209, 161, 274, 148, 289]\n",
      "layer3.0.downsample.0 [27, 4, 20, 136, 61, 120, 52, 81, 96, 15, 138, 86, 13, 142, 21, 112, 115, 123, 93, 32, 151, 107, 105, 149, 18]\n",
      "layer2.0.downsample.0 [72, 67, 46, 35, 63, 73, 5, 61, 45, 20, 21, 48]\n",
      "conv1 [34, 3, 9, 5, 7, 23]\n",
      "layer1.0.conv1 [21, 0, 33, 19, 2, 8]\n",
      "layer1.1.conv1 [27, 36, 32, 10, 25, 26]\n",
      "layer2.0.conv1 [16, 43, 47, 6, 68, 24, 23, 41, 15, 29, 67, 63]\n",
      "layer2.1.conv1 [42, 7, 17, 54, 6, 24, 4, 23, 65, 59, 13, 10]\n",
      "layer3.0.conv1 [64, 56, 77, 104, 29, 33, 152, 34, 16, 9, 63, 144, 125, 122, 89, 119, 42, 40, 26, 118, 81, 36, 123, 60, 27]\n",
      "layer3.1.conv1 [113, 55, 40, 21, 52, 48, 61, 2, 118, 5, 126, 116, 81, 139, 70, 86, 134, 14, 8, 150, 25, 82, 67, 62, 18]\n",
      "layer4.0.conv1 [105, 21, 259, 257, 56, 256, 72, 37, 215, 190, 29, 36, 293, 223, 25, 241, 110, 181, 197, 69, 47, 42, 98, 198, 52, 24, 298, 186, 161, 90, 208, 204, 242, 192, 22, 163, 84, 244, 144, 1, 133, 160, 125, 182, 11, 209, 76, 32, 207, 143, 225]\n",
      "layer4.1.conv1 [79, 171, 284, 293, 262, 37, 150, 203, 4, 214, 17, 12, 260, 287, 177, 213, 281, 11, 259, 204, 58, 254, 20, 176, 21, 10, 104, 277, 149, 27, 63, 133, 55, 64, 302, 72, 16, 264, 89, 40, 54, 291, 180, 297, 166, 274, 296, 23, 173, 122, 91]\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=256, out_features=1000, bias=True)\n",
      ")\n",
      "torch.Size([1, 1000])\n",
      "  Iter 5/5, Params: 11.69 M => 3.06 M\n",
      "  Iter 5/5, MACs: 1.82 G => 0.49 G\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "base_macs, base_nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "for i in range(iterative_steps):\n",
    "    pruner.step()\n",
    "\n",
    "    macs, nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "    print(model)\n",
    "    print(model(example_inputs).shape)\n",
    "    print(\n",
    "        \"  Iter %d/%d, Params: %.2f M => %.2f M\"\n",
    "        % (i+1, iterative_steps, base_nparams / 1e6, nparams / 1e6)\n",
    "    )\n",
    "    print(\n",
    "        \"  Iter %d/%d, MACs: %.2f G => %.2f G\"\n",
    "        % (i+1, iterative_steps, base_macs / 1e9, macs / 1e9)\n",
    "    )\n",
    "    print(\"=\"*16)\n",
    "    # finetune your model here\n",
    "    # finetune(model)\n",
    "    # ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
