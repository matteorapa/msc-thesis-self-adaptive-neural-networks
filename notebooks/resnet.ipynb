{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "spatial-pitch",
      "metadata": {
        "id": "spatial-pitch"
      },
      "source": [
        "*Author: Pytorch Team*\n",
        "\n",
        "**Deep residual networks pre-trained on ImageNet**\n",
        "\n",
        "<img src=\"https://pytorch.org/assets/images/resnet.png\" alt=\"alt\" width=\"50%\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "celtic-scenario",
      "metadata": {
        "id": "celtic-scenario"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to C:\\Users\\35679/.cache\\torch\\hub\\v0.10.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\35679/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "203e2a92bc69451393d8b3ee1ce89fc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "# or any of these variants\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rising-replica",
      "metadata": {
        "id": "rising-replica"
      },
      "source": [
        "All pre-trained models expect input images normalized in the same way,\n",
        "i.e. mini-batches of 3-channel RGB images of shape `(3 x H x W)`, where `H` and `W` are expected to be at least `224`.\n",
        "The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]`\n",
        "and `std = [0.229, 0.224, 0.225]`.\n",
        "\n",
        "Here's a sample execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "abandoned-stretch",
      "metadata": {
        "id": "abandoned-stretch"
      },
      "outputs": [],
      "source": [
        "# Download an example image from the pytorch website\n",
        "import urllib\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "try: urllib.URLopener().retrieve(url, filename)\n",
        "except: urllib.request.urlretrieve(url, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "imperial-credits",
      "metadata": {
        "id": "imperial-credits"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 1.5089e-02, -1.5503e+00,  3.1961e-01, -2.0598e+00, -8.5831e-01,\n",
            "         1.7848e+00,  1.4685e+00,  2.1620e+00,  4.4893e+00,  8.2984e-01,\n",
            "        -5.7814e+00, -3.4978e+00, -4.0642e+00, -4.7533e+00, -3.8090e+00,\n",
            "        -4.7252e+00, -1.2615e+00,  2.9549e-01, -2.0475e+00, -5.3074e-01,\n",
            "        -3.5979e+00, -8.1635e-01, -2.7669e+00, -1.2771e+00, -3.4197e+00,\n",
            "        -1.9057e+00, -3.0022e+00, -1.3482e+00, -1.8409e+00,  1.3930e+00,\n",
            "        -2.0119e+00, -1.4140e+00, -2.3277e+00, -1.8197e+00, -1.1829e-01,\n",
            "        -3.4102e+00, -1.6543e+00, -3.4496e+00, -2.6464e+00, -2.7419e+00,\n",
            "        -2.2194e+00, -3.6504e+00, -4.1260e+00, -5.5951e+00, -1.7523e+00,\n",
            "        -1.6901e+00, -9.8184e-01, -2.1237e+00, -3.5146e+00, -1.3338e+00,\n",
            "        -1.1355e+00, -1.1558e+00, -2.2381e-02, -8.5839e-01, -1.2910e+00,\n",
            "        -2.8687e+00,  6.6053e-01, -1.7175e+00, -1.2442e+00, -2.3368e+00,\n",
            "        -5.8092e-02, -1.9202e+00, -2.5973e+00, -1.8028e+00, -1.5124e+00,\n",
            "        -1.0848e+00, -4.0898e-01, -1.3092e+00, -9.4153e-01, -4.0614e+00,\n",
            "        -1.9027e+00, -6.0960e-01, -2.3423e+00, -2.5535e+00, -2.7564e+00,\n",
            "        -2.1582e+00, -3.0444e+00, -3.8206e+00,  1.9946e+00,  8.0646e-01,\n",
            "        -2.8855e+00, -4.6220e-01, -1.9102e+00, -1.8594e+00, -1.9820e-01,\n",
            "        -7.4742e-01, -2.3896e+00, -1.1257e+00, -2.0507e+00,  2.2934e+00,\n",
            "        -2.6399e+00, -3.6726e+00, -4.7534e+00, -2.8061e+00, -1.9315e+00,\n",
            "        -4.6477e+00, -2.5205e+00, -2.4846e+00, -3.0078e+00, -4.8750e-01,\n",
            "        -9.3596e-01, -2.6070e+00,  2.1369e+00, -2.6334e+00,  8.3523e+00,\n",
            "         8.9612e-01,  3.7529e+00, -3.4316e+00, -1.8965e+00, -4.2932e+00,\n",
            "         2.8991e-01, -2.3315e+00,  2.3837e+00,  4.2821e-02,  2.2145e-01,\n",
            "         7.5270e-01, -3.3090e+00, -1.4754e+00, -1.1794e+00, -1.9246e+00,\n",
            "        -1.8424e+00, -1.2782e+00, -1.0876e+00, -9.9690e-01,  1.5086e-01,\n",
            "        -1.4337e+00, -1.8056e+00,  1.0746e+00, -1.8637e+00,  2.6137e-01,\n",
            "        -1.5027e+00, -4.6542e+00, -1.9520e+00, -6.8755e+00, -1.6434e+00,\n",
            "        -3.2280e+00, -3.2745e+00, -3.8378e+00, -2.1750e+00, -3.5039e+00,\n",
            "        -4.7021e+00, -3.6273e+00, -4.8849e+00, -1.9907e+00,  2.6570e-01,\n",
            "        -6.7328e-01,  9.3662e-01, -2.2425e+00, -2.1357e+00, -4.7979e-01,\n",
            "        -2.6172e-01,  5.0758e+00,  4.4922e+00,  5.3023e+00,  5.1179e+00,\n",
            "         1.0436e+00,  5.4661e-02,  5.7186e+00,  2.8048e+00, -6.5405e-01,\n",
            "         7.1833e-01, -1.0800e+00, -8.4607e-01, -1.4039e+00, -4.8246e-01,\n",
            "        -4.0580e+00,  2.0822e-02, -1.7142e+00, -2.5374e-01,  5.0043e+00,\n",
            "         6.5728e+00,  3.8879e-01,  1.4274e-01,  3.1350e+00,  6.6803e+00,\n",
            "         2.2404e+00,  4.6953e-01,  3.2942e+00, -8.5201e-01,  1.1064e+00,\n",
            "         1.6827e+00,  3.1527e-02,  2.7648e+00,  1.0104e+00,  3.2896e+00,\n",
            "         6.0653e+00,  7.0660e+00,  5.1553e-01,  3.6303e+00,  2.7645e+00,\n",
            "         3.2239e+00, -9.3868e-01,  6.9447e+00,  4.2813e+00,  2.6166e+00,\n",
            "         1.6067e+00,  4.3809e-01,  1.0879e+00, -3.5366e-01,  6.1557e+00,\n",
            "         2.6471e+00,  1.6050e+00,  2.6773e+00,  1.0348e+01,  2.5253e+00,\n",
            "         8.3491e-01, -1.3490e+00,  5.1936e+00,  2.9660e+00, -5.6781e-01,\n",
            "        -1.4319e+00,  2.9507e-02,  2.4523e+00,  3.0322e-01, -7.7799e-01,\n",
            "         1.6593e+00,  1.9861e+00,  2.0589e+00,  2.6885e-01, -1.8728e-01,\n",
            "         2.7439e-01, -1.7499e+00,  8.8939e+00,  8.1101e+00,  7.3221e+00,\n",
            "         2.8666e+00,  3.7838e+00,  4.1992e+00,  5.8169e+00,  6.1470e+00,\n",
            "         6.4173e+00,  7.6093e+00,  6.9843e+00,  2.9920e+00, -5.2723e-01,\n",
            "         5.5959e+00,  1.4408e+00, -3.9438e-01,  2.0428e+00,  1.8710e+00,\n",
            "         2.0414e+00,  2.0471e-01,  6.4373e-01, -4.0608e-01,  2.5662e+00,\n",
            "         1.2412e+00,  1.4624e+00,  4.1678e+00,  1.0818e+01,  8.7367e+00,\n",
            "         9.9061e+00,  2.8386e+00,  2.0070e-01,  1.7961e+00,  2.3183e+00,\n",
            "         2.5286e+00,  4.4997e+00,  1.1027e+01,  1.6274e+01,  1.1214e+01,\n",
            "         7.8085e+00,  1.0738e+01, -1.0085e-01,  5.7150e+00,  4.7259e+00,\n",
            "         3.3950e+00,  3.0949e+00,  3.8420e+00, -8.0398e-01,  8.1713e+00,\n",
            "         1.3277e+01,  3.4654e+00,  4.4429e+00,  5.5232e+00,  4.1477e+00,\n",
            "        -1.9570e-01,  1.3172e+00,  5.0930e+00,  4.9218e+00,  1.3312e+01,\n",
            "         4.6669e+00,  4.1281e+00,  3.8469e+00,  6.4153e+00,  6.1103e+00,\n",
            "         3.3096e+00,  2.3570e+00,  6.8430e+00,  9.5323e-01,  2.8577e+00,\n",
            "        -1.1242e+00,  1.5071e+00,  1.7616e+00,  1.2521e+00,  2.8543e+00,\n",
            "         1.7456e+00,  6.7804e+00,  2.5113e-01, -1.3356e+00,  5.0939e-01,\n",
            "        -2.8947e+00, -8.2537e-01, -2.9123e+00, -3.0454e+00, -1.1135e+00,\n",
            "        -2.8020e+00, -1.4490e+00, -6.7150e-01, -4.2241e+00, -1.7614e+00,\n",
            "         4.3646e-01, -1.4004e+00, -1.5364e+00, -1.5601e+00,  1.6336e+00,\n",
            "        -2.3879e+00, -2.9757e+00, -4.3681e-01, -5.4994e-01, -6.1558e+00,\n",
            "        -4.0849e+00, -2.3554e+00, -3.9521e+00, -2.8761e+00, -4.5067e-01,\n",
            "        -1.7371e+00, -1.6370e+00,  2.1339e+00, -8.5113e-01, -1.7758e-02,\n",
            "         2.7722e+00,  5.3793e+00,  5.9557e+00,  5.4215e+00,  2.8842e+00,\n",
            "         3.7393e-01,  1.6295e+00,  4.4273e-01,  3.2413e+00,  9.7724e-01,\n",
            "         2.7266e-02,  3.1044e+00, -2.7162e-01, -2.7840e+00, -3.1695e+00,\n",
            "         8.1719e-01, -6.5057e-01, -2.9622e+00,  2.6086e+00, -9.6602e-01,\n",
            "        -9.5437e-01, -4.7034e+00, -3.5780e+00,  2.3157e-01, -2.1670e+00,\n",
            "         6.5026e+00,  5.7227e+00,  2.9794e+00,  6.4621e+00,  5.4999e+00,\n",
            "        -5.3089e-01,  4.7046e+00,  2.8004e+00, -3.5798e-03, -1.3504e+00,\n",
            "        -4.5685e-01, -5.6409e-01, -1.6333e+00,  2.1274e+00, -1.4573e+00,\n",
            "        -3.4309e-03,  9.0454e-01,  1.6575e+00,  2.0594e+00,  1.0802e+00,\n",
            "        -8.2095e-01, -3.6837e+00,  2.5439e+00,  1.4157e+00,  5.3706e-01,\n",
            "         1.0819e+00, -9.6823e-02,  4.5965e-01,  1.0735e+00,  7.6943e-02,\n",
            "        -2.6617e+00, -4.3078e+00,  3.6649e+00,  5.1776e+00, -6.1764e-01,\n",
            "        -1.5431e+00,  7.3337e-01, -3.7433e+00, -2.9979e+00, -5.4950e-01,\n",
            "        -1.9210e+00, -3.7736e+00, -2.9887e+00, -9.2434e-01, -4.2472e-01,\n",
            "        -8.8676e-01, -5.8462e-01, -6.5250e-01, -4.9161e+00, -2.8372e+00,\n",
            "         3.4409e-01, -2.2515e+00, -2.7310e-01, -2.4042e+00, -5.2642e-01,\n",
            "        -2.6057e+00,  3.2462e-01,  4.0671e+00, -2.1194e+00, -5.1580e-01,\n",
            "        -1.7738e+00, -2.0601e+00, -6.6151e-01, -1.4356e+00,  9.8518e-01,\n",
            "         5.7832e-03, -9.6798e-01, -6.0119e-01, -1.4005e+00, -2.0708e+00,\n",
            "         1.1085e+00, -1.9486e+00,  2.2071e+00,  2.9293e+00,  1.8665e+00,\n",
            "        -2.8895e+00, -4.3054e-01, -1.3979e+00, -3.7498e-01,  7.7784e-01,\n",
            "         3.9189e+00, -7.5770e-01, -1.8414e-01, -1.6240e+00,  2.2080e+00,\n",
            "         1.5943e+00,  6.9938e-02,  3.9138e-01,  4.6427e-01,  5.9126e-01,\n",
            "        -9.3088e-02, -5.1362e-01, -1.3619e+00, -1.5019e-01, -5.6865e-01,\n",
            "         2.4670e+00, -1.7127e+00, -1.6868e+00, -3.2554e-01, -8.4231e-01,\n",
            "         2.1132e+00, -8.2538e-02,  1.7843e+00, -6.3572e-01, -7.4654e-01,\n",
            "         4.2896e-01, -5.1209e-01,  3.4114e+00,  5.7135e+00, -1.2809e+00,\n",
            "        -1.6499e+00, -2.5273e+00, -3.1736e+00, -1.0123e+00,  9.4708e-01,\n",
            "         9.9356e-01, -1.0825e-01,  2.5826e+00,  1.4921e+00, -1.2992e+00,\n",
            "        -2.8235e-01, -8.6317e-01, -1.4717e-01,  1.7307e+00,  2.4509e+00,\n",
            "        -7.3500e-01, -2.5547e+00, -1.9144e+00,  1.7057e-01,  3.2730e-01,\n",
            "        -1.3449e+00, -1.5284e+00, -7.6564e-01, -7.8829e-01,  1.0065e+00,\n",
            "        -1.2147e+00,  1.4785e+00, -2.7494e-01, -1.3608e+00, -1.7720e-01,\n",
            "        -1.1744e+00,  2.3971e+00, -6.7845e-01, -2.6893e+00,  7.6372e-02,\n",
            "        -3.4516e+00,  1.2129e+00,  1.2666e+00, -1.0994e+00,  2.7978e-01,\n",
            "        -9.9938e-01, -2.0038e+00,  7.5339e-01,  2.4312e+00, -1.7241e+00,\n",
            "        -7.9219e-02,  8.8602e-01, -4.0895e-01, -2.4657e+00, -1.2013e+00,\n",
            "         5.4756e-01, -1.6016e+00, -2.4269e+00,  5.5474e-01, -3.8118e-01,\n",
            "        -2.0493e+00,  3.3756e+00,  3.1898e+00,  6.6950e-01, -6.8569e-01,\n",
            "        -9.4572e-01, -3.6390e-01, -7.6092e-01,  2.1828e+00,  8.0150e-01,\n",
            "        -1.0051e+00, -1.2829e+00, -2.3665e+00, -3.1691e+00,  2.1268e+00,\n",
            "         1.2682e-01, -1.6894e+00,  2.6969e+00, -3.0821e+00,  4.0309e+00,\n",
            "        -2.8324e+00,  3.3930e-01,  9.7703e-03,  5.2645e-01,  1.9743e+00,\n",
            "        -7.0858e-02,  2.9061e-01, -2.9110e+00, -2.4003e+00,  7.0144e-01,\n",
            "        -4.1847e+00,  4.7540e-01,  1.1468e+00, -6.1558e-01, -7.0932e-01,\n",
            "        -3.9957e-01, -3.3671e-01, -6.5570e-01, -2.2188e+00,  1.5335e+00,\n",
            "         1.2745e+00,  2.7891e-01, -2.2749e+00, -5.5984e-01, -3.7193e+00,\n",
            "        -2.9075e+00, -6.8712e-01,  9.5426e-02,  1.8665e+00, -8.5107e-01,\n",
            "        -8.4564e-01, -3.8518e+00,  3.4205e-01,  2.5445e-01,  2.6894e+00,\n",
            "         2.6179e-01, -2.0000e+00,  5.3832e-01,  1.0983e+00, -1.3292e+00,\n",
            "         1.4832e+00, -5.9421e-01, -2.0442e+00, -1.2366e+00,  1.0516e+00,\n",
            "         6.4951e-01, -6.2277e-02,  1.2360e+00,  6.8306e-01,  3.8257e+00,\n",
            "        -1.7963e+00, -6.7169e-01, -2.5599e+00, -1.6516e+00,  1.1819e+00,\n",
            "        -1.2911e+00,  2.2565e+00, -4.0462e-01, -1.1869e+00, -2.3762e+00,\n",
            "         8.0003e-01, -9.1854e-01, -1.6106e+00, -1.9349e+00, -3.9244e+00,\n",
            "        -2.1014e+00,  2.1315e+00, -2.5614e-01,  4.8893e-01, -6.0480e-01,\n",
            "         1.1582e+00,  1.8458e+00, -4.0934e+00,  2.7059e-01, -2.1229e-01,\n",
            "         1.3762e+00, -1.4055e+00, -1.0374e+00,  4.6284e-02, -1.2730e-01,\n",
            "         3.3108e-01,  1.8635e+00,  3.2689e+00, -3.5499e-01, -2.1398e+00,\n",
            "        -4.3078e-01,  7.7586e-01,  3.6606e-02, -2.0641e+00,  3.1169e-01,\n",
            "         1.6394e+00,  2.6679e+00,  2.7177e-01,  8.3626e-01, -2.9801e+00,\n",
            "        -2.4562e-01,  2.4830e-01,  1.3197e-01, -4.3360e-01, -4.3010e-01,\n",
            "         6.5687e-01,  2.1315e+00, -3.2668e+00, -5.1006e-01,  4.9260e-01,\n",
            "        -1.8918e+00,  1.8285e+00, -1.6702e+00,  6.3079e-01, -1.6440e+00,\n",
            "        -1.6577e+00, -1.3680e-03, -6.8751e-01,  2.0158e+00, -4.9094e-01,\n",
            "         7.9189e-01, -6.6019e-01, -1.4459e+00,  5.7425e-01,  2.2909e-01,\n",
            "        -2.9924e-01, -2.0784e+00, -9.1709e-01, -1.9480e+00,  8.3736e-01,\n",
            "         1.2708e+00, -9.1410e-01,  5.4735e-01, -3.6872e+00, -9.1356e-01,\n",
            "         1.9879e+00, -2.5386e-01,  2.8573e-01,  2.0951e+00,  1.2078e+00,\n",
            "         2.1141e-01,  3.4620e+00,  9.4110e-02, -8.0212e-01,  2.7200e-01,\n",
            "         1.2201e+00,  7.2187e-01, -2.8352e+00, -2.7137e+00,  4.7930e-01,\n",
            "        -1.8520e+00,  2.9695e-01, -4.1017e+00,  1.8296e-01, -7.9838e-01,\n",
            "        -1.7312e+00, -9.6659e-01, -5.8278e-01, -8.2906e-01, -9.9303e-02,\n",
            "        -5.0542e-01,  1.5542e+00,  1.4926e+00, -1.2965e+00, -1.0700e-01,\n",
            "         2.9906e+00, -1.3597e+00, -3.7223e+00,  9.1916e-01, -2.5763e+00,\n",
            "        -3.0642e+00,  1.3368e+00, -1.4009e+00, -3.5363e-01, -1.1706e+00,\n",
            "        -7.4927e-01, -2.6048e-01, -6.0201e-01, -1.5579e+00,  1.3911e+00,\n",
            "        -2.3786e+00,  1.9798e+00,  3.3174e-01, -1.0211e-01,  2.4428e+00,\n",
            "         1.2637e+00, -6.6251e-01,  2.2867e+00,  1.8505e+00, -2.9047e+00,\n",
            "        -5.7559e-01, -5.1068e+00, -2.6340e+00,  2.1389e+00, -1.3484e+00,\n",
            "        -2.2585e+00,  4.3965e+00, -2.2585e+00, -1.0232e+00, -3.2031e+00,\n",
            "         6.7246e-01, -1.9910e+00, -2.0743e-01,  4.0507e-01, -2.9343e+00,\n",
            "         1.5755e+00, -9.1958e-01,  1.1540e+00, -9.1342e-01, -1.2571e+00,\n",
            "        -1.9492e+00,  1.0353e+00,  8.4013e-01,  1.6415e+00,  1.3329e+00,\n",
            "         7.9255e-01,  7.8857e-01,  1.2217e+00,  1.3783e+00, -7.8063e-01,\n",
            "        -1.3650e+00,  5.3839e+00,  5.1459e-01,  4.9063e-01,  5.2539e-01,\n",
            "         7.3335e-01,  2.2726e+00, -1.3190e+00,  9.3388e-01, -1.6301e+00,\n",
            "         2.4308e-01, -2.4952e-01, -4.8609e-01,  2.1128e+00,  1.4493e+00,\n",
            "         3.7127e-01,  1.3994e+00,  1.5164e+00, -3.6139e-01,  2.8896e-01,\n",
            "        -9.3996e-01, -2.2428e+00, -4.9513e-01, -4.6024e-01, -2.1171e+00,\n",
            "        -2.6525e+00, -4.1990e-01,  1.4907e+00,  6.6772e-01,  1.0794e+00,\n",
            "        -2.9806e-01,  1.3684e+00,  7.1110e-01,  2.7850e-01,  3.7345e-02,\n",
            "        -1.5737e+00,  6.9205e-01,  1.3082e+00, -6.9068e-01,  8.7272e-02,\n",
            "        -4.8735e-01, -1.4146e+00,  2.3658e+00, -8.0643e-01,  7.6389e-01,\n",
            "        -4.9401e+00, -6.1562e-01, -4.6367e-01, -2.4241e+00,  1.1555e+00,\n",
            "         6.3769e+00,  9.0726e-01, -4.1319e-01, -1.3369e+00,  2.3592e-01,\n",
            "         1.4638e+00,  2.6395e+00, -1.3031e+00,  8.5328e-01, -3.5964e-01,\n",
            "        -9.9014e-01, -1.2842e+00,  5.6059e-01,  2.1377e-02, -8.9593e-01,\n",
            "        -6.9279e-01, -1.9416e+00, -6.7488e-01,  1.2530e+00,  1.3381e+00,\n",
            "         8.7613e-01, -4.7763e-01,  1.7543e+00,  5.0886e-01, -1.3915e+00,\n",
            "        -8.7733e-01,  1.1601e+00, -1.0184e+00, -1.3266e+00, -3.7243e-01,\n",
            "        -1.0474e+00,  5.7442e-01,  1.5571e+00,  1.8509e+00, -4.1199e-01,\n",
            "        -2.0713e-01,  1.0543e+00,  1.8595e+00,  4.5602e-01,  9.1576e-01,\n",
            "         1.1516e+00, -1.4325e+00, -5.3119e-01, -1.4746e+00, -1.0064e+00,\n",
            "         1.2266e+00,  1.5212e+00,  5.0181e+00, -1.5196e+00, -5.4019e-01,\n",
            "        -6.5511e-01, -1.8706e+00, -3.6347e+00, -1.0427e+00,  6.9907e-02,\n",
            "        -2.3706e+00,  2.4605e+00, -1.2995e-01, -1.7974e+00, -7.5405e-01,\n",
            "        -1.0343e+00, -1.3364e+00, -2.9556e-01, -8.2861e-01,  2.7099e-01,\n",
            "         1.5895e+00, -7.2387e-01, -2.9648e-01, -9.2953e-01, -2.4288e+00,\n",
            "        -9.2227e-01,  4.7515e+00, -1.6791e+00,  8.6921e-01,  7.8092e-01,\n",
            "         1.6632e+00, -1.0690e+00,  1.3575e+00, -8.2498e-01, -1.9552e+00,\n",
            "         4.4923e-01, -2.2728e+00, -1.9737e+00, -1.3134e+00,  7.5424e-02,\n",
            "        -6.2426e-01, -1.2938e+00, -7.9296e-01,  1.4129e-01, -5.3698e-01,\n",
            "        -3.7495e+00,  2.5782e+00,  2.9508e+00,  1.1151e+00, -7.3136e-02,\n",
            "        -1.0582e+00,  1.7442e-01,  1.4929e+00, -1.3864e+00,  1.2889e+00,\n",
            "        -1.8522e+00, -2.2480e+00,  2.7288e-01, -2.0507e+00, -5.4459e-01,\n",
            "         8.9382e-01,  7.9887e-01,  1.3945e+00, -1.7408e-01, -5.9488e-01,\n",
            "         8.0614e-01, -1.3244e-01, -3.2290e+00, -2.1369e-01, -1.5624e+00,\n",
            "        -2.2854e+00, -3.0849e-01, -4.4388e+00, -6.2376e-01, -2.5398e+00,\n",
            "        -2.4717e+00, -3.3128e+00, -2.8569e+00, -2.9189e+00,  3.9100e+00,\n",
            "        -2.2016e+00, -2.0259e+00, -5.1893e-01, -4.8116e+00, -2.6816e+00,\n",
            "         7.0602e-01, -3.2540e-01,  8.4822e-01,  1.2228e+00,  1.4952e+00,\n",
            "        -1.9164e+00, -3.8726e+00, -4.3381e-01,  2.0182e+00, -2.2138e+00,\n",
            "        -3.7774e+00, -3.2419e+00, -1.0162e+00,  1.8904e+00,  4.7740e-01,\n",
            "        -2.6052e+00, -2.1494e+00, -2.8181e+00, -1.2958e+00, -1.0290e+00,\n",
            "        -2.7631e+00, -1.6160e+00, -4.1305e-01, -1.9207e-01, -2.4870e+00,\n",
            "        -1.3859e+00,  7.6162e-01, -2.6262e+00, -2.1404e+00, -5.1691e+00,\n",
            "        -2.3790e+00, -4.5233e-01, -4.3730e+00, -2.3877e-01, -8.7216e-01,\n",
            "         4.7195e-01,  1.5151e+00, -1.1395e+00, -3.5781e+00, -1.3164e-01,\n",
            "         2.2074e+00, -1.6671e+00,  7.5923e-01, -1.0774e+00, -7.7670e-01,\n",
            "        -6.3071e-01,  1.1797e-01,  1.1369e+00, -1.4193e+00, -8.3176e-01,\n",
            "        -1.6176e+00, -2.2299e+00,  6.9415e-01, -3.4879e+00, -1.4847e+00,\n",
            "        -1.3037e+00, -1.8132e-01, -5.2501e-01, -5.7334e+00, -1.8347e+00,\n",
            "        -6.5456e-01, -1.8079e+00, -2.9132e+00,  5.6145e-01,  2.5130e+00],\n",
            "       device='cuda:0')\n",
            "tensor([7.6827e-08, 1.6057e-08, 1.0418e-07, 9.6468e-09, 3.2078e-08, 4.5092e-07,\n",
            "        3.2863e-07, 6.5751e-07, 6.7397e-06, 1.7352e-07, 2.3341e-10, 2.2903e-09,\n",
            "        1.2999e-09, 6.5255e-10, 1.6778e-09, 6.7120e-10, 2.1433e-08, 1.0169e-07,\n",
            "        9.7667e-09, 4.4511e-08, 2.0720e-09, 3.3452e-08, 4.7569e-09, 2.1102e-08,\n",
            "        2.4763e-09, 1.1255e-08, 3.7595e-09, 1.9654e-08, 1.2008e-08, 3.0474e-07,\n",
            "        1.0121e-08, 1.8402e-08, 7.3798e-09, 1.2265e-08, 6.7234e-08, 2.4999e-09,\n",
            "        1.4471e-08, 2.4034e-09, 5.3658e-09, 4.8771e-09, 8.2240e-09, 1.9662e-09,\n",
            "        1.2220e-09, 2.8121e-10, 1.3121e-08, 1.3963e-08, 2.8350e-08, 9.0504e-09,\n",
            "        2.2521e-09, 1.9939e-08, 2.4312e-08, 2.3823e-08, 7.4002e-08, 3.2075e-08,\n",
            "        2.0810e-08, 4.2962e-09, 1.4650e-07, 1.3585e-08, 2.1808e-08, 7.3131e-09,\n",
            "        7.1406e-08, 1.1093e-08, 5.6358e-09, 1.2475e-08, 1.6678e-08, 2.5575e-08,\n",
            "        5.0274e-08, 2.0435e-08, 2.9516e-08, 1.3035e-09, 1.1289e-08, 4.1135e-08,\n",
            "        7.2730e-09, 5.8880e-09, 4.8068e-09, 8.7430e-09, 3.6040e-09, 1.6583e-09,\n",
            "        5.5618e-07, 1.6951e-07, 4.2249e-09, 4.7668e-08, 1.1204e-08, 1.1788e-08,\n",
            "        6.2070e-08, 3.5839e-08, 6.9373e-09, 2.4551e-08, 9.7351e-09, 7.4987e-07,\n",
            "        5.4010e-09, 1.9229e-09, 6.5254e-10, 4.5741e-09, 1.0968e-08, 7.2526e-10,\n",
            "        6.0859e-09, 6.3086e-09, 3.7383e-09, 4.6478e-08, 2.9681e-08, 5.5818e-09,\n",
            "        6.4124e-07, 5.4364e-09, 3.2085e-04, 1.8541e-07, 3.2273e-06, 2.4470e-09,\n",
            "        1.1358e-08, 1.0338e-09, 1.0113e-07, 7.3517e-09, 8.2072e-07, 7.8987e-08,\n",
            "        9.4436e-08, 1.6064e-07, 2.7663e-09, 1.7307e-08, 2.3269e-08, 1.1043e-08,\n",
            "        1.1990e-08, 2.1080e-08, 2.5506e-08, 2.7926e-08, 8.7999e-08, 1.8043e-08,\n",
            "        1.2439e-08, 2.2164e-07, 1.1737e-08, 9.8282e-08, 1.6840e-08, 7.2055e-10,\n",
            "        1.0745e-08, 7.8159e-11, 1.4630e-08, 2.9995e-09, 2.8632e-09, 1.6302e-09,\n",
            "        8.5971e-09, 2.2763e-09, 6.8683e-10, 2.0121e-09, 5.7210e-10, 1.0338e-08,\n",
            "        9.8708e-08, 3.8598e-08, 1.9308e-07, 8.0365e-09, 8.9425e-09, 4.6837e-08,\n",
            "        5.8250e-08, 1.2116e-05, 6.7594e-06, 1.5195e-05, 1.2637e-05, 2.1488e-07,\n",
            "        7.9928e-08, 2.3041e-05, 1.2505e-06, 3.9347e-08, 1.5521e-07, 2.5699e-08,\n",
            "        3.2473e-08, 1.8589e-08, 4.6712e-08, 1.3080e-09, 7.7269e-08, 1.3629e-08,\n",
            "        5.8717e-08, 1.1280e-05, 5.4137e-05, 1.1164e-07, 8.7288e-08, 1.7398e-06,\n",
            "        6.0280e-05, 7.1111e-07, 1.2103e-07, 2.0398e-06, 3.2280e-08, 2.2881e-07,\n",
            "        4.0713e-07, 7.8100e-08, 1.2014e-06, 2.0786e-07, 2.0305e-06, 3.2591e-05,\n",
            "        8.8652e-05, 1.2672e-07, 2.8549e-06, 1.2011e-06, 1.9015e-06, 2.9600e-08,\n",
            "        7.8527e-05, 5.4743e-06, 1.0360e-06, 3.7736e-07, 1.1728e-07, 2.2462e-07,\n",
            "        5.3134e-08, 3.5672e-05, 1.0680e-06, 3.7670e-07, 1.1007e-06, 2.3613e-03,\n",
            "        9.4553e-07, 1.7440e-07, 1.9638e-08, 1.3630e-05, 1.4692e-06, 4.2891e-08,\n",
            "        1.8077e-08, 7.7943e-08, 8.7901e-07, 1.0248e-07, 3.4760e-08, 3.9771e-07,\n",
            "        5.5144e-07, 5.9311e-07, 9.9019e-08, 6.2752e-08, 9.9570e-08, 1.3151e-08,\n",
            "        5.5151e-04, 2.5184e-04, 1.1453e-04, 1.3302e-06, 3.3285e-06, 5.0424e-06,\n",
            "        2.5422e-05, 3.5364e-05, 4.6340e-05, 1.5263e-04, 8.1700e-05, 1.5079e-06,\n",
            "        4.4667e-08, 2.0382e-05, 3.1967e-07, 5.1013e-08, 5.8363e-07, 4.9152e-07,\n",
            "        5.8280e-07, 9.2868e-08, 1.4406e-07, 5.0420e-08, 9.8499e-07, 2.6182e-07,\n",
            "        3.2664e-07, 4.8865e-06, 3.7757e-03, 4.7125e-04, 1.5175e-03, 1.2935e-06,\n",
            "        9.2496e-08, 4.5604e-07, 7.6874e-07, 9.4869e-07, 6.8102e-06, 4.6542e-03,\n",
            "        8.8482e-01, 5.6128e-03, 1.8628e-04, 3.4879e-03, 6.8417e-08, 2.2959e-05,\n",
            "        8.5384e-06, 2.2562e-06, 1.6714e-06, 3.5278e-06, 3.3869e-08, 2.6773e-04,\n",
            "        4.4184e-02, 2.4208e-06, 6.4338e-06, 1.8951e-05, 4.7893e-06, 6.2226e-08,\n",
            "        2.8249e-07, 1.2326e-05, 1.0387e-05, 4.5733e-02, 8.0491e-06, 4.6964e-06,\n",
            "        3.5454e-06, 4.6248e-05, 3.4091e-05, 2.0717e-06, 7.9912e-07, 7.0929e-05,\n",
            "        1.9631e-07, 1.3184e-06, 2.4587e-08, 3.4157e-07, 4.4058e-07, 2.6469e-07,\n",
            "        1.3139e-06, 4.3359e-07, 6.6627e-05, 9.7280e-08, 1.9903e-08, 1.2595e-07,\n",
            "        4.1861e-09, 3.3152e-08, 4.1130e-09, 3.6007e-09, 2.4853e-08, 4.5927e-09,\n",
            "        1.7769e-08, 3.8666e-08, 1.1078e-09, 1.3002e-08, 1.1709e-07, 1.8653e-08,\n",
            "        1.6283e-08, 1.5900e-08, 3.8764e-07, 6.9490e-09, 3.8603e-09, 4.8894e-08,\n",
            "        4.3664e-08, 1.6052e-10, 1.2733e-09, 7.1786e-09, 1.4541e-09, 4.2646e-09,\n",
            "        4.8221e-08, 1.3321e-08, 1.4724e-08, 6.3932e-07, 3.2309e-08, 7.4345e-08,\n",
            "        1.2104e-06, 1.6411e-05, 2.9206e-05, 1.7120e-05, 1.3538e-06, 1.0999e-07,\n",
            "        3.8606e-07, 1.1783e-07, 1.9348e-06, 2.0108e-07, 7.7768e-08, 1.6872e-06,\n",
            "        5.7676e-08, 4.6763e-09, 3.1803e-09, 1.7134e-07, 3.9484e-08, 3.9128e-09,\n",
            "        1.0277e-06, 2.8802e-08, 2.9140e-08, 6.8597e-10, 2.1138e-09, 9.5397e-08,\n",
            "        8.6666e-09, 5.0465e-05, 2.3137e-05, 1.4890e-06, 4.8464e-05, 1.8515e-05,\n",
            "        4.4504e-08, 8.3590e-06, 1.2450e-06, 7.5406e-08, 1.9610e-08, 4.7924e-08,\n",
            "        4.3050e-08, 1.4779e-08, 6.3515e-07, 1.7622e-08, 7.5417e-08, 1.8698e-07,\n",
            "        3.9701e-07, 5.9338e-07, 2.2288e-07, 3.3299e-08, 1.9016e-09, 9.6331e-07,\n",
            "        3.1175e-07, 1.2948e-07, 2.2326e-07, 6.8693e-08, 1.1984e-07, 2.2140e-07,\n",
            "        8.1729e-08, 5.2842e-09, 1.0188e-09, 2.9553e-06, 1.3415e-05, 4.0806e-08,\n",
            "        1.6174e-08, 1.5756e-07, 1.7917e-09, 3.7756e-09, 4.3683e-08, 1.1084e-08,\n",
            "        1.7382e-09, 3.8105e-09, 3.0028e-08, 4.9489e-08, 3.1178e-08, 4.2176e-08,\n",
            "        3.9408e-08, 5.5452e-10, 4.4339e-09, 1.0676e-07, 7.9645e-09, 5.7591e-08,\n",
            "        6.8368e-09, 4.4703e-08, 5.5887e-09, 1.0470e-07, 4.4184e-06, 9.0890e-09,\n",
            "        4.5181e-08, 1.2842e-08, 9.6446e-09, 3.9055e-08, 1.8010e-08, 2.0268e-07,\n",
            "        7.6115e-08, 2.8746e-08, 4.1483e-08, 1.8653e-08, 9.5420e-09, 2.2928e-07,\n",
            "        1.0782e-08, 6.8783e-07, 1.4163e-06, 4.8927e-07, 4.2078e-09, 4.9202e-08,\n",
            "        1.8701e-08, 5.2013e-08, 1.6473e-07, 3.8101e-06, 3.5473e-08, 6.2949e-08,\n",
            "        1.4917e-08, 6.8846e-07, 3.7269e-07, 8.1159e-08, 1.1193e-07, 1.2039e-07,\n",
            "        1.3669e-07, 6.8950e-08, 4.5279e-08, 1.9386e-08, 6.5123e-08, 4.2855e-08,\n",
            "        8.9203e-07, 1.3650e-08, 1.4009e-08, 5.4649e-08, 3.2595e-08, 6.2618e-07,\n",
            "        6.9681e-08, 4.5068e-07, 4.0075e-08, 3.5871e-08, 1.1621e-07, 4.5349e-08,\n",
            "        2.2935e-06, 2.2924e-05, 2.1022e-08, 1.4535e-08, 6.0447e-09, 3.1672e-09,\n",
            "        2.7499e-08, 1.9511e-07, 2.0439e-07, 6.7913e-08, 1.0013e-06, 3.3649e-07,\n",
            "        2.0641e-08, 5.7061e-08, 3.1922e-08, 6.5320e-08, 4.2717e-07, 8.7776e-07,\n",
            "        3.6287e-08, 5.8810e-09, 1.1157e-08, 8.9751e-08, 1.0498e-07, 1.9719e-08,\n",
            "        1.6413e-08, 3.5192e-08, 3.4404e-08, 2.0704e-07, 2.2460e-08, 3.3194e-07,\n",
            "        5.7485e-08, 1.9409e-08, 6.3387e-08, 2.3385e-08, 8.3180e-07, 3.8398e-08,\n",
            "        5.1408e-09, 8.1683e-08, 2.3986e-09, 2.5452e-07, 2.6856e-07, 2.5206e-08,\n",
            "        1.0011e-07, 2.7857e-08, 1.0203e-08, 1.6075e-07, 8.6061e-07, 1.3496e-08,\n",
            "        6.9913e-08, 1.8355e-07, 5.0275e-08, 6.4285e-09, 2.2763e-08, 1.3085e-07,\n",
            "        1.5254e-08, 6.6832e-09, 1.3179e-07, 5.1691e-08, 9.7494e-09, 2.2129e-06,\n",
            "        1.8378e-06, 1.4782e-07, 3.8122e-08, 2.9393e-08, 5.2592e-08, 3.5359e-08,\n",
            "        6.7135e-07, 1.6867e-07, 2.7699e-08, 2.0981e-08, 7.0990e-09, 3.1816e-09,\n",
            "        6.3479e-07, 8.5909e-08, 1.3972e-08, 1.1226e-06, 3.4706e-09, 4.2616e-06,\n",
            "        4.4553e-09, 1.0625e-07, 7.6419e-08, 1.2811e-07, 5.4497e-07, 7.0500e-08,\n",
            "        1.0120e-07, 4.1182e-09, 6.8630e-09, 1.5261e-07, 1.1523e-09, 1.2174e-07,\n",
            "        2.3825e-07, 4.0890e-08, 3.7231e-08, 5.0749e-08, 5.4042e-08, 3.9282e-08,\n",
            "        8.2292e-09, 3.5072e-07, 2.7069e-07, 1.0002e-07, 7.7800e-09, 4.3234e-08,\n",
            "        1.8353e-09, 4.1329e-09, 3.8067e-08, 8.3254e-08, 4.8928e-07, 3.2311e-08,\n",
            "        3.2487e-08, 1.6075e-09, 1.0654e-07, 9.7604e-08, 1.1142e-06, 9.8323e-08,\n",
            "        1.0241e-08, 1.2964e-07, 2.2696e-07, 2.0031e-08, 3.3350e-07, 4.1773e-08,\n",
            "        9.7985e-09, 2.1974e-08, 2.1660e-07, 1.4489e-07, 7.1107e-08, 2.6046e-07,\n",
            "        1.4983e-07, 3.4709e-06, 1.2556e-08, 3.8659e-08, 5.8507e-09, 1.4511e-08,\n",
            "        2.4675e-07, 2.0809e-08, 7.2271e-07, 5.0494e-08, 2.3094e-08, 7.0303e-09,\n",
            "        1.6843e-07, 3.0203e-08, 1.5118e-08, 1.0931e-08, 1.4949e-09, 9.2544e-09,\n",
            "        6.3775e-07, 5.8576e-08, 1.2340e-07, 4.1333e-08, 2.4096e-07, 4.7927e-07,\n",
            "        1.2625e-09, 9.9192e-08, 6.1202e-08, 2.9965e-07, 1.8560e-08, 2.6818e-08,\n",
            "        7.9261e-08, 6.6631e-08, 1.0538e-07, 4.8782e-07, 1.9890e-06, 5.3063e-08,\n",
            "        8.9054e-09, 4.9190e-08, 1.6440e-07, 7.8498e-08, 9.6059e-09, 1.0335e-07,\n",
            "        3.8989e-07, 1.0905e-06, 9.9309e-08, 1.7464e-07, 3.8434e-09, 5.9196e-08,\n",
            "        9.7006e-08, 8.6352e-08, 4.9051e-08, 4.9224e-08, 1.4596e-07, 6.3775e-07,\n",
            "        2.8855e-09, 4.5441e-08, 1.2385e-07, 1.1413e-08, 4.7104e-07, 1.4244e-08,\n",
            "        1.4220e-07, 1.4621e-08, 1.4423e-08, 7.5573e-08, 3.8052e-08, 5.6810e-07,\n",
            "        4.6318e-08, 1.6706e-07, 3.9106e-08, 1.7825e-08, 1.3439e-07, 9.5160e-08,\n",
            "        5.6105e-08, 9.4698e-09, 3.0246e-08, 1.0789e-08, 1.7483e-07, 2.6968e-07,\n",
            "        3.0337e-08, 1.3082e-07, 1.8951e-09, 3.0353e-08, 5.5247e-07, 5.8710e-08,\n",
            "        1.0070e-07, 6.1495e-07, 2.5323e-07, 9.3492e-08, 2.4127e-06, 8.3144e-08,\n",
            "        3.3932e-08, 9.9332e-08, 2.5635e-07, 1.5576e-07, 4.4429e-09, 5.0165e-09,\n",
            "        1.2221e-07, 1.1876e-08, 1.0184e-07, 1.2520e-09, 9.0869e-08, 3.4059e-08,\n",
            "        1.3401e-08, 2.8786e-08, 4.2253e-08, 3.3030e-08, 6.8523e-08, 4.5652e-08,\n",
            "        3.5806e-07, 3.3665e-07, 2.0697e-08, 6.7998e-08, 1.5058e-06, 1.9429e-08,\n",
            "        1.8298e-09, 1.8974e-07, 5.7554e-09, 3.5336e-09, 2.8809e-07, 1.8645e-08,\n",
            "        5.3135e-08, 2.3474e-08, 3.5773e-08, 5.8322e-08, 4.1449e-08, 1.5935e-08,\n",
            "        3.0415e-07, 7.0137e-09, 5.4800e-07, 1.0545e-07, 6.8331e-08, 8.7067e-07,\n",
            "        2.6779e-07, 3.9015e-08, 7.4487e-07, 4.8151e-07, 4.1444e-09, 4.2558e-08,\n",
            "        4.5824e-10, 5.4327e-09, 6.4251e-07, 1.9650e-08, 7.9090e-09, 6.1425e-06,\n",
            "        7.9085e-09, 2.7202e-08, 3.0752e-09, 1.4825e-07, 1.0335e-08, 6.1500e-08,\n",
            "        1.1347e-07, 4.0237e-09, 3.6575e-07, 3.0171e-08, 2.3996e-07, 3.0358e-08,\n",
            "        2.1527e-08, 1.0775e-08, 2.1310e-07, 1.7532e-07, 3.9071e-07, 2.8698e-07,\n",
            "        1.6717e-07, 1.6651e-07, 2.5677e-07, 3.0029e-07, 3.4669e-08, 1.9326e-08,\n",
            "        1.6488e-05, 1.2660e-07, 1.2361e-07, 1.2798e-07, 1.5756e-07, 7.3444e-07,\n",
            "        2.0235e-08, 1.9255e-07, 1.4826e-08, 9.6500e-08, 5.8965e-08, 4.6543e-08,\n",
            "        6.2595e-07, 3.2240e-07, 1.0970e-07, 3.0671e-07, 3.4478e-07, 5.2725e-08,\n",
            "        1.0103e-07, 2.9562e-08, 8.0342e-09, 4.6124e-08, 4.7762e-08, 9.1099e-09,\n",
            "        5.3332e-09, 4.9728e-08, 3.3602e-07, 1.4755e-07, 2.2270e-07, 5.6172e-08,\n",
            "        2.9735e-07, 1.5410e-07, 9.9979e-08, 7.8556e-08, 1.5685e-08, 1.5119e-07,\n",
            "        2.7997e-07, 3.7932e-08, 8.2578e-08, 4.6484e-08, 1.8390e-08, 8.0615e-07,\n",
            "        3.3786e-08, 1.6245e-07, 5.4135e-10, 4.0888e-08, 4.7599e-08, 6.7014e-09,\n",
            "        2.4031e-07, 4.4506e-05, 1.8749e-07, 5.0063e-08, 1.9877e-08, 9.5812e-08,\n",
            "        3.2711e-07, 1.0600e-06, 2.0560e-08, 1.7764e-07, 5.2817e-08, 2.8116e-08,\n",
            "        2.0952e-08, 1.3256e-07, 7.7312e-08, 3.0893e-08, 3.7852e-08, 1.0858e-08,\n",
            "        3.8536e-08, 2.6494e-07, 2.8846e-07, 1.8174e-07, 4.6939e-08, 4.3738e-07,\n",
            "        1.2588e-07, 1.8821e-08, 3.1473e-08, 2.4143e-07, 2.7331e-08, 2.0083e-08,\n",
            "        5.2146e-08, 2.6551e-08, 1.3441e-07, 3.5908e-07, 4.8170e-07, 5.0123e-08,\n",
            "        6.1519e-08, 2.1719e-07, 4.8590e-07, 1.1940e-07, 1.8909e-07, 2.3938e-07,\n",
            "        1.8065e-08, 4.4491e-08, 1.7319e-08, 2.7663e-08, 2.5803e-07, 3.4641e-07,\n",
            "        1.1437e-05, 1.6559e-08, 4.4092e-08, 3.9305e-08, 1.1656e-08, 1.9971e-09,\n",
            "        2.6676e-08, 8.1156e-08, 7.0700e-09, 8.8625e-07, 6.6455e-08, 1.2542e-08,\n",
            "        3.5603e-08, 2.6901e-08, 1.9887e-08, 5.6312e-08, 3.3045e-08, 9.9232e-08,\n",
            "        3.7093e-07, 3.6693e-08, 5.6260e-08, 2.9873e-08, 6.6700e-09, 3.0090e-08,\n",
            "        8.7601e-06, 1.4117e-08, 1.8049e-07, 1.6524e-07, 3.9929e-07, 2.5985e-08,\n",
            "        2.9411e-07, 3.3165e-08, 1.0711e-08, 1.1859e-07, 7.7967e-09, 1.0515e-08,\n",
            "        2.0349e-08, 8.1605e-08, 4.0537e-08, 2.0753e-08, 3.4244e-08, 8.7161e-08,\n",
            "        4.4234e-08, 1.7807e-09, 9.9696e-07, 1.4471e-06, 2.3080e-07, 7.0339e-08,\n",
            "        2.6266e-08, 9.0097e-08, 3.3677e-07, 1.8917e-08, 2.7462e-07, 1.1874e-08,\n",
            "        7.9920e-09, 9.9419e-08, 9.7356e-09, 4.3899e-08, 1.8499e-07, 1.6823e-07,\n",
            "        3.0519e-07, 6.3586e-08, 4.1745e-08, 1.6946e-07, 6.6289e-08, 2.9965e-09,\n",
            "        6.1116e-08, 1.5864e-08, 7.6987e-09, 5.5589e-08, 8.9378e-10, 4.0557e-08,\n",
            "        5.9694e-09, 6.3901e-09, 2.7556e-09, 4.3475e-09, 4.0861e-09, 3.7763e-06,\n",
            "        8.3719e-09, 9.9795e-09, 4.5040e-08, 6.1559e-10, 5.1801e-09, 1.5331e-07,\n",
            "        5.4657e-08, 1.7674e-07, 2.5704e-07, 3.3754e-07, 1.1135e-08, 1.5745e-09,\n",
            "        4.9041e-08, 5.6946e-07, 8.2700e-09, 1.7317e-09, 2.9580e-09, 2.7394e-08,\n",
            "        5.0113e-07, 1.2198e-07, 5.5915e-09, 8.8208e-09, 4.5194e-09, 2.0711e-08,\n",
            "        2.7043e-08, 4.7750e-09, 1.5037e-08, 5.0070e-08, 6.2452e-08, 6.2931e-09,\n",
            "        1.8927e-08, 1.6208e-07, 5.4752e-09, 8.8998e-09, 4.3059e-10, 7.0112e-09,\n",
            "        4.8141e-08, 9.5457e-10, 5.9603e-08, 3.1636e-08, 1.2132e-07, 3.4431e-07,\n",
            "        2.4214e-08, 2.1135e-09, 6.6342e-08, 6.8809e-07, 1.4288e-08, 1.6169e-07,\n",
            "        2.5766e-08, 3.4805e-08, 4.0276e-08, 8.5152e-08, 2.3590e-07, 1.8305e-08,\n",
            "        3.2941e-08, 1.5013e-08, 8.1382e-09, 1.5150e-07, 2.3130e-09, 1.7146e-08,\n",
            "        2.0549e-08, 6.3127e-08, 4.4766e-08, 2.4489e-10, 1.2082e-08, 3.9327e-08,\n",
            "        1.2410e-08, 4.1095e-09, 1.3268e-07, 9.3397e-07], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# sample execution (requires torchvision)\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)\n",
        "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
        "print(output[0])\n",
        "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "print(probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "editorial-outdoors",
      "metadata": {
        "id": "editorial-outdoors"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# Download ImageNet labels\n",
        "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "psychological-percentage",
      "metadata": {
        "id": "psychological-percentage"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Samoyed 0.884821891784668\n",
            "Arctic fox 0.04573269188404083\n",
            "white wolf 0.0441838763654232\n",
            "Pomeranian 0.00561278173699975\n",
            "Great Pyrenees 0.004654198419302702\n"
          ]
        }
      ],
      "source": [
        "# Read the categories\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "# Show top categories per image\n",
        "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "for i in range(top5_prob.size(0)):\n",
        "    print(categories[top5_catid[i]], top5_prob[i].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "synthetic-lambda",
      "metadata": {
        "id": "synthetic-lambda"
      },
      "source": [
        "### Model Description\n",
        "\n",
        "Resnet models were proposed in \"Deep Residual Learning for Image Recognition\".\n",
        "Here we have the 5 versions of resnet models, which contains 18, 34, 50, 101, 152 layers respectively.\n",
        "Detailed model architectures can be found in Table 1.\n",
        "Their 1-crop error rates on imagenet dataset with pretrained models are listed below.\n",
        "\n",
        "| Model structure | Top-1 error | Top-5 error |\n",
        "| --------------- | ----------- | ----------- |\n",
        "|  resnet18       | 30.24       | 10.92       |\n",
        "|  resnet34       | 26.70       | 8.58        |\n",
        "|  resnet50       | 23.85       | 7.13        |\n",
        "|  resnet101      | 22.63       | 6.44        |\n",
        "|  resnet152      | 21.69       | 5.94        |\n",
        "\n",
        "### References\n",
        "\n",
        " - [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
